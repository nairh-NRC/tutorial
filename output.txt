Title: ['Skip to main content', '\n                                    ', '\n                                ', 'Apply for funding', 'Manage your award', 'What we do', 'News and events', 'Who we are', 'Our councils', 'Apply for funding', 'Funding finder', 'How to apply for research and innovation funding', 'Studentships and doctoral training', 'How we make decisions', 'Improving your funding experience', 'Horizon Europe', 'Manage your award', 'Accept your offer', 'Getting your funding', 'UKRI terms and conditions', 'Request a change', 'Report your outcomes', 'Report your spending', 'Publish your findings', 'What we do', 'Browse our areas of investment and support', 'What we’ve funded', 'International', 'Investing across the UK', 'Career development', 'Supporting collaboration', 'Infrastructure', 'Research culture', 'Artificial intelligence', 'Research financial sustainability', 'Public engagement', 'News and events', 'News', 'Blog', 'Events', 'Voices blog', '101 jobs that change the world', 'Who we are', 'About UK Research and Innovation', 'Our vision and strategy', 'How we’re governed', 'Who we fund', 'How we’re doing', 'How we engage', 'Policies, standards and data', 'Work for us: jobs and advisory roles', 'Contact us', 'Our councils', 'AHRC', 'BBSRC', 'ESRC', 'EPSRC', 'Innovate UK', 'MRC', 'NERC', 'Research England', 'STFC', 'Innovate UK', 'full opportunity details on the Innovation Funding Service', 'SME', 'Print this guidance or save as PDF', 'feedback', 'help improve our online products and services']
URL: 

Title: ['Skip to main content', '\n                                    ', '\n                                ', 'Apply for funding', 'Manage your award', 'What we do', 'News and events', 'Who we are', 'Our councils', 'Apply for funding', 'Funding finder', 'How to apply for research and innovation funding', 'Studentships and doctoral training', 'How we make decisions', 'Improving your funding experience', 'Horizon Europe', 'Manage your award', 'Accept your offer', 'Getting your funding', 'UKRI terms and conditions', 'Request a change', 'Report your outcomes', 'Report your spending', 'Publish your findings', 'What we do', 'Browse our areas of investment and support', 'What we’ve funded', 'International', 'Investing across the UK', 'Career development', 'Supporting collaboration', 'Infrastructure', 'Research culture', 'Artificial intelligence', 'Research financial sustainability', 'Public engagement', 'News and events', 'News', 'Blog', 'Events', 'Voices blog', '101 jobs that change the world', 'Who we are', 'About UK Research and Innovation', 'Our vision and strategy', 'How we’re governed', 'Who we fund', 'How we’re doing', 'How we engage', 'Policies, standards and data', 'Work for us: jobs and advisory roles', 'Contact us', 'Our councils', 'AHRC', 'BBSRC', 'ESRC', 'EPSRC', 'Innovate UK', 'MRC', 'NERC', 'Research England', 'STFC', 'Home', 'News', 'UK Research and Innovation (UKRI) Infrastructure Fund', 'felicity.perry@jic.ac.uk', 'feedback', 'help improve our online products and services']
URL: Top image:  A computer-generated image of the Next Generation Infrastructure gardens and buildings. Credit: BDP, Secchi Smith
Title: ['Skip to main content', '\n                                    ', '\n                                ', 'Apply for funding', 'Manage your award', 'What we do', 'News and events', 'Who we are', 'Our councils', 'Apply for funding', 'Funding finder', 'How to apply for research and innovation funding', 'Studentships and doctoral training', 'How we make decisions', 'Improving your funding experience', 'Horizon Europe', 'Manage your award', 'Accept your offer', 'Getting your funding', 'UKRI terms and conditions', 'Request a change', 'Report your outcomes', 'Report your spending', 'Publish your findings', 'What we do', 'Browse our areas of investment and support', 'What we’ve funded', 'International', 'Investing across the UK', 'Career development', 'Supporting collaboration', 'Infrastructure', 'Research culture', 'Artificial intelligence', 'Research financial sustainability', 'Public engagement', 'News and events', 'News', 'Blog', 'Events', 'Voices blog', '101 jobs that change the world', 'Who we are', 'About UK Research and Innovation', 'Our vision and strategy', 'How we’re governed', 'Who we fund', 'How we’re doing', 'How we engage', 'Policies, standards and data', 'Work for us: jobs and advisory roles', 'Contact us', 'Our councils', 'AHRC', 'BBSRC', 'ESRC', 'EPSRC', 'Innovate UK', 'MRC', 'NERC', 'Research England', 'STFC', 'Innovate UK', 'UK and Canada biomanufacturing innovations in cell and gene therapies', 'Print this guidance or save as PDF', 'feedback', 'help improve our online products and services']
URL: 

Title: ['Skip to main content', '\n                                    ', '\n                                ', 'Apply for funding', 'Manage your award', 'What we do', 'News and events', 'Who we are', 'Our councils', 'Apply for funding', 'Funding finder', 'How to apply for research and innovation funding', 'Studentships and doctoral training', 'How we make decisions', 'Improving your funding experience', 'Horizon Europe', 'Manage your award', 'Accept your offer', 'Getting your funding', 'UKRI terms and conditions', 'Request a change', 'Report your outcomes', 'Report your spending', 'Publish your findings', 'What we do', 'Browse our areas of investment and support', 'What we’ve funded', 'International', 'Investing across the UK', 'Career development', 'Supporting collaboration', 'Infrastructure', 'Research culture', 'Artificial intelligence', 'Research financial sustainability', 'Public engagement', 'News and events', 'News', 'Blog', 'Events', 'Voices blog', '101 jobs that change the world', 'Who we are', 'About UK Research and Innovation', 'Our vision and strategy', 'How we’re governed', 'Who we fund', 'How we’re doing', 'How we engage', 'Policies, standards and data', 'Work for us: jobs and advisory roles', 'Contact us', 'Our councils', 'AHRC', 'BBSRC', 'ESRC', 'EPSRC', 'Innovate UK', 'MRC', 'NERC', 'Research England', 'STFC', 'Home', 'News', 'Sign up for the latest news, funding opportunities and ISCF updates', 'feedback', 'help improve our online products and services']
URL: Top image:  Credit: ArtistGNDphotography / Getty Images
Title: ['Skip to main content', '\n                                    ', '\n                                ', 'Apply for funding', 'Manage your award', 'What we do', 'News and events', 'Who we are', 'Our councils', 'Apply for funding', 'Funding finder', 'How to apply for research and innovation funding', 'Studentships and doctoral training', 'How we make decisions', 'Improving your funding experience', 'Horizon Europe', 'Manage your award', 'Accept your offer', 'Getting your funding', 'UKRI terms and conditions', 'Request a change', 'Report your outcomes', 'Report your spending', 'Publish your findings', 'What we do', 'Browse our areas of investment and support', 'What we’ve funded', 'International', 'Investing across the UK', 'Career development', 'Supporting collaboration', 'Infrastructure', 'Research culture', 'Artificial intelligence', 'Research financial sustainability', 'Public engagement', 'News and events', 'News', 'Blog', 'Events', 'Voices blog', '101 jobs that change the world', 'Who we are', 'About UK Research and Innovation', 'Our vision and strategy', 'How we’re governed', 'Who we fund', 'How we’re doing', 'How we engage', 'Policies, standards and data', 'Work for us: jobs and advisory roles', 'Contact us', 'Our councils', 'AHRC', 'BBSRC', 'ESRC', 'EPSRC', 'Innovate UK', 'MRC', 'NERC', 'Research England', 'STFC', 'Home', 'What we do', 'What we’ve funded', 'What Research England has funded', 'feedback', 'help improve our online products and services']
URL: 

Content: <main class="govuk-main-wrapper ukri-main-content" id="main-content">

        
<div class="govuk-width-container">
		<h1 class="govuk-heading-xl main-area__page-title" id="skipnav-target">International Investment Initiative (I3) funding decisions</h1>    <div class="govuk-grid-row">
        <div class="govuk-grid-column-two-thirds-from-desktop main-content-column">
        	<div id="post-36318" class="post-36318 page type-page status-publish hentry category-research-england">
    <div class="entry-header">
		<div class="ukri-post-image-holder">
								</div>
        
		    </div>

    <div class="entry-content">
        <p>Research England awarded a total of £3.6 million to eight higher education providers (HEPs) through a competitive scheme.</p>
<p>Awards are allocated over up to five years and must be led by an English HEP with a minimum of one international university or research organisation as a partner.</p>
<p>Eight bids received funding from the i3 fund.</p>
<h2>Brunel University London</h2>
<h3>Bid title</h3>
<p>UK and Finland: Research Collaboration for Prosperity and Health</p>
<h3>Partner</h3>
<p>Tampere University (Finland)</p>
<h3>Investment</h3>
<p>£343,918</p>
<h3>Summary</h3>
<p>The award will accelerate the development of a strategic partnership between Brunel and Tampere University in Materials &amp; Manufacturing, Biomedical Engineering, Structural Integrity, Digital Technology, Water Resources and Ageing &amp; Wellness. It will deliver benefits to the UK and Finland in the form of research competitiveness, societal impact and innovation.</p>
<h2>Imperial College London</h2>
<h3>Bid title</h3>
<p>Data 4.0: leading the fourth industrial revolution with data-driven technologies</p>
<h3>Partners</h3>
<p>Centre National de la Recherche Scientifique (CNRS, France)<br>
Technical University of Munich (Germany)<br>
Nanyang Technological University (Singapore)</p>
<h3>Investment</h3>
<p>£500,000</p>
<h3>Summary</h3>
<p>Imperial will establish Data 4.0 clusters in: Mathematical sciences, with France’s CNRS; AI and robotics, with Germany’s Technical University of Munich; Technology and healthcare, with Singapore’s Nanyang Technological University. Each cluster will develop flagship international studentships, expand academic exchange, accelerate frontier research with seed funding, and launch bespoke doctoral programmes.</p>
<h2>Liverpool John Moores University</h2>
<h3>Bid title</h3>
<p>i-CARDIO – International Collaboration Assessing novel health models: A Research Design Intervention Opportunity</p>
<h3>Partner</h3>
<p>University of Western Australia (Australia)</p>
<h3>Investment</h3>
<p>£488,829</p>
<h3>Summary</h3>
<p>The UK faces a growing crisis of physical inactivity and associated disease risk. In Australia “registered exercise professionals” support the healthcare system and have reduced healthcare costs. This system does not exist in the UK, and this award will evaluate healthcare model development in Australia and pathways to changes in the UK.</p>
<h2>Loughborough University</h2>
<h3>Bid title</h3>
<p>An International Research Centre to study the effects of Connected and Autonomous Vehicles on Vulnerable Road-Users</p>
<h3>Partners</h3>
<p>Queensland University of Technology (QUT, Australia)<br>
Tongji University (China)</p>
<h3>Investment</h3>
<p>£436,067</p>
<h3>Summary</h3>
<p>This project will scale up an existing strategic, international collaboration between three world-leading research centres – Loughborough University (UK), Queensland University of Technology (Australia), and Tongji University (China). It will establish a new International Research Centre to study the impacts of connected and autonomous vehicles on vulnerable road users’ safety.</p>
<h2>Newcastle University</h2>
<h3>Bid title</h3>
<p>Newcastle University/Monash Academic Track (NUMAcT) scheme</p>
<h3>Partner</h3>
<p>Monash University (Australia)</p>
<h3>Investment</h3>
<p>£500,000</p>
<h3>Summary</h3>
<p>Building on the recently launched and extremely popular NUAcT scheme supporting researchers making the transition to independence, NUMAcT will allow investigators to work in two long-standing partner universities, Newcastle and Monash. The initial focus on drug discovery provides complementary access to world-class facilities, expertise, and bespoke training and mentorship.</p>
<h2>University of Birmingham</h2>
<h3>Bid title</h3>
<p>Industrialisation of Energy, Waste and Recycling</p>
<h3>Partners</h3>
<p>Fraunhofer Institute for Environmental Safety and Energy Technology (UMSICHT, Germany)<br>
Jiangsu Industrial Technology Research Institute (JITRI, China)</p>
<h3>Investment</h3>
<p>£499,099</p>
<h3>Summary</h3>
<p>Investment of £2.6 million, made up of nearly £0.5 million from Research England, and £2.1 million co-investment, over five years will scale up the partnerships between the University of Birmingham, Fraunhofer Institute for Environmental, Safety, and Energy Technology, and Jiangsu Industry Technology Research Institute. This three-way multi-country bridge will provide a comprehensive research and innovation pipeline from fundamental research to close-to-market innovation.</p>
<h2>University of Brighton</h2>
<h3>Bid title</h3>
<p>3DMed – Anglo Canadian Collaboration on Interface Science for Medical Innovation</p>
<h3>Partner</h3>
<p>York University (Canada)</p>
<h3>Investment</h3>
<p>£455,080</p>
<h3>Summary</h3>
<p>3DMed scales up a well-established strategic collaboration between University of Brighton, UK and York University, Canada. The project will capitalise on the synergy between programmes of excellent research in engineering and biomedicine to develop industrial applications and novel research skills in 3D bio-printing and additive biomedical manufacturing technologies.</p>
<h2>University of Hull</h2>
<h3>Bid title</h3>
<p>Building Critical Mass for Palliative Care Research through Collaborative Support, Exchange and Challenge</p>
<h3>Partner</h3>
<p>University of Technology Sydney (Australia)</p>
<h3>Investment</h3>
<p>£403,510</p>
<h3>Summary</h3>
<p>This award will increase the scale and impact of our international collaboration between the Wolfson Palliative Care Research Centre, University of Hull, and the Improving Palliative and Chronic Care Through Clinical Research and Translation group, University Technology Sydney, forming critical mass to drive societal benefit through high-quality palliative care research.</p>
									                    <p class="last-updated">Last updated: 31 March 2022</p>
                    </div><!-- .entry-content -->
	</div><!-- #post -->
        </div>
        <aside class="govuk-grid-column-one-third-from-desktop ukri-sidebar">
            

        </aside>
    </div>
</div>
    </main>

Title: ['Skip to main content', '\n                                    ', '\n                                ', 'Apply for funding', 'Manage your award', 'What we do', 'News and events', 'Who we are', 'Our councils', 'Apply for funding', 'Funding finder', 'How to apply for research and innovation funding', 'Studentships and doctoral training', 'How we make decisions', 'Improving your funding experience', 'Horizon Europe', 'Manage your award', 'Accept your offer', 'Getting your funding', 'UKRI terms and conditions', 'Request a change', 'Report your outcomes', 'Report your spending', 'Publish your findings', 'What we do', 'Browse our areas of investment and support', 'What we’ve funded', 'International', 'Investing across the UK', 'Career development', 'Supporting collaboration', 'Infrastructure', 'Research culture', 'Artificial intelligence', 'Research financial sustainability', 'Public engagement', 'News and events', 'News', 'Blog', 'Events', 'Voices blog', '101 jobs that change the world', 'Who we are', 'About UK Research and Innovation', 'Our vision and strategy', 'How we’re governed', 'Who we fund', 'How we’re doing', 'How we engage', 'Policies, standards and data', 'Work for us: jobs and advisory roles', 'Contact us', 'Our councils', 'AHRC', 'BBSRC', 'ESRC', 'EPSRC', 'Innovate UK', 'MRC', 'NERC', 'Research England', 'STFC', 'Innovate UK', 'full opportunity details on the Innovation Funding Service', 'micro, small or medium-sized enterprises (SME)', 'Print this guidance or save as PDF', 'feedback', 'help improve our online products and services']
URL: 

Title: ['Skip to main content', '\n                                    ', '\n                                ', 'Apply for funding', 'Manage your award', 'What we do', 'News and events', 'Who we are', 'Our councils', 'Apply for funding', 'Funding finder', 'How to apply for research and innovation funding', 'Studentships and doctoral training', 'How we make decisions', 'Improving your funding experience', 'Horizon Europe', 'Manage your award', 'Accept your offer', 'Getting your funding', 'UKRI terms and conditions', 'Request a change', 'Report your outcomes', 'Report your spending', 'Publish your findings', 'What we do', 'Browse our areas of investment and support', 'What we’ve funded', 'International', 'Investing across the UK', 'Career development', 'Supporting collaboration', 'Infrastructure', 'Research culture', 'Artificial intelligence', 'Research financial sustainability', 'Public engagement', 'News and events', 'News', 'Blog', 'Events', 'Voices blog', '101 jobs that change the world', 'Who we are', 'About UK Research and Innovation', 'Our vision and strategy', 'How we’re governed', 'Who we fund', 'How we’re doing', 'How we engage', 'Policies, standards and data', 'Work for us: jobs and advisory roles', 'Contact us', 'Our councils', 'AHRC', 'BBSRC', 'ESRC', 'EPSRC', 'Innovate UK', 'MRC', 'NERC', 'Research England', 'STFC', 'Innovate UK', 'full opportunity details on the Innovation Funding Service', 'Print this guidance or save as PDF', 'feedback', 'help improve our online products and services']
URL: 

Title: ['Skip to main content', '\n                                    ', '\n                                ', 'Apply for funding', 'Manage your award', 'What we do', 'News and events', 'Who we are', 'Our councils', 'Apply for funding', 'Funding finder', 'How to apply for research and innovation funding', 'Studentships and doctoral training', 'How we make decisions', 'Improving your funding experience', 'Horizon Europe', 'Manage your award', 'Accept your offer', 'Getting your funding', 'UKRI terms and conditions', 'Request a change', 'Report your outcomes', 'Report your spending', 'Publish your findings', 'What we do', 'Browse our areas of investment and support', 'What we’ve funded', 'International', 'Investing across the UK', 'Career development', 'Supporting collaboration', 'Infrastructure', 'Research culture', 'Artificial intelligence', 'Research financial sustainability', 'Public engagement', 'News and events', 'News', 'Blog', 'Events', 'Voices blog', '101 jobs that change the world', 'Who we are', 'About UK Research and Innovation', 'Our vision and strategy', 'How we’re governed', 'Who we fund', 'How we’re doing', 'How we engage', 'Policies, standards and data', 'Work for us: jobs and advisory roles', 'Contact us', 'Our councils', 'AHRC', 'BBSRC', 'ESRC', 'EPSRC', 'Innovate UK', 'MRC', 'NERC', 'Research England', 'STFC', 'Home', 'Review of peer review', 'Introduction', 'Interventions covered in this review', 'Method note', 'Structure of this report', 'General observations', 'Main findings: interventions prior to a funding opportunity', 'Main findings: interventions in assessment process design', 'Main findings: interventions to the shape of decision-making', 'Main findings: interventions in training and feedback', 'Additional interventions identified by our review', 'Summary and recommendations', 'Print this document or save as a PDF', 'Peer Review of Grant Applications: Criteria Used and Qualitative Study of Reviewer Practices', 'Criteria for assessing grant applications: a systematic review', 'Do peers share the same criteria for assessing grant applications?', 'The decision-making constraints and processes of grant peer review, and their effects on the review outcome.', 'Study on the proposal evaluation system for the EU R&I framework programme', 'Assessment of potential bias in research grant peer review in Canada', 'The effects of funding policies on academic research', 'Evaluating Grant Peer Review in the Health Sciences: A review of the literature', 'Report of the Research Councils UK Efficiency and', 'Effectiveness of Peer Review Project', 'Response to the RCUK consultation on the Efficiency and Effectiveness of Peer Review', 'Several grants simultaneously', 'What requirements apply if I already have a grant from the Swedish Research Council', 'Science funding: Duel to the death', 'Sham Peer Review: the Destruction of Medical Careers (PDF, 37KB).', 'What works for peer review and decision-making in research funding: a realist synthesis', 'Tough love', 'International Evaluation of the Funding and Management of the National Natural Science Foundation of China', 'ESPR Research Grant Programme 2017 to 2022', 'ESRC – Large Grants Competition 2016/17 (Update). University of Lincoln: Research Blog', 'Demand management', 'Towards inclusive funding practices for early career researchers', 'The Equality, Diversity and Inclusion Engagement Fellowship Pilot AHRC funding scheme report 2020 to 2022', 'Ethnicity and race inequity in our portfolio: findings of our community engagement and actions for change', 'Gender equality and positive action: evidence from UK universities', 'Positive action towards gender equality? Evidence from the Athena SWAN Charter in UK Medical Schools.', 'Effect of Athena SWAN funding incentives on women’s research leadership', 'Study on the proposal evaluation system for the EU R&I framework programme', 'The leaky pipeline in research grant peer review and funding decisions: challenges and future directions', 'Grant application outcomes for biomedical researchers who participated in the National Research Mentoring Network’s Grant Writing Coaching Programs', 'The experimental research funder’s handbook, Research on Research Institute', 'Alternatives to peer review in research project funding', 'Sandpit methodology: results of a rapid literature search to inform a sandpit exercise for PETRA', 'Sandpits can develop cross-disciplinary projects, but funders need to be as open-minded as researchers', 'Decision-making approaches used by UK and international health funding organisations for allocating research funds: a survey of current practice', 'What works for peer review and decision-making in research funding: a realist synthesis. Research integrity and peer review', 'Creativity greenhouse: at-a-distance collaboration and competition over research funding', 'Exploring the potential role of community engagement in evaluating clinical and translational science grant proposals', 'Streamlined research funding using short proposals and accelerated peer review: an observational study', 'NSF tries two-step review, drawing praise – and darts', 'Assessing health research grant applications: a retrospective comparative review of a one-stage versus a two-stage application assessment process', 'Exploring the potential role of community engagement in evaluating clinical and translational science grant proposals. Journal of Clinical and Translational Science', 'Study on the proposal evaluation system for the EU R&I framework programme', 'The experimental research funder’s handbook, Research on Research Institute', 'Looking across and looking beyond the knowledge frontier: intellectual distance, novelty, and resource allocation in science', 'What do we know about grant peer review in the health sciences?', 'Is blinded review enough? How gendered outcomes arise even under anonymous evaluation', 'Conservatism gets funded? A field experiment on the role of negative information in novel project evaluation', 'Evaluation of the Spark pilot.', 'Anonymizing peer review for the NIH Director’s Transformative Research Award Applications', 'German funder sees early success in grant-by-lottery trial', 'An experimental test of the effects of redacting grant applicant identifiers on peer review outcomes', 'Study on the proposal evaluation system for the EU R&I framework programme', 'Blinding applicants in a first-stage peer-review process of biomedical grants: an observational study', 'Assigning evaluators to research grant applications: the case of Slovak Research and Development Agency', 'Innovating in the research funding process: peer review alternatives and adaptations', 'An algorithm for automatic assignment of reviewers to papers.', 'How research funders ensure the scientific legitimacy of their decisions: investigation in support of the design of formas', 'UKRI Research and Innovation Funding Service (RIFS) visioning work', 'A semi-automatic web based tool for the selection of research projects reviewers', 'What works for peer review and decision-making in research funding: a realist synthesis, Research Integrity and Peer Review', 'Dragons’ Den: promoting healthcare research and innovation', 'Fleshing out the data: when epidemiological researchers engage with patients and carers. Learning lessons from a patient involvement activity', 'Peer review for Ideas Grants in 2021', 'Expanding group peer review: a proposal for medical education scholarship', 'Communities of practice in peer review: outlining a group review process', 'The experimental research funder’s handbook', 'The decision-making constraints and processes of grant peer review, and their effects on the review outcome', 'Consultation on the development of peer review for NHMRC’s new grant program', 'Academic talent selection in grant review panels', 'An outcome evaluation of the National Institutes of Health (NIH) Director’s pioneer award (NDPA) program', 'Evaluation practices in the selection of ground-breaking research proposals', 'Study on the proposal evaluation system for the EU R&I framework programme', 'Ensuring sustainable evaluation: how to improve quality of evaluating grant proposals?', 'Similar-to-me effects in the grant application process: Applicants, panelists, and the likelihood of obtaining funds', 'Equality, Diversity and Inclusion Engagement Fellowship Pilot AHRC Funding Scheme Report', 'Designing grant-review panels for better funding decisions: lessons from an empirically calibrated simulation model', 'Process review of UKRI’s research and innovation response to COVID-19', 'Exploring the degree of delegated authority for the peer review of societal impact', 'Community review: a robust and scalable selection system for resource allocation within open science and innovation communities', 'Innovating in the research funding process: peer review alternatives and adaptations', 'Evaluation of the ESRC Transformative Research Scheme', 'A radical change in peer review: a pilot project to ease pressure on NSF’s vaunted peer-review system required grant applicants to review seven competing proposals', 'Powering discovery: the expert panel on international practices for funding natural sciences and engineering research', 'What works for peer review and decision-making in research funding: a realist synthesis', 'Administrative discretion in scientific funding: evidence from a prestigious postdoctoral training program', 'Alternatives to peer review in research project funding', 'Process review of UKRI’s research and innovation response to COVID-19', 'Evaluating transformative research programmes: A case study of the NSF Small Grants for Exploratory Research programme', 'Enhancing NIH grant peer review: a broader perspective', 'Standing Panel on Impact Assessment (SPIA)', 'Participation and motivations of grant peer reviewers: a comprehensive survey of the biomedical research community', 'IES guide for grant peer review panel members: information, tips and instructions for members of IES scientific grant peer review panels (PDF, 780KB)', 'Organisational and process review of the Human Frontier Science Program.', 'Process review of UKRI’s research and innovation response to COVID-19', 'Becoming a peer reviewer for NIJ (2023)', 'Improving NIJ’s peer review process: the scientific review panel pilot project', 'CSR data and evaluations', 'Review of disability and rehabilitation research: NIDRR grantmaking processes and products', 'Responsive mode grant assessment process', 'An overview: IES procedures for peer review of grant applications', 'Managing internal nomination and peer review processes to reduce bias', 'Assessment of potential bias in research grant peer review in Canada', 'San Francisco Declaration on Research Assessment (DORA)', 'Harnessing the Metric Tide: indicators, infrastructures and priorities for UK responsible research assessment', 'How do NIHR peer review panels use bibliometric information to support their decisions?', 'The role of metrics in peer assessments', 'Segmenting academics: resource targeting of research grants', 'Dealing with the limits of peer review with innovative approaches to allocating research funding (PDF, 314KB)', 'The leaky pipeline in research grant peer review and funding decision: challenges and future directions.', 'Does the inclusion of non-academic reviewers make any difference for grant impact panels?', 'The influence of peer reviewer expertise on the evaluation of research funding applications', 'Alternatives to peer review in research project funding', 'Innovating in the research funding process: peer review alternatives and adaptations', 'The experimental Research funder’s handbook', 'UKRI Research and Innovation Funding Service (RIFS) visioning work (PDF, 1.5MB)', 'How research funders ensure the scientific legitimacy of their decisions: investigation in support of the design of Formas scientific management', 'Evaluation of research proposals by peer review panels: broader panels for broader assessments?', 'Peer review of health research funding proposals: A systematic map and systematic review of innovations for effectiveness and efficiency', 'Face-to-face panel meetings versus remote evaluation of fellowship applications: simulation study at the Swiss National Science Foundation', 'Meeting for peer review at a resort that’s virtually free', 'Teleconference versus face-to-face scientific peer review of grant application: effects on review outcomes', 'Alternatives to Peer Review in Research Project Funding', 'What do we know about grant peer review in the health sciences?', 'Innovating in the research funding process: peer review alternatives and adaptations', 'Pre-award process review of the IRC Laureate Award (PDF, 2.4MB)', 'What works for peer review and decision: making in research funding: a realist synthesis, Research Integrity and Peer Review', 'Peer review of health research funding proposals: A systematic map and systematic review of innovations for effectiveness and efficiency', 'Mavericks and lotteries', 'Dealing with the limits of peer review with innovative approaches to allocating research funding (PDF, 314KB)', 'I won a project!', 'Alternatives to peer review in research project funding', 'What works for peer review and decision-making in research funding: a realist synthesis', 'Fund ideas, not pedigree, to find fresh insight', 'Mavericks and lotteries', 'The troubles with peer review for allocating research funding', 'The experimental research funder’s handbook', 'NIH peer review percentile scores are poorly predictive of grant productivity', 'Research funding: the case for a modified lottery', 'Alternatives to peer review in research project funding', 'Innovating in the research funding process: peer review alternatives and adaptations', 'The consequences of competition: simulating the effects of research grant allocation strategies', 'Are peer-reviews of grant proposals reliable? An analysis of Economic and Social Research Council (ESRC) funding applications', 'Study on the proposal evaluation system for the EU R&I framework programme', 'Blind Luck – Could lotteries be a more efficient mechanism for allocating research funds than peer review?', 'Peer review or lottery? A critical analysis of two different forms of decision-making mechanisms for allocation of research grants', 'Partially Randomized Procedure – Lottery and Peer Review', 'Give Chance a Chance', 'Peer review of grant applications: criteria used and qualitative study of reviewer practices', 'Alternatives to peer review in research project funding – 2013 update', 'Are peer-reviews of grant proposals reliable? An analysis of Economic and Social Research Council (ESRC) funding applications', 'Commensuration bias in peer review', 'Your comments are meaner than your score’: score calibration talk influences intra- and inter-panel variability during scientific grant peer review', 'Science Europe study on research assessment practices', 'UKRI Research and Innovation Funding Service (RIFS) visioning work – Final report (PDF, 1.5MB)', 'How research funders ensure the scientific legitimacy of their decisions: investigation in support of the design of Formas scientific management.', 'Addressing racial disparities in NIH funding', 'Grant allocation disparities from a gender perspective: literature review', 'The modified lottery: formalizing the intrinsic randomness of research funding, accountability in research', 'Evolving and upholding fairness in peer review', 'Inequality in early career research in the UK life sciences', 'Understanding our portfolio: a gender perspective', 'Interventions designed to reduce implicit prejudices and implicit stereotypes in real world contexts: a systematic review', 'Scientists from minority-serving institutions and their participation in grant peer review', 'The problem with implicit bias training', 'The state of women in life sciences at McGill: a summary and report of the Win4Science Forum (PDF, 918KB)', 'Who resembles a scientific leader – Jack or Jill? How implicit bias could influence research grant funding', 'The good, the bad, and the ugly of implicit bias', 'Does gender bias still affect women in science?', 'Assessment of potential bias in research grant peer review in Canada', 'Unconscious bias and diversity training – what the evidence says', 'Is there gender bias in research grant success in social sciences? Hong Kong as a case study', 'Targeted, actionable and fair: reviewer reports as feedback and its effect on ECR career choices', 'Study on the proposal evaluation system for the EU R&I framework programme', 'Evaluation of the ESRC Transformative Research Scheme (PDF, 1.5MB)', 'Organisational and process review of the Human Frontier Science Program', 'ESF survey analysis report on peer review practices (PDF, 6.4MB)', 'What do we know about grant peer review in the health sciences?', 'Individual versus general structured feedback to improve agreement in grant peer review: a randomized controlled trial', 'Global state of peer review 2018', 'What works for peer review and decision-making in research funding: a realist synthesis', 'Grant peer review: improving inter-rater reliability with training', 'Peer review of health research funding proposals: a systematic map and systematic review of innovations for effectiveness and efficiency', 'Attitudes and practices of open data, preprinting, and peer-review-A cross sectional study on Croatian scientists.', 'Gender-equal funding rates conceal unequal evaluations', 'Horizon Europe and Plan B research funding: turning adversity into opportunity', 'Strategic advice for enhancing the gender dimension of Open Science and Innovation Policy', 'Innovating in the research funding process: peer review alternatives and adaptations', 'Response by the Author', 'Decision-making approaches used by UK and international health funding organisations for allocating research funds: a survey of current practice', 'How research funders ensure the scientific legitimacy of their decisions: investigation in support of the design of Formas scientific management', 'What works for peer review and decision-making in research funding: a realist synthesis', 'summary table of aims, hazards and evidence strength', '\n\t\t\t\t', '\n\t\t\t', 'feedback', 'help improve our online products and services']
URL: 
			
Title: ['Skip to main content', '\n                                    ', '\n                                ', 'Apply for funding', 'Manage your award', 'What we do', 'News and events', 'Who we are', 'Our councils', 'Apply for funding', 'Funding finder', 'How to apply for research and innovation funding', 'Studentships and doctoral training', 'How we make decisions', 'Improving your funding experience', 'Horizon Europe', 'Manage your award', 'Accept your offer', 'Getting your funding', 'UKRI terms and conditions', 'Request a change', 'Report your outcomes', 'Report your spending', 'Publish your findings', 'What we do', 'Browse our areas of investment and support', 'What weâ€™ve funded', 'International', 'Investing across the UK', 'Career development', 'Supporting collaboration', 'Infrastructure', 'Research culture', 'Artificial intelligence', 'Research financial sustainability', 'Public engagement', 'News and events', 'News', 'Blog', 'Events', 'Voices blog', '101 jobs that change the world', 'Who we are', 'About UK Research and Innovation', 'Our vision and strategy', 'How weâ€™re governed', 'Who we fund', 'How weâ€™re doing', 'How we engage', 'Policies, standards and data', 'Work for us: jobs and advisory roles', 'Contact us', 'Our councils', 'AHRC', 'BBSRC', 'ESRC', 'EPSRC', 'Innovate UK', 'MRC', 'NERC', 'Research England', 'STFC', 'Home', 'News', 'Sign up for the latest news, funding opportunities and ISCF updates', 'feedback', 'help improve our online products and services']
URL: Top image: Â Credit: ArtistGNDphotography / Getty Images
Content: <main class="govuk-main-wrapper ukri-main-content" id="main-content">

        <div class="govuk-width-container">
			<h1 class="govuk-heading-xl main-area__page-title" id="skipnav-target">Â£2.2 million awarded to UK agri-tech firms with Canadian partners</h1>
	<div class="govuk-grid-row">
        <div class="govuk-grid-column-two-thirds-from-desktop main-content-column">
          <div id="post-23774" class="post-23774 news type-news status-publish has-post-thumbnail hentry category-innovate-uk">
    <div class="entry-header">
		<div class="ukri-post-image-holder">
			<img width="735" height="490" src="https://www.ukri.org/wp-content/uploads/2021/05/IUK-280521-GettyImages-1256112296-e1621494802738-735x490.jpg" class="attachment-large size-large wp-post-image" alt="Harvesting in agriculture crop field" decoding="async" fetchpriority="high" srcset="https://www.ukri.org/wp-content/uploads/2021/05/IUK-280521-GettyImages-1256112296-e1621494802738-735x490.jpg 735w, https://www.ukri.org/wp-content/uploads/2021/05/IUK-280521-GettyImages-1256112296-e1621494802738-300x200.jpg 300w, https://www.ukri.org/wp-content/uploads/2021/05/IUK-280521-GettyImages-1256112296-e1621494802738-750x500.jpg 750w, https://www.ukri.org/wp-content/uploads/2021/05/IUK-280521-GettyImages-1256112296-e1621494802738-510x340.jpg 510w, https://www.ukri.org/wp-content/uploads/2021/05/IUK-280521-GettyImages-1256112296-e1621494802738-360x240.jpg 360w, https://www.ukri.org/wp-content/uploads/2021/05/IUK-280521-GettyImages-1256112296-e1621494802738.jpg 1500w" sizes="(min-width: 1200px) 735px, (min-width: 769px) calc((((100vw - 30px) / 3) * 2) - 45px), calc(100vw - 30px)">					</div>
        
<p class="govuk-body-s post-summary__date govuk-!-padding-top-3"><time datetime="2021-05-20">20 May 2021</time></p>			    </div>

    <div class="entry-content">
        <p class="govuk-body-l">UKRI has pledged over Â£2.2 million to seven agri-tech firms to develop new agricultural techniques that will help countries meet their net zero emission targets.</p>
<p>The funding is being awarded through UK Research and Innovationâ€™s (UKRI) <em>UK-Canada: enhancing agricultural productivity and sustainability</em> competition, which is overseen by the Transforming Food Production challenge.</p>
<p>In this competition, UK and Canadian companies were brought together through online and in person events to identify and build project concepts in sustainable agriculture.</p>
<p>The seven winning UK companies are:</p>
<ul>
<li>Arden Biotechnology</li>
<li>Devenish</li>
<li>Precision Decisions</li>
<li>Airborne Robotics</li>
<li>RAFT Solutions</li>
<li>Clarity Biosolutions</li>
<li>RS AQUA.</li>
</ul>
<p>Their respective Canadian partners are:</p>
<ul>
<li>TrustBIX</li>
<li>Mara Renewables Corporation</li>
<li>JCA Industries</li>
<li>SociÃ©tÃ© pour lâ€™information industrielle (SII Canada)</li>
<li>Bow Valley Genetics</li>
<li>Sona Nanotech</li>
<li>Innovasea Marine Systems.</li>
</ul>
<p>The Canadian partners will receive funding support through the National Research Council of Canada Industrial Research Assistance Program (NRC IRAP).</p>
<h2>Combatting climate change</h2>
<p>The competition ran in the first half of 2020 and aims to boost international cooperation and business growth, by mobilising cross border resources and expertise to combat climate change.</p>
<p>The winning projects had to demonstrate a clear plan to:</p>
<ul>
<li>improve productivity</li>
<li>increase sustainability</li>
<li>help move towards achieving net zero emissions by 2040</li>
<li>show market awareness</li>
<li>develop a commercial plan.</li>
</ul>
<p>Katrina Hayter, challenge director for the Transforming Food Production programme, UKRI, said:</p>
<blockquote><p>UKRIâ€™s UK-Canada competition is an important initiative that helps UK businesses create strong international networks, access expertise and develop international market opportunities. The UK companies and their Canadian partners are working on an exciting array of projects to integrate cutting-edge technology into everyday farming techniques that could help both UK and Canadian agriculture improve productivity and sustainability. Ultimately, making our respective agricultural systems more climate friendly.</p></blockquote>
<p>Mitch Davies, President of NRC, said:</p>
<blockquote><p>The NRC is honoured to partner with UKRI to stimulate co-innovation between Canadian and UK small and medium-sized enterprises. International collaboration is key to SME growth and these collaborative partnerships provide accelerated access to new markets and global value chains, positioning Canadian businesses to compete globally.</p></blockquote>
<p>The projects include:</p>
<ul>
<li>Devenishâ€™s plan to develop the next generation of algae-derived products for use in poultry production, which will be trialled on British and Canadian farms</li>
<li>Airborne Roboticsâ€™ RootDetect programme, which aims to design a sophisticated sensor to scout out large areas for signs of club root in canola and oil seed rape crops.</li>
</ul>
<p>Farming Minister, Victoria Prentis, noted:</p>
<blockquote><p>We must all work together to tackle the impacts of climate change and ensure our food production and farming techniques are sustainable, profitable and support long-term food security.</p>
<p>This investment provides a valuable boost to the sector. The UK is at the forefront of efforts to develop sustainable agricultural technologies and practices, in collaboration with our international partners.</p></blockquote>
<p>The Hon FranÃ§ois-Philippe Champagne, Minister of Innovation, Science and Industry, explained:</p>
<blockquote><p>The greener, cleaner economy of the future will have impacts across all sectors of our economy. The sustainable projects announced today are great examples of innovations that promise to make Canadaâ€™s agriculture industry more competitive. They will also sustain and create jobs, and support Canadaâ€™s transition to a low-carbon economy.</p></blockquote>
<p>Population growth and climate change are driving more sustainable agriculture practices in Canada and the UK, both of whom have significant strengths in both primary agriculture and precision agriculture technologies. Under a memoranda of understanding (MoUs), Innovate UK and NRC IRAP have supported over $30 million, or Â£20 million, of collaborative innovation projects.</p>
					
				<div class="clear-content govuk-!-padding-top-7">
		<div class="well govuk-!-padding-4">
			<h2>Further information</h2>
			<h3>About the Transforming Food Production challenge</h3>
<p>UKRIâ€™s Â£90 million Transforming Food Production programme is part of the Industrial Strategy Challenge Fund and aims to help the agricultural sector grow economically with less environmental impact.</p>
<p>The programme will set food production systems towards net-zero emissions by 2040 by producing food in ways that are more:</p>
<ul>
<li>efficient</li>
<li>resilient</li>
<li>sustainable.</li>
</ul>
<p>It will accelerate the development and adoption of integrated precision approaches to improve productivity in agricultural systems. The investment will be made over four years.</p>
<p>The programme will focus on the development, demonstration and adoption of data-driven systems and technologies to achieve:</p>
<ul>
<li>a better approach to agricultural production</li>
<li>reduce emissions.</li>
</ul>
<p>The remit includes both crop and farmed animal production, as well as, new production systems. The long-term success of the challenge is dependent on a diverse range of farm businesses adopting new technologies and approaches.</p>
<h3><strong>Additional Information on competition winners </strong></h3>
<p>The funding amount refers to the grant made to UK companies.</p>
<h4><strong>Arden Biotech (UK), partnered with TrustBIX Inc â€“ Â£247,846</strong></h4>
<p>Arden Biotechnology have developed a novel bacteriophage cocktail, a natural feed supplement (NFS) to:</p>
<ul>
<li>combat clostridium perfringens</li>
<li>enhance gut health</li>
<li>reduce the risk of necrotic enteritis.</li>
</ul>
<p>Through this collaborative 24-month industrial research project, Arden are seeking to extend the development of this technology to apply to the Canadian poultry and other livestock sectors in partnership with TrustBIX.</p>
<h4>Devenish (UK) partnered with Mara Renewables Corporation â€“ Â£384,216</h4>
<p>This projectâ€™s vision is to develop the next-generation of algae-derived products for use in poultry production in the UK, Canada, and other commercial markets worldwide, including:</p>
<ul>
<li>South America</li>
<li>Australasia</li>
<li>MENA.</li>
</ul>
<p>The key objective of the project is to develop a more sustainably produced, nutrient dense chicken that will provide a rich source of omega-3 oils in the human diet. Also, whilst enhancing the overall efficacy of poultry production. The project consortium envisages that the results of this technology will also be applicable to other areas of primary agriculture (for example aquaculture, pigs) and expand access to essential lipids in human diets globally.</p>
<p>Commercial on-farm studies, in the UK and Canada, will use a range of sensors and electronic (big) data to prove the validity of this innovative approach to poultry farming.</p>
<h4>Precision Decisions (UK) partnered with JCA Technologies â€“ Â£396,035</h4>
<p>This project proposes to use the strengths of each of the collaborating organisations in the development of an integrated, precision agriculture platform. One which can:</p>
<ul>
<li>provide seamless and real-time availability data from agricultural machine control applications</li>
<li>use this data for planning and analytics</li>
<li>deploy intelligent task direction to a fleet of machines.</li>
</ul>
<p>The system provides both after-market and original equipment manufacturer integrated solutions to address the mixed-fleet needs of farmers.</p>
<h4>Airborne Robotics &amp; ADAS (UK) partnered with SociÃ©tÃ© pour lâ€™information industrielle SII Inc. (SII Canada) â€“ Â£391,347</h4>
<p>Airborne Robotics will build a specialised unmanned aerial vehicle (UAV) prototype for the agricultural environment. ADAS will validate data from the UAV with in-field assessments of clubroot disease, and SII Canada will develop the algorithms necessary for machine learning for identification and diagnostics purposes.</p>
<p>The product and service enabled by this project will be an integrated, data driven clubroot management tool. This will combine UAV capability with on-farm software that optimises the long and short-term economics of clubroot management, based on remotely-sensed spatial data. The RootDetect smart tool will be competitively priced to ensure it is accessible to end users and maximise uptake of its use.</p>
<p>The RootDetect project will develop a semi-autonomous remote sensing tool that will efficiently scout large areas and â€˜seeâ€™ clubroot symptoms earlier than the grower or agronomist.</p>
<p>Affected areas in the field will then be mapped and linked to precision farming technology which will allow targeted treatment of infested patches. This will be cost effective for the grower and will minimise wastage and thus lower carbon emissions.</p>
<h4>RAFT Solutions Ltd, Atelerix, Ostara Biomedical Ltd &amp; Dyneval (UK) partnered with Bow Valley Genetics (Canada)Â â€“ Â£398,894</h4>
<p>Good fertility performance is the cornerstone of a profitable and sustainable livestock enterprise. In the international dairy and beef herd, optimum performance is achieved by maintaining a calving interval (CI) of 365 days. Every day CI increases \&gt;365 days is estimated to directly cost the farmer close to Â£2.07 or $3.54 per cow, or more for high yielding dairy cows.</p>
<p>Fertility drives productivity, and in turn the mitigation of greenhouse gas emissions, through reduced waste and optimising unproductive replacement youngstock inventories.</p>
<p>This project is supported by advisors at University of Saskatchewan and University of Guelph in Canada. As an integrated bilateral approach, it will:</p>
<ul>
<li>research and develop several innovative new technologies</li>
<li>establish national level referral facilities for quality assurance and improvement of bovine germplasm.</li>
</ul>
<p>The outputs of the project will transform genetic progress, through adoption of:</p>
<ul>
<li>precision technologies</li>
<li>diagnostics</li>
<li>advanced breeding</li>
<li>big data.</li>
</ul>
<p>This will lead to more sustainable livestock food production and export opportunities in both UK and Canada.</p>
<h4>CLARITY BIOSOLUTIONS (UK) partnered with Sona Nanotech (Canada) â€“ Â£299,736</h4>
<p>Tuberculosis (TB) is a bacterial infection that mainly affects the lungs, causing a general state of illness, coughing and eventually death. Bovine tuberculosis (bTB) is caused by a particular bacterium that affects cows but can be passed on to practically all mammals, including humans.</p>
<p>The usual route of infection is through the inhalation of infected droplets which are expelled from the lungs by coughing. Because the course of the disease is slow, an undetected cow can spread the disease to many others in a herd before it begins to show any visible signs of illness.</p>
<p>Unregulated movement of infected but undetected cows, along with contact with infected wild animals such as badgers, are the major ways that the disease is spread.</p>
<p>Critical to achieving the eradication of the disease is:</p>
<ul>
<li>accurate detection</li>
<li>herd management</li>
<li>movement control.</li>
</ul>
<p>The current test for bovine tuberculosis on farm herds is relatively subjective relying on individual veterinary practitioner interpretation. It is also not sensitive enough to detect all the cows that are infected therefore making eradication impossible.</p>
<p>bTB control measures cost over Â£500 million in the last 10 years. Without intervention, costs are expected to top Â£1 billion over the next decade if no new action is taken. A new, effective test is urgently needed.</p>
<p>This proposal would bring together an international consortium to lead the fight against tuberculosis in cattle.</p>
<p>The ambitious consortium has set out to do a project that will eliminate inaccurate test results frequently experienced by farming communities across the country but also worldwide. These â€œfalse negativeâ€ results lead to infected animals being missed, bringing enormous economic and emotional cost to:</p>
<ul>
<li>farmers</li>
<li>society</li>
<li>governments.</li>
</ul>
<p>This collaboration allies Aberystwythâ€™s world-leading biomarker research with:</p>
<ul>
<li>Lateral Flow Diagnostic (LFD) specialists, Clarity Biosolutions</li>
<li>life science businesses, Dynamic Extractions</li>
<li>software specialists, Bond Digital Health and Sona Nanotech in Canada</li>
<li>specialists in gold nanrod LFD technology.</li>
</ul>
<p>This builds a team of academic and industry experts because no single company can achieve this goal alone.</p>
<p>The project combines the latest cutting-edge science and technological developments with world-class research, state of the art facilities and expertise, to develop a new highly accurate, objective test to rapidly detect, manage, control and ultimately eradicate bTB.</p>
<h4>RS AQUA (UK) partnered with Innovasea Marine Systems Canada â€“ Â£103,807</h4>
<p>Aquaculture is an important industry for sustainable protein production. Atlantic salmon, are known for having one of the lowest feed conversion ratios of all protein sources.</p>
<p>Aquaculture producers are continuously looking for solutions to improve the health, welfare, and productivity of their stock, while further reducing environmental impact of farm activities. Harmful algal blooms (HABs), which can contribute to higher incidences of disease and elevated mortality on fish farms, currently pose a challenge to these goals.</p>
<p>Under certain environmental conditions, microscopic algae, or phytoplankton, populations can become very large and form blooms. Not all phytoplankton are harmful, but some species:</p>
<ul>
<li>produce harmful toxins</li>
<li>deplete dissolved oxygen in the water</li>
<li>have physical features that can damage fish gills, compromising their health.</li>
</ul>
<p>HABs are not only harmful to fish, but can also affect birds and mammals, including humans. A HAB near a salmon farm can cause major problems for fish health and welfare. This may result in high mortality, which is both economically and environmentally costly.</p>
<p>Global warming may have contributed to an overall increase in HAB frequency and farmers are increasingly concerned with their ability to detect and mitigate these threats.</p>
<p>HAB monitoring is part of the daily routine for many aquaculture farmers, who want to have the best possible tools at their disposal. This project is a collaborative effort between Innovasea and RS Aqua, and includes Grieg Seafood Shetland as an unfunded industry partner.</p>
<p>The team will develop an early warning system to notify fish farmers of potential and imminent HABs. By continuously monitoring the environmental conditions on and surrounding their farms, farmers will be informed when conditions that promote blooms are occurring in real-time. Thus, enabling them to respond quickly and take steps to reduce the impact of such events.</p>
<p>Such a system will have far-reaching impacts to the aquaculture industry and advance the methods of HAB monitoring, while increasing food production and reducing the carbon footprint of fish farming.</p>
		</div>
	</div>
						<div class="clear-content govuk-!-padding-top-5">
			<p class="govuk-body-s">Top image: Â Credit: ArtistGNDphotography / Getty Images</p>
		</div>
				<div class="share-this-page__container clear-content">
	<h2>Share this page</h2>
	<ul class="share-this-page__list">
		<li><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fwww.ukri.org%2Fnews%2F2-2-million-awarded-to-uk-agri-tech-firms-with-canadian-partners%2F&amp;title=%C2%A32.2+million+awarded+to+UK+agri-tech+firms+with+Canadian+partners" class="share-twitter"><span class="govuk-visually-hidden">Share this page on </span><span>Twitter</span></a></li>
		<li><a href="http://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fwww.ukri.org%2Fnews%2F2-2-million-awarded-to-uk-agri-tech-firms-with-canadian-partners%2F" class="share-linkedin"><span class="govuk-visually-hidden">Share this page on </span><span>LinkedIn</span></a></li>
		<li><a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.ukri.org%2Fnews%2F2-2-million-awarded-to-uk-agri-tech-firms-with-canadian-partners%2F" class="share-facebook"><span class="govuk-visually-hidden">Share this page on </span><span>Facebook</span></a></li>
	</ul>
</div>
		                    </div><!-- .entry-content -->
	</div><!-- #post -->
        </div>
        <aside class="govuk-grid-column-one-third-from-desktop ukri-sidebar">
            
<div class="ukri-email-signup__widget widget"><div class="ukri-email-signup"><h2 class="govuk-heading-m ukri-sidebar__title">Subscribe to UKRI emails</h2><p>Sign up for news, views, events and funding alerts.</p><form id="GD-snippet-form" action="https://public.govdelivery.com/accounts/UKRI/subscriber/qualify" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="âœ“"><input type="hidden" name="authenticity_token" value="+YhakBaKcGaLHAiEXHIrJZI7M21BsdXY4FCT0O65c3+v1fI18upE/geX9xnPumuqjMuPnpb9mqAFT0gZNB1PPA=="><label class="govuk-visually-hidden" for="email">Email address</label><input class="govuk-input ukri-email-signup__input" id="email" name="email" type="email" placeholder="Email address"><br><button class="govuk-button ukri-button--blue ukri-email-signup__button" data-module="govuk-button" id="analytics-newsletter-signup">Subscribe</button></form></div></div>
	<div class="widget featured-widget">
		<h2 class="govuk-heading-m ukri-sidebar__title">Subscribe to Innovate UK emails</h2>
		<p><a href="https://ukri.innovateuk.org/subscriptionpage?s=innovateuk">Sign up for the latest news, funding opportunities and ISCF updates</a>.</p>
	</div>
        </aside>
    </div>
</div>
    </main>

Title: ['Skip to main content', '\n                                    ', '\n                                ', 'Apply for funding', 'Manage your award', 'What we do', 'News and events', 'Who we are', 'Our councils', 'Apply for funding', 'Funding finder', 'How to apply for research and innovation funding', 'Studentships and doctoral training', 'How we make decisions', 'Improving your funding experience', 'Horizon Europe', 'Manage your award', 'Accept your offer', 'Getting your funding', 'UKRI terms and conditions', 'Request a change', 'Report your outcomes', 'Report your spending', 'Publish your findings', 'What we do', 'Browse our areas of investment and support', 'What weâ€™ve funded', 'International', 'Investing across the UK', 'Career development', 'Supporting collaboration', 'Infrastructure', 'Research culture', 'Artificial intelligence', 'Research financial sustainability', 'Public engagement', 'News and events', 'News', 'Blog', 'Events', 'Voices blog', '101 jobs that change the world', 'Who we are', 'About UK Research and Innovation', 'Our vision and strategy', 'How weâ€™re governed', 'Who we fund', 'How weâ€™re doing', 'How we engage', 'Policies, standards and data', 'Work for us: jobs and advisory roles', 'Contact us', 'Our councils', 'AHRC', 'BBSRC', 'ESRC', 'EPSRC', 'Innovate UK', 'MRC', 'NERC', 'Research England', 'STFC', 'Home', 'News', 'UK Research and Innovation (UKRI) Infrastructure Fund', 'felicity.perry@jic.ac.uk', 'feedback', 'help improve our online products and services']
URL: Top image: Â A computer-generated image of the Next Generation Infrastructure gardens and buildings. Credit: BDP, Secchi Smith
Content: <main class="govuk-main-wrapper ukri-main-content" id="main-content">

        <div class="govuk-width-container">
			<h1 class="govuk-heading-xl main-area__page-title" id="skipnav-target">UKRI confirms major investment in plant and microbial research hub</h1>
	<div class="govuk-grid-row">
        <div class="govuk-grid-column-two-thirds-from-desktop main-content-column">
          <div id="post-110578" class="post-110578 news type-news status-publish has-post-thumbnail hentry category-bbsrc category-ukri">
    <div class="entry-header">
		<div class="ukri-post-image-holder">
			<img width="735" height="490" src="https://www.ukri.org/wp-content/uploads/2023/06/BBSRC-07062023-CGI_Gardens-and-Buildings_JIC_TSL_NGI-Credit-BDP-Secchi-Smith-1-735x490.jpg" class="attachment-large size-large wp-post-image" alt="A computer-generated image of the Next Generation Infrastructure gardens and buildings" decoding="async" fetchpriority="high" srcset="https://www.ukri.org/wp-content/uploads/2023/06/BBSRC-07062023-CGI_Gardens-and-Buildings_JIC_TSL_NGI-Credit-BDP-Secchi-Smith-1-735x490.jpg 735w, https://www.ukri.org/wp-content/uploads/2023/06/BBSRC-07062023-CGI_Gardens-and-Buildings_JIC_TSL_NGI-Credit-BDP-Secchi-Smith-1-300x200.jpg 300w, https://www.ukri.org/wp-content/uploads/2023/06/BBSRC-07062023-CGI_Gardens-and-Buildings_JIC_TSL_NGI-Credit-BDP-Secchi-Smith-1-750x500.jpg 750w, https://www.ukri.org/wp-content/uploads/2023/06/BBSRC-07062023-CGI_Gardens-and-Buildings_JIC_TSL_NGI-Credit-BDP-Secchi-Smith-1-510x340.jpg 510w, https://www.ukri.org/wp-content/uploads/2023/06/BBSRC-07062023-CGI_Gardens-and-Buildings_JIC_TSL_NGI-Credit-BDP-Secchi-Smith-1-360x240.jpg 360w, https://www.ukri.org/wp-content/uploads/2023/06/BBSRC-07062023-CGI_Gardens-and-Buildings_JIC_TSL_NGI-Credit-BDP-Secchi-Smith-1.jpg 1500w" sizes="(min-width: 1200px) 735px, (min-width: 769px) calc((((100vw - 30px) / 3) * 2) - 45px), calc(100vw - 30px)">					</div>
        
<p class="govuk-body-s post-summary__date govuk-!-padding-top-3"><time datetime="2023-06-08">8 June 2023</time></p>					<p class="govuk-body-l">UKRI is set to invest more than Â£317 million in a ground-breaking plant and microbial science and innovation hub at the heart of Norwich Research Park.</p>
	    </div>

    <div class="entry-content">
        <p>The transformational investment will aid the development of new cutting-edge, world-class facilities for the John Innes Centre (JIC) and The Sainsbury Laboratory (TSL).</p>
<p>As well as transforming the existing capabilities of JIC and TSL, both internationally recognised centres of excellence in plant and microbial science, the new hub aims to become a net zero carbon laboratory.</p>
<p>It will deliver a step change in the UKâ€™s capability to translate scientific knowledge into bio-based solutions in response to some of societyâ€™s most pressing challenges.</p>
<p>The hub will play a pivotal role in:</p>
<ul>
<li>reducing the impact of climate change</li>
<li>providing long-term sustainable food solutions</li>
<li>improving human health</li>
<li>enhancing growth and economic prosperity across the UK and beyond</li>
</ul>
<h2>Next generation infrastructure</h2>
<p>The JIC and TSL Next Generation Infrastructure programme is funded by the <a href="/what-we-offer/creating-world-class-research-and-innovation-infrastructure/">UK Research and Innovation (UKRI) Infrastructure Fund</a>, which invests in the facilities, equipment and resources that are essential for researchers and innovators to do ground-breaking work.</p>
<p>The programme will develop the Norwich-based site over the next seven years, with Â£54.7 million being invested over the first three years and a total investment of Â£317.7 million from the fund.</p>
<p>Construction of the new hub is expected to be complete by 2030.</p>
<h2>Strengthening UK bioscience</h2>
<p>Professor Melanie Welham, Executive Chair of the Biotechnology and Biological Sciences Research Council (BBSRC), said:</p>
<blockquote><p>Providing access to cutting-edge, sustainable research and innovation infrastructure is mission-critical to the competitiveness and long-term success of UK bioscience.</p>
<p>UKRIâ€™s investment in the John Innes Centre and The Sainsbury Laboratory Next Generation Infrastructure provides an important opportunity to further improve our local connections with key partners at Norwich Research Park, the likes of which include Earlham Institute and Quadram Institute.</p>
<p>Beyond that, the investment also represents a real opportunity to establish a world-leading global interdisciplinary hub for plant and microbial sciences that will help deliver the bio-based solutions needed to address global challenges around sustainable agriculture, food, nutrition and health.</p></blockquote>
<h2>The power of plant and microbial science</h2>
<p>Professor Graham Moore, Director of JIC, said:</p>
<blockquote><p>Securing this funding is a major step forward in realising our vision to improve collaborative working across the UK and overseas, helping us to provide a safer, healthier and more sustainable future through the power of plant and microbial science.</p>
<p>As well as new laboratories, the investment includes a redevelopment of our plant growth facilities, which in conjunction with our existing field station, will improve our ability to study the effects of climate change.</p></blockquote>
<h2>Transforming global agriculture</h2>
<p>Professor Nick Talbot FRS, Executive Director of TSL, said:</p>
<blockquote><p>This transformational investment exemplifies the UKâ€™s confidence in the future of our research institutes and their ability to transform global agriculture through innovation. It is imperative that agricultural production is transformed to become a net carbon zero activity that no longer relies on fossil fuels.</p>
<p>The investment from UKRI will enable us to harness the collaborative environment on the Norwich Research Park, catalysing new research initiatives and creating a unique asset for UK science and innovation.</p></blockquote>
<h2>Enabling an ambitious vision</h2>
<p>The investment by UKRI will enable the realisation of an ambitious longer-term vision for JIC and TSL.</p>
<p>Healthy Plants, Healthy People, Healthy Planet (HP3) seeks to provide a safer, healthier and more sustainable future through the power of plant and microbial science.</p>
<p>This bold vision represents a revolution in plant and microbial sciences that strives to reach new levels of understanding by integrating advances in:</p>
<ul>
<li>computational biology</li>
<li>genetics</li>
<li>genomics</li>
<li>live cell imaging</li>
<li>structural biology</li>
</ul>
<h2>Collaborating for success</h2>
<p>A fundraising campaign is currently underway at JIC and TSL to secure a further Â£30 million investment to support the full cost of the Next Generation Infrastructure programme and longer-term HP3 vision.</p>
<p>To date, the campaign has garnered generous contributions from:</p>
<ul>
<li>Garfield Weston Foundation</li>
<li>Gatsby Charitable Foundation</li>
<li>John Innes Foundation</li>
<li>The Wolfson Foundation</li>
<li>University of East Anglia</li>
</ul>
<p>Visit the HP3 website to find out more about JIC and TSLâ€™s vision to build a more sustainable future through the power of plant and microbial science or contact Felicity Perry at <a href="mailto:felicity.perry@jic.ac.uk">felicity.perry@jic.ac.uk</a></p>
					
									<div class="clear-content govuk-!-padding-top-5">
			<p class="govuk-body-s">Top image: Â A computer-generated image of the Next Generation Infrastructure gardens and buildings. Credit: BDP, Secchi Smith</p>
		</div>
				<div class="share-this-page__container clear-content">
	<h2>Share this page</h2>
	<ul class="share-this-page__list">
		<li><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fwww.ukri.org%2Fnews%2Fukri-confirms-major-investment-in-plant-and-microbial-research-hub%2F&amp;title=UKRI+confirms+major+investment+in+plant+and+microbial+research+hub" class="share-twitter"><span class="govuk-visually-hidden">Share this page on </span><span>Twitter</span></a></li>
		<li><a href="http://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fwww.ukri.org%2Fnews%2Fukri-confirms-major-investment-in-plant-and-microbial-research-hub%2F" class="share-linkedin"><span class="govuk-visually-hidden">Share this page on </span><span>LinkedIn</span></a></li>
		<li><a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.ukri.org%2Fnews%2Fukri-confirms-major-investment-in-plant-and-microbial-research-hub%2F" class="share-facebook"><span class="govuk-visually-hidden">Share this page on </span><span>Facebook</span></a></li>
	</ul>
</div>
		                    </div><!-- .entry-content -->
	</div><!-- #post -->
        </div>
        <aside class="govuk-grid-column-one-third-from-desktop ukri-sidebar">
            	<div class="widget related-content">
		<h2 class="govuk-heading-m ukri-sidebar__title">Related content</h2>
		<ul>
						<li><a class="ukri-sidebar__link ukri-related-content__link" href="/what-we-offer/creating-world-class-research-and-innovation-infrastructure/"><span>Creating world-class research and innovation infrastructure</span></a></li>
									<li><a class="ukri-sidebar__link ukri-related-content__link" href="/what-we-offer/creating-world-class-research-and-innovation-infrastructure/funded-infrastructure-projects/"><span>Infrastructure Fund projects</span></a></li>
							</ul>
	</div>

<div class="ukri-email-signup__widget widget"><div class="ukri-email-signup"><h2 class="govuk-heading-m ukri-sidebar__title">Subscribe to UKRI emails</h2><p>Sign up for news, views, events and funding alerts.</p><form id="GD-snippet-form" action="https://public.govdelivery.com/accounts/UKRI/subscriber/qualify" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="âœ“"><input type="hidden" name="authenticity_token" value="+YhakBaKcGaLHAiEXHIrJZI7M21BsdXY4FCT0O65c3+v1fI18upE/geX9xnPumuqjMuPnpb9mqAFT0gZNB1PPA=="><label class="govuk-visually-hidden" for="email">Email address</label><input class="govuk-input ukri-email-signup__input" id="email" name="email" type="email" placeholder="Email address"><br><button class="govuk-button ukri-button--blue ukri-email-signup__button" data-module="govuk-button" id="analytics-newsletter-signup">Subscribe</button></form></div></div>
        </aside>
    </div>
</div>
    </main>

Title: ['Skip to main content', '\n                                    ', '\n                                ', 'Apply for funding', 'Manage your award', 'What we do', 'News and events', 'Who we are', 'Our councils', 'Apply for funding', 'Funding finder', 'How to apply for research and innovation funding', 'Studentships and doctoral training', 'How we make decisions', 'Improving your funding experience', 'Horizon Europe', 'Manage your award', 'Accept your offer', 'Getting your funding', 'UKRI terms and conditions', 'Request a change', 'Report your outcomes', 'Report your spending', 'Publish your findings', 'What we do', 'Browse our areas of investment and support', 'What weâ€™ve funded', 'International', 'Investing across the UK', 'Career development', 'Supporting collaboration', 'Infrastructure', 'Research culture', 'Artificial intelligence', 'Research financial sustainability', 'Public engagement', 'News and events', 'News', 'Blog', 'Events', 'Voices blog', '101 jobs that change the world', 'Who we are', 'About UK Research and Innovation', 'Our vision and strategy', 'How weâ€™re governed', 'Who we fund', 'How weâ€™re doing', 'How we engage', 'Policies, standards and data', 'Work for us: jobs and advisory roles', 'Contact us', 'Our councils', 'AHRC', 'BBSRC', 'ESRC', 'EPSRC', 'Innovate UK', 'MRC', 'NERC', 'Research England', 'STFC', 'Home', 'What we do', 'What weâ€™ve funded', 'What Research England has funded', 'feedback', 'help improve our online products and services']
URL: 

Content: <main class="govuk-main-wrapper ukri-main-content" id="main-content">

        
<div class="govuk-width-container">
		<h1 class="govuk-heading-xl main-area__page-title" id="skipnav-target">International Investment Initiative (I3) funding decisions</h1>    <div class="govuk-grid-row">
        <div class="govuk-grid-column-two-thirds-from-desktop main-content-column">
        	<div id="post-36318" class="post-36318 page type-page status-publish hentry category-research-england">
    <div class="entry-header">
		<div class="ukri-post-image-holder">
								</div>
        
		    </div>

    <div class="entry-content">
        <p>Research England awarded a total of Â£3.6 million to eight higher education providers (HEPs) through a competitive scheme.</p>
<p>Awards are allocated over up to five years and must be led by an English HEP with a minimum of one international university or research organisation as a partner.</p>
<p>Eight bids received funding from the i3 fund.</p>
<h2>Brunel University London</h2>
<h3>Bid title</h3>
<p>UK and Finland: Research Collaboration for Prosperity and Health</p>
<h3>Partner</h3>
<p>Tampere University (Finland)</p>
<h3>Investment</h3>
<p>Â£343,918</p>
<h3>Summary</h3>
<p>The award will accelerate the development of a strategic partnership between Brunel and Tampere University in Materials &amp; Manufacturing, Biomedical Engineering, Structural Integrity, Digital Technology, Water Resources and Ageing &amp; Wellness. It will deliver benefits to the UK and Finland in the form of research competitiveness, societal impact and innovation.</p>
<h2>Imperial College London</h2>
<h3>Bid title</h3>
<p>Data 4.0: leading the fourth industrial revolution with data-driven technologies</p>
<h3>Partners</h3>
<p>Centre National de la Recherche Scientifique (CNRS, France)<br>
Technical University of Munich (Germany)<br>
Nanyang Technological University (Singapore)</p>
<h3>Investment</h3>
<p>Â£500,000</p>
<h3>Summary</h3>
<p>Imperial will establish Data 4.0 clusters in: Mathematical sciences, with Franceâ€™s CNRS; AI and robotics, with Germanyâ€™s Technical University of Munich; Technology and healthcare, with Singaporeâ€™s Nanyang Technological University. Each cluster will develop flagship international studentships, expand academic exchange, accelerate frontier research with seed funding, and launch bespoke doctoral programmes.</p>
<h2>Liverpool John Moores University</h2>
<h3>Bid title</h3>
<p>i-CARDIO â€“ International Collaboration Assessing novel health models: A Research Design Intervention Opportunity</p>
<h3>Partner</h3>
<p>University of Western Australia (Australia)</p>
<h3>Investment</h3>
<p>Â£488,829</p>
<h3>Summary</h3>
<p>The UK faces a growing crisis of physical inactivity and associated disease risk. In Australia â€œregistered exercise professionalsâ€ support the healthcare system and have reduced healthcare costs. This system does not exist in the UK, and this award will evaluate healthcare model development in Australia and pathways to changes in the UK.</p>
<h2>Loughborough University</h2>
<h3>Bid title</h3>
<p>An International Research Centre to study the effects of Connected and Autonomous Vehicles on Vulnerable Road-Users</p>
<h3>Partners</h3>
<p>Queensland University of Technology (QUT, Australia)<br>
Tongji University (China)</p>
<h3>Investment</h3>
<p>Â£436,067</p>
<h3>Summary</h3>
<p>This project will scale up an existing strategic, international collaboration between three world-leading research centres â€“ Loughborough University (UK), Queensland University of Technology (Australia), and Tongji University (China). It will establish a new International Research Centre to study the impacts of connected and autonomous vehicles on vulnerable road usersâ€™ safety.</p>
<h2>Newcastle University</h2>
<h3>Bid title</h3>
<p>Newcastle University/Monash Academic Track (NUMAcT) scheme</p>
<h3>Partner</h3>
<p>Monash University (Australia)</p>
<h3>Investment</h3>
<p>Â£500,000</p>
<h3>Summary</h3>
<p>Building on the recently launched and extremely popular NUAcT scheme supporting researchers making the transition to independence, NUMAcT will allow investigators to work in two long-standing partner universities, Newcastle and Monash. The initial focus on drug discovery provides complementary access to world-class facilities, expertise, and bespoke training and mentorship.</p>
<h2>University of Birmingham</h2>
<h3>Bid title</h3>
<p>Industrialisation of Energy, Waste and Recycling</p>
<h3>Partners</h3>
<p>Fraunhofer Institute for Environmental Safety and Energy Technology (UMSICHT, Germany)<br>
Jiangsu Industrial Technology Research Institute (JITRI, China)</p>
<h3>Investment</h3>
<p>Â£499,099</p>
<h3>Summary</h3>
<p>Investment of Â£2.6 million, made up of nearly Â£0.5 million from Research England, and Â£2.1 million co-investment, over five years will scale up the partnerships between the University of Birmingham, Fraunhofer Institute for Environmental, Safety, and Energy Technology, and Jiangsu Industry Technology Research Institute. This three-way multi-country bridge will provide a comprehensive research and innovation pipeline from fundamental research to close-to-market innovation.</p>
<h2>University of Brighton</h2>
<h3>Bid title</h3>
<p>3DMed â€“ Anglo Canadian Collaboration on Interface Science for Medical Innovation</p>
<h3>Partner</h3>
<p>York University (Canada)</p>
<h3>Investment</h3>
<p>Â£455,080</p>
<h3>Summary</h3>
<p>3DMed scales up a well-established strategic collaboration between University of Brighton, UK and York University, Canada. The project will capitalise on the synergy between programmes of excellent research in engineering and biomedicine to develop industrial applications and novel research skills in 3D bio-printing and additive biomedical manufacturing technologies.</p>
<h2>University of Hull</h2>
<h3>Bid title</h3>
<p>Building Critical Mass for Palliative Care Research through Collaborative Support, Exchange and Challenge</p>
<h3>Partner</h3>
<p>University of Technology Sydney (Australia)</p>
<h3>Investment</h3>
<p>Â£403,510</p>
<h3>Summary</h3>
<p>This award will increase the scale and impact of our international collaboration between the Wolfson Palliative Care Research Centre, University of Hull, and the Improving Palliative and Chronic Care Through Clinical Research and Translation group, University Technology Sydney, forming critical mass to drive societal benefit through high-quality palliative care research.</p>
									                    <p class="last-updated">Last updated: 31 March 2022</p>
                    </div><!-- .entry-content -->
	</div><!-- #post -->
        </div>
        <aside class="govuk-grid-column-one-third-from-desktop ukri-sidebar">
            

        </aside>
    </div>
</div>
    </main>

Title: ['Skip to main content', '\n                                    ', '\n                                ', 'Apply for funding', 'Manage your award', 'What we do', 'News and events', 'Who we are', 'Our councils', 'Apply for funding', 'Funding finder', 'How to apply for research and innovation funding', 'Studentships and doctoral training', 'How we make decisions', 'Improving your funding experience', 'Horizon Europe', 'Manage your award', 'Accept your offer', 'Getting your funding', 'UKRI terms and conditions', 'Request a change', 'Report your outcomes', 'Report your spending', 'Publish your findings', 'What we do', 'Browse our areas of investment and support', 'What weâ€™ve funded', 'International', 'Investing across the UK', 'Career development', 'Supporting collaboration', 'Infrastructure', 'Research culture', 'Artificial intelligence', 'Research financial sustainability', 'Public engagement', 'News and events', 'News', 'Blog', 'Events', 'Voices blog', '101 jobs that change the world', 'Who we are', 'About UK Research and Innovation', 'Our vision and strategy', 'How weâ€™re governed', 'Who we fund', 'How weâ€™re doing', 'How we engage', 'Policies, standards and data', 'Work for us: jobs and advisory roles', 'Contact us', 'Our councils', 'AHRC', 'BBSRC', 'ESRC', 'EPSRC', 'Innovate UK', 'MRC', 'NERC', 'Research England', 'STFC', 'Innovate UK', 'full opportunity details on the Innovation Funding Service', 'micro, small or medium-sized enterprises (SME)', 'Print this guidance or save as PDF', 'feedback', 'help improve our online products and services']
URL: 

Content: <main class="govuk-main-wrapper ukri-main-content" id="main-content">

        <div class="govuk-width-container">
	<div class="content-badge">Funding opportunity</div>
	<h1 class="govuk-heading-xl main-area__page-title" id="skipnav-target"><span class="govuk-visually-hidden">Funding opportunity: </span>Canada-UK: Biomanufacturing of Biologics and Advanced Therapies round 2</h1>
    <div class="govuk-grid-row">
                <div class="govuk-grid-column-two-thirds-from-desktop single-opportunity__content-container main-content-column">
      			<div class="entry-header">
        				<div class="entry-meta single-opportunity__entry-meta">
          					
<dl class="govuk-table opportunity__summary">
  <div class="govuk-table__row">
    <dt class="govuk-table__header opportunity-cells">Opportunity status: </dt>
    <dd class="govuk-table__cell opportunity-cells"><span class="open opportunity-status__flag">Open</span></dd>
  </div>
  <div class="govuk-table__row">
    <dt class="govuk-table__header opportunity-cells">Funders: </dt>
    <dd class="govuk-table__cell opportunity-cells">
	<a class="ukri-funder__link" href="https://www.ukri.org/councils/innovate-uk/">Innovate UK</a>	</dd>
  </div>
      <div class="govuk-table__row">
      <dt class="govuk-table__header opportunity-cells">Co-funders: </dt>
	  <dd class="govuk-table__cell opportunity-cells">National Research Council of Canada Industrial Research Assistance Program (NRC IRAP)</dd>
	</div>
    <div class="govuk-table__row">
    <dt class="govuk-table__header opportunity-cells">Funding type: </dt>
	<dd class="govuk-table__cell opportunity-cells">Grant</dd>
  </div>
      <div class="govuk-table__row">
    <dt class="govuk-table__header opportunity-cells">Publication date: </dt>
	<dd class="govuk-table__cell opportunity-cells">7 May 2024</dd>
  </div>
  <div class="govuk-table__row">
    <dt class="govuk-table__header opportunity-cells">Opening date: </dt>
	<dd class="govuk-table__cell opportunity-cells">
	<time datetime="2024-05-08T09:30:00">8 May 2024 9:30am UK time</time>	</dd>
  </div>
  <div class="govuk-table__row">
    <dt class="govuk-table__header opportunity-cells">Closing date: </dt>
	<dd class="govuk-table__cell opportunity-cells">
	<time datetime="2024-10-16T11:00:00">16 October 2024 11:00am UK time</time>	</dd>
  </div>
</dl>
														<div class="clearfix"></div>
        				</div>
                            </div><!-- .entry-header -->

            <div class="entry-content single-opportunity__entry-content">
                <div class="description">
                    <div class="ukri-callout-box">
<p>See the <a href="https://apply-for-innovation-funding.service.gov.uk/competition/1948/overview/111fa136-3248-48d8-afdc-0f9ad353fbbf">full opportunity details on the Innovation Funding Service</a>.</p>
</div>
<p>UK registered organisations can apply for a share of up to Â£3 million for collaboration with Canadian <a href="https://www.gov.uk/government/publications/life-of-a-company-annual-requirements/life-of-a-company-part-1-accounts#micro-entity">micro, small or medium-sized enterprises (SME)</a> on joint R&amp;D projects, for enabling technologies and innovations in biomanufacturing of biologics and advanced therapies.</p>
<h2>Eligibility summary</h2>
<p>This competition is open to Canada and UK collaborations only.</p>
<p>To lead a project your organisation must:</p>
<ul>
<li>be a UK-registered business of any size</li>
<li>be or involve at least one grant claiming UK-registered SMEs</li>
<li>collaborate with a Canadian SME, which must be a separate non-linked entity to the UK project partners</li>
</ul>
<p>or</p>
<ul>
<li>be a Canadian SME</li>
<li>partner with at least one grant claiming UK-registered SME</li>
</ul>
                </div>
            </div><!-- .entry-content -->

            			
			      	</div><!-- #content -->

        <aside class="govuk-grid-column-one-third-from-desktop ukri-sidebar">
            
<div class="widget ukri-document__widget ukri-print__widget">
    <h2 class="govuk-visually-hidden">Print and download options</h2>
    <ul class="govuk-list ukri-document-list">
        <li class="ukri-document-list__item">
            <span class="ukri-document__icon">
            <svg id="Capa_1" data-name="Capa 1" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 20 15.65" width="20" height="15.65"><title>icon-printer</title><style type="text/css">.st0{fill:#FFFFFF;}</style><path class="st0" d="M0,11.3a4.34,4.34,0,0,0,3.48,4.26V11.74h13v3.82A4.34,4.34,0,0,0,20,11.3V6.52H0ZM3.91,9.13H16.09a.44.44,0,0,1,0,.87H3.91a.44.44,0,0,1,0-.87Z"></path><rect class="st0" x="4.35" y="12.61" width="11.3" height="3.04"></rect><rect class="st0" x="3.91" width="12.17" height="5.65"></rect></svg>
            </span>
            <a class="govuk-link" href="javascript:window.print()" id="analytics-opportunity-print">Print this guidance or save as PDF</a>
        </li>
    </ul>
</div>

<div class="widget good-research">
	<h2 class="govuk-heading-m ukri-sidebar__title">Guidance on good research</h2>
	<div class="textwidget">
		<ul>
			<li><a class="ukri-sidebar__link ukri-good-research__link" href="/about-us/policies-standards-and-data/good-research-resource-hub/"><span>Good research resource hub</span></a></li>
		</ul>
	</div>
</div>




<div class="ukri-email-signup__widget widget"><div class="ukri-email-signup"><h2 class="govuk-heading-m ukri-sidebar__title">Subscribe to UKRI emails</h2><p>Sign up for news, views, events and funding alerts.</p><form id="GD-snippet-form" action="https://public.govdelivery.com/accounts/UKRI/subscriber/qualify" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="âœ“"><input type="hidden" name="authenticity_token" value="+YhakBaKcGaLHAiEXHIrJZI7M21BsdXY4FCT0O65c3+v1fI18upE/geX9xnPumuqjMuPnpb9mqAFT0gZNB1PPA=="><label class="govuk-visually-hidden" for="email">Email address</label><input class="govuk-input ukri-email-signup__input" id="email" name="email" type="email" placeholder="Email address"><br><button class="govuk-button ukri-button--blue ukri-email-signup__button" data-module="govuk-button" id="analytics-newsletter-signup">Subscribe</button></form></div></div>        </aside>
            </div><!-- #primary -->
</div>
    </main>

Title: ['Skip to main content', '\n                                    ', '\n                                ', 'Apply for funding', 'Manage your award', 'What we do', 'News and events', 'Who we are', 'Our councils', 'Apply for funding', 'Funding finder', 'How to apply for research and innovation funding', 'Studentships and doctoral training', 'How we make decisions', 'Improving your funding experience', 'Horizon Europe', 'Manage your award', 'Accept your offer', 'Getting your funding', 'UKRI terms and conditions', 'Request a change', 'Report your outcomes', 'Report your spending', 'Publish your findings', 'What we do', 'Browse our areas of investment and support', 'What weâ€™ve funded', 'International', 'Investing across the UK', 'Career development', 'Supporting collaboration', 'Infrastructure', 'Research culture', 'Artificial intelligence', 'Research financial sustainability', 'Public engagement', 'News and events', 'News', 'Blog', 'Events', 'Voices blog', '101 jobs that change the world', 'Who we are', 'About UK Research and Innovation', 'Our vision and strategy', 'How weâ€™re governed', 'Who we fund', 'How weâ€™re doing', 'How we engage', 'Policies, standards and data', 'Work for us: jobs and advisory roles', 'Contact us', 'Our councils', 'AHRC', 'BBSRC', 'ESRC', 'EPSRC', 'Innovate UK', 'MRC', 'NERC', 'Research England', 'STFC', 'Innovate UK', 'UK and Canada biomanufacturing innovations in cell and gene therapies', 'Print this guidance or save as PDF', 'feedback', 'help improve our online products and services']
URL: 

Content: <main class="govuk-main-wrapper ukri-main-content" id="main-content">

        <div class="govuk-width-container">
	<div class="content-badge">Funding opportunity</div>
	<h1 class="govuk-heading-xl main-area__page-title" id="skipnav-target"><span class="govuk-visually-hidden">Funding opportunity: </span>UK and Canada biomanufacturing innovations in cell and gene therapies</h1>
    <div class="govuk-grid-row">
                <div class="govuk-grid-column-two-thirds-from-desktop single-opportunity__content-container main-content-column">
      			<div class="entry-header">
        				<div class="entry-meta single-opportunity__entry-meta">
          					
<dl class="govuk-table opportunity__summary">
  <div class="govuk-table__row">
    <dt class="govuk-table__header opportunity-cells">Opportunity status: </dt>
    <dd class="govuk-table__cell opportunity-cells"><span class="closed opportunity-status__flag">Closed</span></dd>
  </div>
  <div class="govuk-table__row">
    <dt class="govuk-table__header opportunity-cells">Funders: </dt>
    <dd class="govuk-table__cell opportunity-cells">
	<a class="ukri-funder__link" href="https://www.ukri.org/councils/innovate-uk/">Innovate UK</a>	</dd>
  </div>
    <div class="govuk-table__row">
    <dt class="govuk-table__header opportunity-cells">Funding type: </dt>
	<dd class="govuk-table__cell opportunity-cells">Grant</dd>
  </div>
      <div class="govuk-table__row">
    <dt class="govuk-table__header opportunity-cells">Publication date: </dt>
	<dd class="govuk-table__cell opportunity-cells">26 October 2020</dd>
  </div>
  <div class="govuk-table__row">
    <dt class="govuk-table__header opportunity-cells">Opening date: </dt>
	<dd class="govuk-table__cell opportunity-cells">
	<time datetime="2020-10-26T00:00:00">26 October 2020</time>	</dd>
  </div>
  <div class="govuk-table__row">
    <dt class="govuk-table__header opportunity-cells">Closing date: </dt>
	<dd class="govuk-table__cell opportunity-cells">
	<time datetime="2020-12-23T11:00:00">23 December 2020 11:00am UK time</time>	</dd>
  </div>
</dl>
														<div class="clearfix"></div>
        				</div>
                            </div><!-- .entry-header -->

            <div class="entry-content single-opportunity__entry-content">
                <div class="description">
                    <p>A collaborative opportunity with the National Research Council of Canada on process improvement in biomanufacturing of gene and cell therapies</p>
<h2>Eligibility</h2>
<p>This competition is open to single applicants and collaborations.</p>
<p>To lead a project or work alone your organisation must be either a:</p>
<ul>
<li>UK registered micro, small or medium sized enterprise (SME)</li>
<li>catapult</li>
<li>charity</li>
<li>not for profit organisation</li>
</ul>
<p>You must collaborate with a research team from the National Research Council of Canada (NRC).</p>
<div class="ukri-callout-box">
<p>Please note, this funding opportunity is hosted on the Innovation Funding Service. Read full details:Â <a class="govuk-link" href="https://apply-for-innovation-funding.service.gov.uk/competition/751/overview">UK and Canada biomanufacturing innovations in cell and gene therapies</a></p>
</div>
                </div>
            </div><!-- .entry-content -->

            			
			      	</div><!-- #content -->

        <aside class="govuk-grid-column-one-third-from-desktop ukri-sidebar">
                <section class="timeline">
        <h2 class="govuk-heading-l ukri-section-title">Timeline</h2>
        <dl class="ukri-timeline">
                            <div class="ukri-timeline__item">
					<dt class="ukri-timeline__date">
						14 October 2020					</dt>
					<dd class="ukri-timeline__title">Online information session</dd>
                </div>
                            <div class="ukri-timeline__item">
					<dt class="ukri-timeline__date">
						26 October 2020					</dt>
					<dd class="ukri-timeline__title">Competition opens</dd>
                </div>
                            <div class="ukri-timeline__item">
					<dt class="ukri-timeline__date">
						3 November 2020					</dt>
					<dd class="ukri-timeline__title">Online information session</dd>
                </div>
                            <div class="ukri-timeline__item">
					<dt class="ukri-timeline__date">
						23 December 2020 11:00am					</dt>
					<dd class="ukri-timeline__title">Competition closes</dd>
                </div>
                            <div class="ukri-timeline__item">
					<dt class="ukri-timeline__date">
						2 February 2021					</dt>
					<dd class="ukri-timeline__title">Invite to interview</dd>
                </div>
                            <div class="ukri-timeline__item">
					<dt class="ukri-timeline__date">
						15 February 2021					</dt>
					<dd class="ukri-timeline__title">Interview panel</dd>
                </div>
                            <div class="ukri-timeline__item">
					<dt class="ukri-timeline__date">
						26 February 2021					</dt>
					<dd class="ukri-timeline__title">Applicants notified</dd>
                </div>
                    </dl>
    </section>

<div class="widget ukri-document__widget ukri-print__widget">
    <h2 class="govuk-visually-hidden">Print and download options</h2>
    <ul class="govuk-list ukri-document-list">
        <li class="ukri-document-list__item">
            <span class="ukri-document__icon">
            <svg id="Capa_1" data-name="Capa 1" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 20 15.65" width="20" height="15.65"><title>icon-printer</title><style type="text/css">.st0{fill:#FFFFFF;}</style><path class="st0" d="M0,11.3a4.34,4.34,0,0,0,3.48,4.26V11.74h13v3.82A4.34,4.34,0,0,0,20,11.3V6.52H0ZM3.91,9.13H16.09a.44.44,0,0,1,0,.87H3.91a.44.44,0,0,1,0-.87Z"></path><rect class="st0" x="4.35" y="12.61" width="11.3" height="3.04"></rect><rect class="st0" x="3.91" width="12.17" height="5.65"></rect></svg>
            </span>
            <a class="govuk-link" href="javascript:window.print()" id="analytics-opportunity-print">Print this guidance or save as PDF</a>
        </li>
    </ul>
</div>

<div class="widget good-research">
	<h2 class="govuk-heading-m ukri-sidebar__title">Guidance on good research</h2>
	<div class="textwidget">
		<ul>
			<li><a class="ukri-sidebar__link ukri-good-research__link" href="/about-us/policies-standards-and-data/good-research-resource-hub/"><span>Good research resource hub</span></a></li>
		</ul>
	</div>
</div>




<div class="ukri-email-signup__widget widget"><div class="ukri-email-signup"><h2 class="govuk-heading-m ukri-sidebar__title">Subscribe to UKRI emails</h2><p>Sign up for news, views, events and funding alerts.</p><form id="GD-snippet-form" action="https://public.govdelivery.com/accounts/UKRI/subscriber/qualify" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="âœ“"><input type="hidden" name="authenticity_token" value="+YhakBaKcGaLHAiEXHIrJZI7M21BsdXY4FCT0O65c3+v1fI18upE/geX9xnPumuqjMuPnpb9mqAFT0gZNB1PPA=="><label class="govuk-visually-hidden" for="email">Email address</label><input class="govuk-input ukri-email-signup__input" id="email" name="email" type="email" placeholder="Email address"><br><button class="govuk-button ukri-button--blue ukri-email-signup__button" data-module="govuk-button" id="analytics-newsletter-signup">Subscribe</button></form></div></div>        </aside>
            </div><!-- #primary -->
</div>
    </main>

Title: ['Skip to main content', '\n                                    ', '\n                                ', 'Apply for funding', 'Manage your award', 'What we do', 'News and events', 'Who we are', 'Our councils', 'Apply for funding', 'Funding finder', 'How to apply for research and innovation funding', 'Studentships and doctoral training', 'How we make decisions', 'Improving your funding experience', 'Horizon Europe', 'Manage your award', 'Accept your offer', 'Getting your funding', 'UKRI terms and conditions', 'Request a change', 'Report your outcomes', 'Report your spending', 'Publish your findings', 'What we do', 'Browse our areas of investment and support', 'What weâ€™ve funded', 'International', 'Investing across the UK', 'Career development', 'Supporting collaboration', 'Infrastructure', 'Research culture', 'Artificial intelligence', 'Research financial sustainability', 'Public engagement', 'News and events', 'News', 'Blog', 'Events', 'Voices blog', '101 jobs that change the world', 'Who we are', 'About UK Research and Innovation', 'Our vision and strategy', 'How weâ€™re governed', 'Who we fund', 'How weâ€™re doing', 'How we engage', 'Policies, standards and data', 'Work for us: jobs and advisory roles', 'Contact us', 'Our councils', 'AHRC', 'BBSRC', 'ESRC', 'EPSRC', 'Innovate UK', 'MRC', 'NERC', 'Research England', 'STFC', 'Innovate UK', 'full opportunity details on the Innovation Funding Service', 'SME', 'Print this guidance or save as PDF', 'feedback', 'help improve our online products and services']
URL: 

Content: <main class="govuk-main-wrapper ukri-main-content" id="main-content">

        <div class="govuk-width-container">
	<div class="content-badge">Funding opportunity</div>
	<h1 class="govuk-heading-xl main-area__page-title" id="skipnav-target"><span class="govuk-visually-hidden">Funding opportunity: </span>Canada-UK critical minerals: sustainability and circularity</h1>
    <div class="govuk-grid-row">
                <div class="govuk-grid-column-two-thirds-from-desktop single-opportunity__content-container main-content-column">
      			<div class="entry-header">
        				<div class="entry-meta single-opportunity__entry-meta">
          					
<dl class="govuk-table opportunity__summary">
  <div class="govuk-table__row">
    <dt class="govuk-table__header opportunity-cells">Opportunity status: </dt>
    <dd class="govuk-table__cell opportunity-cells"><span class="closed opportunity-status__flag">Closed</span></dd>
  </div>
  <div class="govuk-table__row">
    <dt class="govuk-table__header opportunity-cells">Funders: </dt>
    <dd class="govuk-table__cell opportunity-cells">
	<a class="ukri-funder__link" href="https://www.ukri.org/councils/innovate-uk/">Innovate UK</a>	</dd>
  </div>
      <div class="govuk-table__row">
      <dt class="govuk-table__header opportunity-cells">Co-funders: </dt>
	  <dd class="govuk-table__cell opportunity-cells">National Research Council of Canada Industrial Research Assistance Program (NRC IRAP)</dd>
	</div>
    <div class="govuk-table__row">
    <dt class="govuk-table__header opportunity-cells">Funding type: </dt>
	<dd class="govuk-table__cell opportunity-cells">Grant</dd>
  </div>
      <div class="govuk-table__row">
      <dt class="govuk-table__header opportunity-cells">Total fund: </dt>
	  <dd class="govuk-table__cell opportunity-cells">Â£5,400,000</dd>
    </div>
      <div class="govuk-table__row">
    <dt class="govuk-table__header opportunity-cells">Publication date: </dt>
	<dd class="govuk-table__cell opportunity-cells">24 October 2023</dd>
  </div>
  <div class="govuk-table__row">
    <dt class="govuk-table__header opportunity-cells">Opening date: </dt>
	<dd class="govuk-table__cell opportunity-cells">
	<time datetime="2023-11-20T09:30:00">20 November 2023 9:30am UK time</time>	</dd>
  </div>
  <div class="govuk-table__row">
    <dt class="govuk-table__header opportunity-cells">Closing date: </dt>
	<dd class="govuk-table__cell opportunity-cells">
	<time datetime="2024-04-03T17:00:00">3 April 2024 5:00pm UK time</time>	</dd>
  </div>
</dl>
														<div class="clearfix"></div>
        				</div>
                            </div><!-- .entry-header -->

            <div class="entry-content single-opportunity__entry-content">
                <div class="description">
                    <div class="ukri-callout-box">
<p>See the <a href="https://apply-for-innovation-funding.service.gov.uk/competition/1757/overview/736a153e-70a4-41d4-8be4-cfff091566a8">full opportunity details on the Innovation Funding Service</a>.</p>
</div>
<p>UK registered organisations and Canadian micro, small or medium-sized enterprises (SMEs) can apply for a share of up to Â£5.4 million for joint research and development projects focused on driving circularity in critical minerals.</p>
<h2>Eligibility summary</h2>
<p>This competition is open to Canada and UK collaborations only.</p>
<p>The project consortium must include:</p>
<ul>
<li>at least one grant claiming UK registered <a href="https://www.gov.uk/government/publications/life-of-a-company-annual-requirements/life-of-a-company-part-1-accounts#micro-entity">SME</a></li>
<li>a Canadian SME, which must be a separate non-linked entity to the UK project partners</li>
</ul>
                </div>
            </div><!-- .entry-content -->

            			
			      	</div><!-- #content -->

        <aside class="govuk-grid-column-one-third-from-desktop ukri-sidebar">
            
<div class="widget ukri-document__widget ukri-print__widget">
    <h2 class="govuk-visually-hidden">Print and download options</h2>
    <ul class="govuk-list ukri-document-list">
        <li class="ukri-document-list__item">
            <span class="ukri-document__icon">
            <svg id="Capa_1" data-name="Capa 1" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 20 15.65" width="20" height="15.65"><title>icon-printer</title><style type="text/css">.st0{fill:#FFFFFF;}</style><path class="st0" d="M0,11.3a4.34,4.34,0,0,0,3.48,4.26V11.74h13v3.82A4.34,4.34,0,0,0,20,11.3V6.52H0ZM3.91,9.13H16.09a.44.44,0,0,1,0,.87H3.91a.44.44,0,0,1,0-.87Z"></path><rect class="st0" x="4.35" y="12.61" width="11.3" height="3.04"></rect><rect class="st0" x="3.91" width="12.17" height="5.65"></rect></svg>
            </span>
            <a class="govuk-link" href="javascript:window.print()" id="analytics-opportunity-print">Print this guidance or save as PDF</a>
        </li>
    </ul>
</div>

<div class="widget good-research">
	<h2 class="govuk-heading-m ukri-sidebar__title">Guidance on good research</h2>
	<div class="textwidget">
		<ul>
			<li><a class="ukri-sidebar__link ukri-good-research__link" href="/about-us/policies-standards-and-data/good-research-resource-hub/"><span>Good research resource hub</span></a></li>
		</ul>
	</div>
</div>




<div class="ukri-email-signup__widget widget"><div class="ukri-email-signup"><h2 class="govuk-heading-m ukri-sidebar__title">Subscribe to UKRI emails</h2><p>Sign up for news, views, events and funding alerts.</p><form id="GD-snippet-form" action="https://public.govdelivery.com/accounts/UKRI/subscriber/qualify" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="âœ“"><input type="hidden" name="authenticity_token" value="+YhakBaKcGaLHAiEXHIrJZI7M21BsdXY4FCT0O65c3+v1fI18upE/geX9xnPumuqjMuPnpb9mqAFT0gZNB1PPA=="><label class="govuk-visually-hidden" for="email">Email address</label><input class="govuk-input ukri-email-signup__input" id="email" name="email" type="email" placeholder="Email address"><br><button class="govuk-button ukri-button--blue ukri-email-signup__button" data-module="govuk-button" id="analytics-newsletter-signup">Subscribe</button></form></div></div>        </aside>
            </div><!-- #primary -->
</div>
    </main>

Title: ['Skip to main content', '\n                                    ', '\n                                ', 'Apply for funding', 'Manage your award', 'What we do', 'News and events', 'Who we are', 'Our councils', 'Apply for funding', 'Funding finder', 'How to apply for research and innovation funding', 'Studentships and doctoral training', 'How we make decisions', 'Improving your funding experience', 'Horizon Europe', 'Manage your award', 'Accept your offer', 'Getting your funding', 'UKRI terms and conditions', 'Request a change', 'Report your outcomes', 'Report your spending', 'Publish your findings', 'What we do', 'Browse our areas of investment and support', 'What weâ€™ve funded', 'International', 'Investing across the UK', 'Career development', 'Supporting collaboration', 'Infrastructure', 'Research culture', 'Artificial intelligence', 'Research financial sustainability', 'Public engagement', 'News and events', 'News', 'Blog', 'Events', 'Voices blog', '101 jobs that change the world', 'Who we are', 'About UK Research and Innovation', 'Our vision and strategy', 'How weâ€™re governed', 'Who we fund', 'How weâ€™re doing', 'How we engage', 'Policies, standards and data', 'Work for us: jobs and advisory roles', 'Contact us', 'Our councils', 'AHRC', 'BBSRC', 'ESRC', 'EPSRC', 'Innovate UK', 'MRC', 'NERC', 'Research England', 'STFC', 'Home', 'Review of peer review', 'Introduction', 'Interventions covered in this review', 'Method note', 'Structure of this report', 'General observations', 'Main findings: interventions prior to a funding opportunity', 'Main findings: interventions in assessment process design', 'Main findings: interventions to the shape of decision-making', 'Main findings: interventions in training and feedback', 'Additional interventions identified by our review', 'Summary and recommendations', 'Print this document or save as a PDF', 'Peer Review of Grant Applications: Criteria Used and Qualitative Study of Reviewer Practices', 'Criteria for assessing grant applications: a systematic review', 'Do peers share the same criteria for assessing grant applications?', 'The decision-making constraints and processes of grant peer review, and their effects on the review outcome.', 'Study on the proposal evaluation system for the EU R&I framework programme', 'Assessment of potential bias in research grant peer review in Canada', 'The effects of funding policies on academic research', 'Evaluating Grant Peer Review in the Health Sciences: A review of the literature', 'Report of the Research Councils UK Efficiency and', 'Effectiveness of Peer Review Project', 'Response to the RCUK consultation on the Efficiency and Effectiveness of Peer Review', 'Several grants simultaneously', 'What requirements apply if I already have a grant from the Swedish Research Council', 'Science funding: Duel to the death', 'Sham Peer Review: the Destruction of Medical Careers (PDF, 37KB).', 'What works for peer review and decision-making in research funding: a realist synthesis', 'Tough love', 'International Evaluation of the Funding and Management of the National Natural Science Foundation of China', 'ESPR Research Grant Programme 2017 to 2022', 'ESRC â€“ Large Grants Competition 2016/17 (Update). University of Lincoln: Research Blog', 'Demand management', 'Towards inclusive funding practices for early career researchers', 'The Equality, Diversity and Inclusion Engagement Fellowship Pilot AHRC funding scheme report 2020 to 2022', 'Ethnicity and race inequity in our portfolio: findings of our community engagement and actions for change', 'Gender equality and positive action: evidence from UK universities', 'Positive action towards gender equality? Evidence from the Athena SWAN Charter in UK Medical Schools.', 'Effect of Athena SWAN funding incentives on womenâ€™s research leadership', 'Study on the proposal evaluation system for the EU R&I framework programme', 'The leaky pipeline in research grant peer review and funding decisions: challenges and future directions', 'Grant application outcomes for biomedical researchers who participated in the National Research Mentoring Networkâ€™s Grant Writing Coaching Programs', 'The experimental research funderâ€™s handbook, Research on Research Institute', 'Alternatives to peer review in research project funding', 'Sandpit methodology: results of a rapid literature search to inform a sandpit exercise for PETRA', 'Sandpits can develop cross-disciplinary projects, but funders need to be as open-minded as researchers', 'Decision-making approaches used by UK and international health funding organisations for allocating research funds: a survey of current practice', 'What works for peer review and decision-making in research funding: a realist synthesis. Research integrity and peer review', 'Creativity greenhouse: at-a-distance collaboration and competition over research funding', 'Exploring the potential role of community engagement in evaluating clinical and translational science grant proposals', 'Streamlined research funding using short proposals and accelerated peer review: an observational study', 'NSF tries two-step review, drawing praise â€“ and darts', 'Assessing health research grant applications: a retrospective comparative review of a one-stage versus a two-stage application assessment process', 'Exploring the potential role of community engagement in evaluating clinical and translational science grant proposals. Journal of Clinical and Translational Science', 'Study on the proposal evaluation system for the EU R&I framework programme', 'The experimental research funderâ€™s handbook, Research on Research Institute', 'Looking across and looking beyond the knowledge frontier: intellectual distance, novelty, and resource allocation in science', 'What do we know about grant peer review in the health sciences?', 'Is blinded review enough? How gendered outcomes arise even under anonymous evaluation', 'Conservatism gets funded? A field experiment on the role of negative information in novel project evaluation', 'Evaluation of the Spark pilot.', 'Anonymizing peer review for the NIH Directorâ€™s Transformative Research Award Applications', 'German funder sees early success in grant-by-lottery trial', 'An experimental test of the effects of redacting grant applicant identifiers on peer review outcomes', 'Study on the proposal evaluation system for the EU R&I framework programme', 'Blinding applicants in a first-stage peer-review process of biomedical grants: an observational study', 'Assigning evaluators to research grant applications: the case of Slovak Research and Development Agency', 'Innovating in the research funding process: peer review alternatives and adaptations', 'An algorithm for automatic assignment of reviewers to papers.', 'How research funders ensure the scientific legitimacy of their decisions: investigation in support of the design of formas', 'UKRI Research and Innovation Funding Service (RIFS) visioning work', 'A semi-automatic web based tool for the selection of research projects reviewers', 'What works for peer review and decision-making in research funding: a realist synthesis, Research Integrity and Peer Review', 'Dragonsâ€™ Den: promoting healthcare research and innovation', 'Fleshing out the data: when epidemiological researchers engage with patients and carers. Learning lessons from a patient involvement activity', 'Peer review for Ideas Grants in 2021', 'Expanding group peer review: a proposal for medical education scholarship', 'Communities of practice in peer review: outlining a group review process', 'The experimental research funderâ€™s handbook', 'The decision-making constraints and processes of grant peer review, and their effects on the review outcome', 'Consultation on the development of peer review for NHMRCâ€™s new grant program', 'Academic talent selection in grant review panels', 'An outcome evaluation of the National Institutes of Health (NIH) Directorâ€™s pioneer award (NDPA) program', 'Evaluation practices in the selection of ground-breaking research proposals', 'Study on the proposal evaluation system for the EU R&I framework programme', 'Ensuring sustainable evaluation: how to improve quality of evaluating grant proposals?', 'Similar-to-me effects in the grant application process: Applicants, panelists, and the likelihood of obtaining funds', 'Equality, Diversity and Inclusion Engagement Fellowship Pilot AHRC Funding Scheme Report', 'Designing grant-review panels for better funding decisions: lessons from an empirically calibrated simulation model', 'Process review of UKRIâ€™s research and innovation response to COVID-19', 'Exploring the degree of delegated authority for the peer review of societal impact', 'Community review: a robust and scalable selection system for resource allocation within open science and innovation communities', 'Innovating in the research funding process: peer review alternatives and adaptations', 'Evaluation of the ESRC Transformative Research Scheme', 'A radical change in peer review: a pilot project to ease pressure on NSFâ€™s vaunted peer-review system required grant applicants to review seven competing proposals', 'Powering discovery: the expert panel on international practices for funding natural sciences and engineering research', 'What works for peer review and decision-making in research funding: a realist synthesis', 'Administrative discretion in scientific funding: evidence from a prestigious postdoctoral training program', 'Alternatives to peer review in research project funding', 'Process review of UKRIâ€™s research and innovation response to COVID-19', 'Evaluating transformative research programmes: A case study of the NSF Small Grants for Exploratory Research programme', 'Enhancing NIH grant peer review: a broader perspective', 'Standing Panel on Impact Assessment (SPIA)', 'Participation and motivations of grant peer reviewers: a comprehensive survey of the biomedical research community', 'IES guide for grant peer review panel members: information, tips and instructions for members of IES scientific grant peer review panels (PDF, 780KB)', 'Organisational and process review of the Human Frontier Science Program.', 'Process review of UKRIâ€™s research and innovation response to COVID-19', 'Becoming a peer reviewer for NIJ (2023)', 'Improving NIJâ€™s peer review process: the scientific review panel pilot project', 'CSR data and evaluations', 'Review of disability and rehabilitation research: NIDRR grantmaking processes and products', 'Responsive mode grant assessment process', 'An overview: IES procedures for peer review of grant applications', 'Managing internal nomination and peer review processes to reduce bias', 'Assessment of potential bias in research grant peer review in Canada', 'San Francisco Declaration on Research Assessment (DORA)', 'Harnessing the Metric Tide: indicators, infrastructures and priorities for UK responsible research assessment', 'How do NIHR peer review panels use bibliometric information to support their decisions?', 'The role of metrics in peer assessments', 'Segmenting academics: resource targeting of research grants', 'Dealing with the limits of peer review with innovative approaches to allocating research funding (PDF, 314KB)', 'The leaky pipeline in research grant peer review and funding decision: challenges and future directions.', 'Does the inclusion of non-academic reviewers make any difference for grant impact panels?', 'The influence of peer reviewer expertise on the evaluation of research funding applications', 'Alternatives to peer review in research project funding', 'Innovating in the research funding process: peer review alternatives and adaptations', 'The experimental Research funderâ€™s handbook', 'UKRI Research and Innovation Funding Service (RIFS) visioning work (PDF, 1.5MB)', 'How research funders ensure the scientific legitimacy of their decisions: investigation in support of the design of Formas scientific management', 'Evaluation of research proposals by peer review panels: broader panels for broader assessments?', 'Peer review of health research funding proposals: A systematic map and systematic review of innovations for effectiveness and efficiency', 'Face-to-face panel meetings versus remote evaluation of fellowship applications: simulation study at the Swiss National Science Foundation', 'Meeting for peer review at a resort thatâ€™s virtually free', 'Teleconference versus face-to-face scientific peer review of grant application: effects on review outcomes', 'Alternatives to Peer Review in Research Project Funding', 'What do we know about grant peer review in the health sciences?', 'Innovating in the research funding process: peer review alternatives and adaptations', 'Pre-award process review of the IRC Laureate Award (PDF, 2.4MB)', 'What works for peer review and decision: making in research funding: a realist synthesis, Research Integrity and Peer Review', 'Peer review of health research funding proposals: A systematic map and systematic review of innovations for effectiveness and efficiency', 'Mavericks and lotteries', 'Dealing with the limits of peer review with innovative approaches to allocating research funding (PDF, 314KB)', 'I won a project!', 'Alternatives to peer review in research project funding', 'What works for peer review and decision-making in research funding: a realist synthesis', 'Fund ideas, not pedigree, to find fresh insight', 'Mavericks and lotteries', 'The troubles with peer review for allocating research funding', 'The experimental research funderâ€™s handbook', 'NIH peer review percentile scores are poorly predictive of grant productivity', 'Research funding: the case for a modified lottery', 'Alternatives to peer review in research project funding', 'Innovating in the research funding process: peer review alternatives and adaptations', 'The consequences of competition: simulating the effects of research grant allocation strategies', 'Are peer-reviews of grant proposals reliable? An analysis of Economic and Social Research Council (ESRC) funding applications', 'Study on the proposal evaluation system for the EU R&I framework programme', 'Blind Luck â€“ Could lotteries be a more efficient mechanism for allocating research funds than peer review?', 'Peer review or lottery? A critical analysis of two different forms of decision-making mechanisms for allocation of research grants', 'Partially Randomized Procedure â€“ Lottery and Peer Review', 'Give Chance a Chance', 'Peer review of grant applications: criteria used and qualitative study of reviewer practices', 'Alternatives to peer review in research project funding â€“ 2013 update', 'Are peer-reviews of grant proposals reliable? An analysis of Economic and Social Research Council (ESRC) funding applications', 'Commensuration bias in peer review', 'Your comments are meaner than your scoreâ€™: score calibration talk influences intra- and inter-panel variability during scientific grant peer review', 'Science Europe study on research assessment practices', 'UKRI Research and Innovation Funding Service (RIFS) visioning work â€“ Final report (PDF, 1.5MB)', 'How research funders ensure the scientific legitimacy of their decisions: investigation in support of the design of Formas scientific management.', 'Addressing racial disparities in NIH funding', 'Grant allocation disparities from a gender perspective: literature review', 'The modified lottery: formalizing the intrinsic randomness of research funding, accountability in research', 'Evolving and upholding fairness in peer review', 'Inequality in early career research in the UK life sciences', 'Understanding our portfolio: a gender perspective', 'Interventions designed to reduce implicit prejudices and implicit stereotypes in real world contexts: a systematic review', 'Scientists from minority-serving institutions and their participation in grant peer review', 'The problem with implicit bias training', 'The state of women in life sciences at McGill: a summary and report of the Win4Science Forum (PDF, 918KB)', 'Who resembles a scientific leader â€“ Jack or Jill? How implicit bias could influence research grant funding', 'The good, the bad, and the ugly of implicit bias', 'Does gender bias still affect women in science?', 'Assessment of potential bias in research grant peer review in Canada', 'Unconscious bias and diversity training â€“ what the evidence says', 'Is there gender bias in research grant success in social sciences? Hong Kong as a case study', 'Targeted, actionable and fair: reviewer reports as feedback and its effect on ECR career choices', 'Study on the proposal evaluation system for the EU R&I framework programme', 'Evaluation of the ESRC Transformative Research Scheme (PDF, 1.5MB)', 'Organisational and process review of the Human Frontier Science Program', 'ESF survey analysis report on peer review practices (PDF, 6.4MB)', 'What do we know about grant peer review in the health sciences?', 'Individual versus general structured feedback to improve agreement in grant peer review: a randomized controlled trial', 'Global state of peer review 2018', 'What works for peer review and decision-making in research funding: a realist synthesis', 'Grant peer review: improving inter-rater reliability with training', 'Peer review of health research funding proposals: a systematic map and systematic review of innovations for effectiveness and efficiency', 'Attitudes and practices of open data, preprinting, and peer-review-A cross sectional study on Croatian scientists.', 'Gender-equal funding rates conceal unequal evaluations', 'Horizon Europe and Plan B research funding: turning adversity into opportunity', 'Strategic advice for enhancing the gender dimension of Open Science and Innovation Policy', 'Innovating in the research funding process: peer review alternatives and adaptations', 'Response by the Author', 'Decision-making approaches used by UK and international health funding organisations for allocating research funds: a survey of current practice', 'How research funders ensure the scientific legitimacy of their decisions: investigation in support of the design of Formas scientific management', 'What works for peer review and decision-making in research funding: a realist synthesis', 'summary table of aims, hazards and evidence strength', '\n\t\t\t\t', '\n\t\t\t', 'feedback', 'help improve our online products and services']
URL: 
			
Content: <main class="govuk-main-wrapper ukri-main-content" id="main-content">

        <div class="govuk-width-container">
	<span class="govuk-caption-xl ukri-publication-type">Independent report</span>
	<h1 class="govuk-heading-xl main-area__page-title" id="skipnav-target">Review of peer review: June 2023</h1>
	<div class="entry-header html-publication-meta">
		<dl class="publication-meta govuk-body-s">
			<dt class="publication-meta-term">From: </dt>
			<dd class="publication-meta-definition">UKRI</dd>
						<dt class="publication-meta-term">Published: </dt>
			<dd class="publication-meta-definition"><time datetime="2023-12-05">5 December 2023</time></dd>
					</dl>
		<div class="clearfix"></div>
	</div>
    <div class="govuk-grid-row sticky-element-container" id="contents">
		<div class="govuk-grid-column-one-third-from-desktop ukri-sidebar">
		<nav aria-label="Contents" class="html-publication-contents"><h2>Contents</h2><ul><li><a href="#section-introduction">Introduction</a></li><li><a href="#section-interventions-covered-in-this-review">Interventions covered in this review</a></li><li><a href="#section-method-note">Method note</a></li><li><a href="#section-structure-of-this-report">Structure of this report</a></li><li><a href="#section-general-observations">General observations</a></li><li><a href="#section-main-findings:-interventions-prior-to-a-funding-opportunity">Main findings: interventions prior to a funding opportunity</a></li><li><a href="#section-main-findings:-interventions-in-assessment-process-design">Main findings: interventions in assessment process design</a></li><li><a href="#section-main-findings:-interventions-to-the-shape-of-decision-making">Main findings: interventions to the shape of decision-making</a></li><li><a href="#section-main-findings:-interventions-in-training-and-feedback">Main findings: interventions in training and feedback</a></li><li><a href="#section-additional-interventions-identified-by-our-review">Additional interventions identified by our review</a></li><li><a href="#section-summary-and-recommendations">Summary and recommendations</a></li></ul></nav>			
			<div class="widget ukri-document__widget ukri-print__widget govuk-!-margin-bottom-8">
				<ul class="govuk-list ukri-document-list">
					<li class="ukri-document-list__item">
						<span class="ukri-document__icon">
							<svg id="Capa_1" data-name="Capa 1" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 20 15.65" width="20" height="15.65"><title>icon-printer</title><style type="text/css">.st0{fill:#ffffff;}</style><path class="st0" d="M0,11.3a4.34,4.34,0,0,0,3.48,4.26V11.74h13v3.82A4.34,4.34,0,0,0,20,11.3V6.52H0ZM3.91,9.13H16.09a.44.44,0,0,1,0,.87H3.91a.44.44,0,0,1,0-.87Z"></path><rect class="st0" x="4.35" y="12.61" width="11.3" height="3.04"></rect><rect class="st0" x="3.91" width="12.17" height="5.65"></rect></svg>
						</span>
						<a class="govuk-link" href="javascript:window.print()" id="analytics-document-print">Print this document or save as a PDF</a>
					</li>
				</ul>
			</div>			
		</div>
        <div class="govuk-grid-column-two-thirds-from-desktop single-publication__content-container main-content-column">
			<div class="entry-content">
			<h2>Executive summary</h2>
<p>This report presents the findings of a study commissioned by UK Research and Innovation (UKRI) to review interventions to the peer review processes used in research and innovation (R&amp;I) award funding. It is intended as a resource for R&amp;I funders across the globe looking to optimise and innovate in their award-making processes.</p>
<p>The study assessed 38 interventions, which range from small process â€˜tweaksâ€™ such as increasing or decreasing the number of reviewers per application and shortening application sections, to more fundamental changes such as partial randomisation and complete bypass of peer review.</p>
<p>The aim of the study was to assess these 38 interventions, to establish what each of them might be useful for, and what disadvantages or hazards each might entail. We also provide an assessment of the overall strength of evidence on each intervention, including which ones are well studied and which ones are not.</p>
<p>Our research is underpinned by an extensive literature review (encompassing both academic and â€˜greyâ€™ literature), a survey of UKRI staff, and a programme of 22 interviews with representatives of UK and international research funders and a range of other stakeholders and experts in the field.</p>
<p>We find that all the interventions we considered here are typically intended to fulfil at least one (or sometimes several) of the following seven aims:</p>
<ul>
<li>to save time, including speeding up time-to-grant</li>
<li>to optimise the relevance of applications and funded awards to the aims of the funding scheme</li>
<li>to increase the ability to identify and fund high-risk or high-reward projects (sometimes known as â€˜frontierâ€™, â€˜transformativeâ€™ or â€˜breakthroughâ€™ research)</li>
<li>to reduce burden (on applicants, reviewers, panellists or administrators)</li>
<li>to manage application volume (often a subset of reducing burden, but may also occur for other reasons)</li>
<li>to reduce bias and ensure greater inclusion of disadvantaged groups, including along lines of gender, career stage, institution, or any other category</li>
<li>to improve the overall quality of reviews (for instance, by ensuring optimally tailored expertise of reviewers or increased levels of transparency and feedback)</li>
</ul>
<p>These seven aims correspond well to the known challenges of peer review documented in the â€˜science of scienceâ€™ literature. Almost all the 38 interventions considered in our review provide opportunities to fulfil the above aims.</p>
<p>At the same time, no intervention is a catch-all solution. None pertain to all seven aims, most are useful for certain contexts and less useful (or even problematic) in others, and almost all may entail some form of disadvantage or hazard. Few of these are insurmountable.</p>
<p>Recent work in the UK and beyond to reduce research bureaucracy and improve research culture may help create conditions where many such hazards can be overcome more easily. Modernised IT systems are also a prerequisite for the implementation of many interventions considered here. Often, the disadvantages of one intervention can also be offset by introducing an additional intervention. Not least for this reason, we often identify two or more interventions that are typically used together.</p>
<p>Our study highlights that there is a critical need to coordinate the use of the interventions with the context and aims of each specific funding opportunity in question. Based on our findings, creating bespoke funding processes tailored to the needs and aims of each funding opportunity is a clear â€˜direction of travelâ€™ for the future of R&amp;I funding.</p>
<p>We find a mixed picture when it comes to strength of evidence. For some interventions, there is plenty of evidence, including experimental studies and quantified outcomes, for example:</p>
<ul>
<li>for applicant anonymisation</li>
<li>two-stage application processes</li>
<li>use of non-academic reviewers</li>
</ul>
<p>However, others appear to be under-researched (for example, group review and moderation panels). We therefore recommend that funders continue to evaluate and monitor any interventions they use, and share findings with other funding organisations.</p>
<p>Our headline recommendation is that process design should always be a constituent part of scheme design. Every funding scheme has specific aims and characteristics, and so the design of the application, review and decision-making process should be considered for each individual funding opportunity.</p>
<p>We encourage funders to make extensive use of the interventions studied here and to vary their assessment processes widely. Some interventions (for example, peer review colleges or automation-assisted reviewer allocation) even have potential to be mainstreamed across fundersâ€™ entire portfolios.</p>
<p>We set out our full list of recommendations in the final section of this report.</p>
<h2 id="section-introduction">Introduction</h2><p>This report presents the findings of a study commissioned by UKRI on the use and effectiveness of interventions in peer review for grant-making processes. The study has been carried out by Technopolis from January to March 2023. The intention of this study is to act as a resource for all R&amp;I funders across the globe.</p>
<p>The term â€˜interventionsâ€™ is a catch-all word that encompasses the many different organisational and procedural refinements to the baseline application assessment process used by R&amp;I funders across the globe involving external peer review and panel review. We provide a generalised description of this baseline process below. This step-by-step breakdown is not intended as a representation specifically of UKRI processes, but a generic heuristic of how research and innovation award funding decisions are typically made worldwide. Of the multitude of UKRI funding opportunities, those under the umbrella of â€˜responsive modeâ€™ funding tend to approximate most closely to this baseline process.</p>
<h3>Baseline application assessment process in R&amp;I funding</h3>
<p>Step 1: applicant submits their application</p>
<p>Step 2: funderâ€™s admin staff perform eligibility and compliance checks</p>
<p>Step 3: peer review of applications, including:</p>
<ul>
<li>remote peer review by two to three external experts</li>
<li>panel review, resulting in a ranked list of applications from best to worst</li>
</ul>
<p>Step 4: formal sign-off by department or organisation leadership</p>
<p>Each step has formalised standards, including:</p>
<ul>
<li>reviewer selection</li>
<li>co-investigators</li>
<li>eligibility criteria</li>
</ul>
<p>Peer review is trusted by researchers and research funders across the globe. Notwithstanding numerous advances in assessment techniques and technologies, it remains the primary means of R&amp;I award selection. There is a large literature characterising peer review and exploring its strengths and weaknesses, which is being added to continuously for different domains and different potential solutions. Key issues with peer review include:</p>
<ul>
<li>it can be burdensome and time-consuming for researchers, reviewers and funders</li>
<li>it tends to produce conservative decisions, avoiding risk and novelty</li>
<li>it struggles to suitably assess and reward interdisciplinary research</li>
<li>it can be biased in favour of established names and institutions, and there is some evidence of gender bias</li>
<li>fine-grained rankings of proposals can be influenced by reviewer choice</li>
<li>it is underused as a developmental tool (for example, investing sufficiently in feedback that has sufficient depth and quality to improve applicantsâ€™ future work)</li>
</ul>
<p>Resulting in large part from these challenges, many funders have introduced various interventions to modify and deviate from the baseline. Some change drivers are â€˜proactiveâ€™, meaning that they signal fundersâ€™ expanded remit or new strategic ambitions. For example, funding research to address societal needs, to fund high-risk or high-reward research, or to fund research at speed to respond to an emergency. There is also a â€˜reactiveâ€™ side to change drivers and there are problems with traditional R&amp;I funding assessment processes, including the peer review burden and the risk of bias as outlined above.</p>
<h2 id="section-interventions-covered-in-this-review">Interventions covered in this review</h2><p>Different interventions are intended to respond to different drivers. The key drivers for deviating from a baseline assessment process will vary depending on the aims and objectives of a given funding scheme. For example, interventions aimed at speeding up the assessment process will be important in an emergency response funding scheme, but less so (or not at all) for long-term investments.</p>
<p>Further, interventions may pertain to different parts of the funding process. We distinguish between interventions at the pre-announcement stage, those pertaining to the design of the application itself, the design of the assessment process, and the final decision-making stage. Finally, there are training or feedback interventions underpinning the entire process, so we posit this as an additional category of interventions.</p>
<p>In collaboration with UKRI, we compiled a list of 38 interventions to the baseline research award funding process. This list forms the basis of our review.</p>
<p>The list began with a preliminary list of 29 interventions, which was included by UKRI in the terms of reference for this study. Based on our own experience of evaluating R&amp;I funding schemes across the globe, as well as on studies we recently conducted on peer review processes in general (including for UKRI, Wellcome, Formas (Sweden) and the Global Research Council (GRC)), we added to this list, and also split or combined various interventions from the preliminary list. Further consultation led to the final list of 38 interventions. We kept open the possibility to include additional interventions if we identified any interesting additional ones during our research. We summarise additional interventions in the â€˜Additional interventions identified by our reviewâ€™ section.</p>
<h3>List of 38 interventions to baseline peer review process</h3>
<h4>Pre-announcement</h4>
<h5>Assessment criteria definition</h5>
<p>Adding assessment criteria additional to conventional ones, may involve a tiered system for assessment criteria. For example, essential versus desirable.</p>
<h5>Demand management: individuals (1)</h5>
<p>Limiting researchers to being a lead investigator only on one project or application at a time.</p>
<h5>Demand management: individuals (2)</h5>
<p>Having a â€˜time outâ€™ period of a year, so that after an unsuccessful application, the applicant is not allowed to apply the following year. Based on previous behaviour and includes an element of quality control.</p>
<h5>Demand management: institutions</h5>
<p>Limiting the number of applications or resubmissions accepted from a single institution.</p>
<h5>Working with underrepresented groups</h5>
<p>Providing additional support to groups that are unrepresented in the funderâ€™s portfolio to encourage them to apply and support them as they do, with the view to increasing diversity.</p>
<h4>Application-design and parameters</h4>
<h5>Applicant behaviours</h5>
<p>Designing application forms and processes with a view to encouraging positive behaviours among applicants (for example, removing hierarchies of applicants to encourage consortium building and collaboration).</p>
<h5>Expression of interest or pre-proposal</h5>
<p>A reduced application is submitted in an expression of interest phase (may simply be a short project description and CV) and triage occurs before a subset are invited to submit a full proposal.</p>
<p>See also two-stage application process.</p>
<h5>Reducing application form length or cutting sections</h5>
<p>Shortening application forms (page or word length) to reduce burden. Requiring only project description and not track record, or cutting other sections.</p>
<h4>Process design</h4>
<h5>â€˜Sandpitsâ€™ or matching events</h5>
<p>Potential applicants are invited to an event to discuss possibilities and form teams for potential proposals. May involve some application submission on the day.</p>
<h5>Two-stage application process</h5>
<p>Two â€˜roundsâ€™ of peer or panel review are used, sifting out some after the first stage. May involve different parts of the application being reviewed at different stages, or expression of interest or pre-proposal.</p>
<p>We note that the recent UK Research Bureaucracy Review uses the term differently. However, we opt here for a definition that most international funders would recognise in this form.</p>
<h5>Applicant anonymisation</h5>
<p>Reviewers or panels members or both do not see the identity of the applicant or applicants.</p>
<h5>Automation-assisted reviewer allocation</h5>
<p>Using algorithms, artificial intelligence (AI) or text recognition to aid allocation of reviewers to applications.</p>
<h5>Dragonâ€™s den-style pitch</h5>
<p>Applicants are invited to pitch their proposal in front of a panel, and panels have an opportunity to ask questions. This differs from an interview in that no other form of evidence (for example, written proposals or external expert review) is used in the assessment.</p>
<p>Note for non-UK readers: the term â€˜Dragonâ€™s Denâ€™ originated from a UK TV show involving pitching of business ideas to investors.</p>
<h5>External review only (no panel)</h5>
<p>Proposals are only assessed by external reviewers and review scores are simply combined to give the final score.</p>
<h5>Group review</h5>
<p>The same reviewer comments on multiple proposals.</p>
<h5>Changing the number of reviewers</h5>
<p>Two to three external reviews of applications is typical for responsive-mode grant funding, but this number may be lowered to one or significantly increased.</p>
<h5>Interviews</h5>
<p>Lead applicant (or several application team members) may do a presentation (optional) and are then asked questions on their application by panel members, reviewers or funder representatives.</p>
<h5>Moderation of reviews</h5>
<p>Reviews are processed internally by funding organisation staff and are only passed to the external panel if they are of sufficient quality.</p>
<h5>Moderation panel</h5>
<p>Assessment panels use external reviews alongside their own expertise to assess the proposal.</p>
<p>Compared to moderation panels, assessment panel members can bring in their own expertise and this approach is mostly part of the baseline process and therefore not considered as an intervention in this study.</p>
<p>Moderation panels do not use their own expertise but can only use the reviews to inform their scores.</p>
<p>Note that to ensure clarity for the widest possible readership, we are using terminology that might not align with UKRI terminology. In UKRI some moderation panels can bring in generic or system expertise.</p>
<h5>Panel only (no postal or external review)</h5>
<p>Proposals are only assessed by a panel of experts.</p>
<h5>Peer allocation</h5>
<p>The applicants are also the assessors and review the proposals they are competing against to decide who gets funding.</p>
<h5>Programme managerâ€™s discretion</h5>
<p>Applications go directly to the programme or scheme manager, who can recommend funding or even decide to fund unilaterally. Usually involves complete bypass of peer and panel review.</p>
<h5>Standing panels versus portfolio panels</h5>
<p>Standing panels are the same year on year (with some replacement due to retirement from the panel). Portfolio panels are assembled based on the proposals received and therefore will be comprised differently in each round of funding.</p>
<h5>Use of international assessors</h5>
<p>Having quotas for assessors based in countries other than the funderâ€™s â€˜homeâ€™ country. May extend to mandating all-international panels, reviewers or both.</p>
<h5>Use of metrics</h5>
<p>Use of metrics and bibliometrics as part of the evidence base to inform decision making.</p>
<h5>Use of non-academic assessors (including, industry, policy and practice, patients, â€˜userâ€™ representatives)</h5>
<p>Having quotas for non-academic assessors. May extend to all-user panels, reviewers or both. May take the shape of consultation rather than directly making formal funding recommendations.</p>
<h5>Virtual panels</h5>
<p>Convening panels online rather than in person.</p>
<h4>Decision-making</h4>
<h5>Wildcard</h5>
<p>Sometimes also known as â€˜golden ticketâ€™ or â€˜jokerâ€™. Each panel member (or other decision-maker) is able to select one proposal (for example, per opportunity, per year, or similar) to guarantee funding (provided there is no conflict of interest), regardless of panel rankings or other decision-making processes.</p>
<h5>Partial randomisation</h5>
<p>Successful proposals are chosen at random. In most methodologies, randomisation is only partial. For example, proposals may be scored and sorted into bands, and only those on the border of being funded will be randomised.</p>
<h5>Scoring mechanisms</h5>
<p>Includes calibration of scores, consensus versus voting, weighting.</p>
<h5>Sequential application of criteria (rather than simultaneous application of criteria)</h5>
<p>A proposal is scored for one set of criteria, ranked and a cut-off point determined. Then those above the cut-off point are assessed again for another set of criteria to determine the final funded list.</p>
<h5>Use of quotas</h5>
<p>After ranking, proposals are reviewed to ensure sufficient numbers in certain categories, including quotas related to:</p>
<ul>
<li>protected characteristics</li>
<li>place</li>
<li>first-time applicants</li>
</ul>
<h4>Training and feedback</h4>
<h5>Bringing in reviewers from earlier careers and providing mentoring</h5>
<p>Panels and reviewers tend to be very experienced researchers or innovators. Those early in their careers could be invited to review or be part of panels with additional training, bringing different perspectives and experiences. Previous funding opportunity award winners may also be brought in as reviewers or panellists.</p>
<h5>Embedding equality, diversity and inclusion in assessment</h5>
<p>Training or support provided to make assessors aware of their unconscious biases and to encourage them to call each other out during the assessment process.</p>
<h5>Expanding or reducing the amount or detail of feedback to unsuccessful applicants</h5>
<p>Different levels of feedback may be provided on unsuccessful applications.</p>
<h5>Funder representation on review panels</h5>
<p>The funder is represented on the panel to guide discussion or provide briefing on programme aims. Their role is beyond a purely administrative function, they may even be in a chair role or similar.</p>
<h5>Improving quality of reviews</h5>
<p>Through training, retaining good reviewers or recognition. Peer review colleges fit here too.</p>
<h5>Open review or rebuttal</h5>
<p>Reviews are published or made available to the applicant before funding decisions are taken, so they can be viewed and responded to.</p>
<h2 id="section-method-note">Method note</h2><p>For each of the 38 interventions, we set out to compile an evidence base to establish the following points:</p>
<ul>
<li>definitions: what exactly does the intervention involve? Are there relevant differences in how different funders practise the intervention?</li>
<li>why to do it: what is the envisaged benefit of the intervention? What problems or issues is it supposed to solve? What, therefore, might be measures of its success?</li>
<li>why not to do it: does the intervention have any weaknesses, hazards or drawbacks? Are these especially problematic under certain circumstances (for particular scheme types)?</li>
<li>evidence verdict and strength of evidence: is there evidence to show that this intervention has (or has not) worked? What is the strength of the evidence (for example, controlled experiments, light-touch evaluation, anecdotal)?</li>
</ul>
<p>Our study had three data collection strands, which ran in parallel.</p>
<p>First, we conducted a review of literature on research award funding processes. This included academic literature as well as evidence from evaluations of various funding schemes and wider strategic studies. We conducted keyword searches for each intervention and also added resources known to us prior to the study.</p>
<p>We further conducted a consultation survey of UKRI staff. This survey was primarily intended to obtain views on any of our 38 interventions that may have been trialled in different parts of the organisation, including comments on interventions that worked well and interventions that did not. This information adds additional stakeholder perspectives to the findings obtained from the literature. While the survey cannot be fully representative, we added some survey items that help quantify which interventions appear to be well known or less well known in different parts of UKRI. The survey also identified whether there is particular appetite for certain interventions to be used more.</p>
<p>Finally, we ran a programme of interviews to obtain further viewpoints on the 38 interventions. We included in the programme a small number of follow-up conversations with UKRI survey respondents, as well as several representatives from UK funders other than UKRI, international funders, stakeholders from the UK higher education institution (HEI) landscape, and a selection of academic experts on peer review, its modifications and alternatives.</p>
<p>Method details are presented in the appendices to this report.</p>
<h2 id="section-structure-of-this-report">Structure of this report</h2><p>In the next section, we present some aggregate findings and general observations from our research. In the subsequent five main sections we present the evidence on each of the 38 interventions, split by our five intervention domains:</p>
<ul>
<li>interventions at the pre-announcement stage</li>
<li>interventions pertaining to design of the application itself</li>
<li>the design of the assessment process</li>
<li>the final decision-making stage</li>
<li>training or feedback interventions underpinning the entire process</li>
</ul>
<p>The findings in these five main sections are aggregate summaries from our literature review (see Appendix A), our survey (see Appendix B) and our interviews (see Appendix C).</p>
<p>For each intervention, we provide a write up explaining its aims, some data highlights (including instances of use) and any known effects, as well as hazards or dangers associated with each intervention. For each intervention, we also provide a simple rating of the evidence strength. This rating relates only to evidence strength, not to intervention effectiveness. It does not reflect whether the intervention works, but the strength of evidence demonstrating its efficacy (or lack thereof, as the case may be):</p>
<ul>
<li>one star (*): very limited evidence, almost or entirely tentative or speculative</li>
<li>two stars (**): some evidence, for example several anecdotal pieces and perhaps some minor empirical observations</li>
<li>three stars (***): multiple sources of credible evidence, though not necessarily quantifiable conclusions, and not all parts of the intervention have been investigated thoroughly (for example in cases of multiple aims)</li>
<li>four stars (****): multiple sources of credible evidence, including experimental or other empirical measurement or evaluation</li>
</ul>
<p>Finally, we provide a brief overview of a small number of other minor interventions not included in our initial list of 38, but which were discovered by the research team over the course of the study. The last section of this report provides a summary of findings and our list of recommendations resulting from our research. We note that these recommendations are not specific to UKRI but may be considered by any R&amp;I funder looking to optimise and innovate in their award-making processes.</p>
<h2 id="section-general-observations">General observations</h2><p>The next main section presents findings on each of the 38 interventions and forms the bulk of this report. However, there are some general observations worth noting at the outset.</p>
<p>First, we find that the rationales for the interventions (as expressed in the literature and by consultees) correspond well to the problems of peer review and the â€˜baselineâ€™ funding process noted at the outset. Almost all interventions considered here draw their rationale from the following seven (partially related) aims:</p>
<ul>
<li>to save time, including speeding up time-to-grant, either from a simple efficiency point of view, or in order to be able to respond to emergencies</li>
<li>to optimise the relevance of applications and funded awards to the aims of the funding scheme (for example, thematic or sector relevance, maximum scope for application)</li>
<li>to increase the ability to identify and fund high-risk or high-reward projects (also known as â€˜transformativeâ€™, â€˜radicalâ€™, â€˜frontierâ€™ or â€˜breakthroughâ€™ research); in a sense this is a subset of the previous aim of optimising relevance (if a scheme specifically aims to fund such research) but it relates to the well-documented conservatism of peer review, which is an issue in its own right</li>
<li>to reduce burden on applicants, reviewers, panellists, and administrators; this is generally about efficiencies and minimising the effort and cost needed to carry out the review of applications</li>
<li>to manage application volume; this may to an extent relate to reducing burden more generally, but also relates to discouraging applications that are out of scope or of unsuitably low quality</li>
<li>to reduce bias and ensure greater inclusion of disadvantaged, underrepresented groups or both, including along lines of gender, career stage, institution, or any other category</li>
<li>to improve the overall quality of reviews, which may mean, for instance, to ensure optimally tailored expertise of reviewers, as well as increased levels of transparency and feedback</li>
</ul>
<p>Almost without exception, every literature source, interviewee and survey respondent cites at least one of the above seven aims when discussing any of our 38 interventions. Some interventions relate only to one of these seven aims, though most are associated with several (often two or three). In the concluding section of this report, we provide a comprehensive overview of how our 38 interventions relate to each of the seven aims.</p>
<p>While this list of intervention aims is foremost intended to help funders decide when and why to introduce each intervention, we note that it may also be a useful tool to secure buy-in from the research community. The issue of buy-in is not covered in detail in any of the sources we consulted, but our research indicates that wider buy-in is a concern that funders occasionally have when contemplating introducing interventions. A clear rationale for introduction which draws on this list of possible aims may contribute towards mitigating such concerns.</p>
<p>At the same time, no intervention is a catch-all solution. None pertain to all seven aims, most are useful for certain contexts and less useful (or even problematic) in others, and almost all may entail some form of disadvantage or potential hazard.</p>
<p>This means that there is a critical need to coordinate use of the interventions with the context and aims of the specific funding opportunity in question. Creating bespoke funding processes tailored to the needs and aims of each funding opportunity is a â€˜direction of travelâ€™ for the future of research funding.</p>
<p>The seven main aims and the frequency of themÂ among the 38 interventions are:</p>
<ul>
<li>save time â€“ 9</li>
<li>optimise the relevance of applications â€“ 11</li>
<li>increase the ability to identity and fund high-risk or high-reward projects â€“ 7</li>
<li>reduce burden â€“ 11</li>
<li>manage application volume â€“ 3</li>
<li>reduce bias â€“ 13</li>
<li>improve the overall quality of reviews â€“ 17</li>
</ul>
<p>Regarding the disadvantages and hazards of each intervention, few are insurmountable. We do not provide a full assessment of how easily each hazard or disadvantage may be overcome, in part because this is often context dependent. Some fundersâ€™ IT systems may for instance be readily able to address many noted challenges. Some hazards may be more severe in smaller research systems (be they delineated by country or research field) where conflicts of interest are more likely to occur.</p>
<p>We note hazards and disadvantages where we identify them, but it will most often be dependent on each funderâ€™s context whether they constitute a â€˜showstopperâ€™ or whether they can be dealt with. We also note mitigations where these are evident from our research.</p>
<p>We also note that several interventions may complement each other and may often appear together. For instance, wildcard approaches tend to be used in combination with anonymised reviewing in order to minimise scope for cronyism. In such cases, a hazard associated with one intervention is mitigated by adding another intervention.</p>
<p>On the other hand, some interventions might also counteract each other. An intervention may increase the quality of applications but might entail additional burden, lengthen time-to-grant or both. Others may do the opposite. Pairing or combining different interventions does not appear to be a well-researched topic. However, we have identified some common pairings and rationales for pairing certain interventions together (noted where relevant in the following main section of this report).</p>
<h3>Additional meta findings</h3>
<h4>Positives in the peer review must be recognised</h4>
<p>Several survey respondents and interviewees felt the need to emphasise the good things about the peer review system (including the â€˜baselineâ€™ approach). In light of the overall criticisms, consultees often judge it essential to praise the work that is globally invested in the peer review effort and the benefits it brings.</p>
<p>Funding staff, having regularly observed panels in action, feel it is sometimes unfair to showcase only examples of failure and ignore the positives. This includes the effort invested, the care that reviewers put into the activity and the benefits a good review brings to the research community.</p>
<h4>Political sensitivities and acceptance of the interventions in the research community</h4>
<p>Some interventions, primarily partial randomisation, but also the use of quotas, demand management, interviews, and sandpits, have sometimes raised concerns in the research community or at the research fundersâ€™ boards or oversight institutions. All consulted funders that have introduced partial randomisation report investing extra effort to make a case for the funderâ€™s board or ministries that oversee their operations, regardless of geography. Private funders might be less concerned about external pressures but still have to make a solid internal case.</p>
<p>Some consulted funders and experts pointed out that the acceptance from the oversight bodies and wider society is a more significant concern than the acceptance in the research community itself. This is mainly because researchers are more familiar with the peer review system, its strengths and weaknesses and understand the rationale of the more experimental interventions.</p>
<p>In some cases, the significant scrutiny and risks result in a reluctance to try new things. However, a degree of scepticism is certainly warranted. Demand management, interviews, sandpits and some other interventions do raise concerns about, for instance, equity and the potential favouring of applicants who can access specific meetings and events and have good presentation skills.</p>
<h4>Shifting responsibility from funders to research performing organisations</h4>
<p>There is some tension between the responsibilities of funders and research performing organisations in addressing the equity and burden in research funding. Some of the interventions may mean less burden for the funders but more for the research administrators at the research performing organisations.</p>
<p>Where demand management is transferred to the institutional level, research performing organisations may effectively carry out the assessment for the best application to put forward. There are also examples of funders removing some requirements (for example, specific sections in applications or monitoring requirements). However, those are still implemented or asked for at the research performing organisations to maintain internal oversight. As a result, nothing changes regarding the burden for the â€˜regularâ€™ researcher and for the research system as a whole.</p>
<h4>Manuscript peer review</h4>
<p>In the academic literature, some interventions are discussed primarily or only in the context of manuscript peer review (including, for journal publication). Literature and our expert consultation show that journals frequently experiment with new interventions and assess the results of the experiments. Examples include efforts to improve the review process through open peer review (making reviews public) and improving the quality and reliability of peer review through training reviewers.</p>
<p>Literature on manuscript peer review shows improvements in review reliability in terms of identification of errors or recommending manuscripts for rejection after the introduction of reviewer training.</p>
<p>Although not without controversy (for example concerns about less critical comments if the review is open), manuscript peer review may provide examples worth considering for research funders, even though it is beyond the scope of this review.</p>
<p>Another example is scientific publishers reacting quickly and introducing rules and guidance to specify the use of large language models (AI algorithms like ChatGPT) in manuscript preparation and review process. Several consulted research funders were concerned about the impact of large language models on research funding processes. Examples of addressing the matter in manuscript peer review might be worth considering.</p>
<p>It must also be noted that grant peer review processes like interviews and panels make it more complicated and difficult to compare to journal peer review. Grant peer review and journal peer review happen at different stages of the research process. Journal peer review looks at completed work, while grant peer review looks at proposed work.</p>
<h2 id="section-main-findings:-interventions-prior-to-a-funding-opportunity">Main findings: interventions prior to a funding opportunity</h2><h3>Assessment criteria definition</h3>
<p>Adding assessment criteria additional to conventional ones, may involve a tiered system for assessment criteria for example, essential versus desirable.</p>
<h4>Main intended aims</h4>
<p>The main aim is to: increase relevance of funded project to funding opportunity aims.</p>
<h4>Main hazards</h4>
<p>The hazards include that:</p>
<ul>
<li>reviewers may not follow guidance</li>
<li>too many criteria risk overcomplicating discussions</li>
</ul>
<h4>Evidence strength</h4>
<p>Three star</p>
<h4>Findings</h4>
<p>This intervention may include:</p>
<ul>
<li>clear guidance with definitions of criteria</li>
<li>non-biased language (for example, gender) and weighting of criteria</li>
<li>ensuring criteria are suitably discussed and applied during panel meetings</li>
</ul>
<p>The aim is to make sure that proposals are assessed according to the intended criteria, and therefore to the aims of the funding opportunity. Emphasis is on increasing transparency, consistency, simplification, as well as the need to ensure that the selection reflects the objectives of the specific funding scheme (especially when including new criteria that might be undervalued).</p>
<p>Impact evaluation of one scheme shows the effectiveness of the intervention in supporting projects aimed at achieving non-academic impact. In a small number of cases, consultees were hesitant about publicly sharing certain examples, this is one such case. However, it cannot be attributed solely to the criteria. Funders have observed that this approach meant they funded projects that went on to have impact, and that these would not have been funded if the assessment was purely based on an assessment of research quality.</p>
<p>Several authors appear to agree that more explicit criteria are desirable to avoid bias and inconsistency. However, the evidence also highlights a perception that criteria that go beyond research excellence can still be challenging for reviewers, panellists, or both, to apply. There is also a limit to the number and complexity of criteria that panels can handle.</p>
<p>Further, behaviour of reviewers does not necessarily conform to guidance. Evidence suggests that external reviewers pay more attention to written guidance than panel members.</p>
<h4>References</h4>
<p><a href="https://doi.org/10.1371/journal.pone.0046054">Peer Review of Grant Applications: Criteria Used and Qualitative Study of Reviewer Practices</a>. Abdoul H, Perrey C, Amiel P, Tubach F, Gottot S, Durand-Zaleski I, and Alberti C.</p>
<p><a href="https://doi.org/10.1057/s41599-020-0412-9">Criteria for assessing grant applications: a systematic review</a>. Hug SE, and Aeschbach M.</p>
<p><a href="https://doi.org/10.1093/reseval/rvab034">Do peers share the same criteria for assessing grant applications?</a> Hug SE, and Ochsner M.</p>
<p><a href="https://doi.org/10.1177/030631201031006002">The decision-making constraints and processes of grant peer review, and their effects on the review outcome.</a> Langfeldt L.</p>
<p><a href="https://doi.org/10.2777/16211">Study on the proposal evaluation system for the EU R&amp;I framework programme</a>. Rodriguez-Rincon D, Feijao C, Stevenson C, Evans H, Sinclair A, Thomson S, and Guthrie S.</p>
<p><a href="https://doi.org/10.1503/cmaj.170901">Assessment of potential bias in research grant peer review in Canada</a>. Tamblyn R, Girard N, Qian CJ and Hanley J.</p>
<h4>Interviewees and survey responses</h4>
<p>Two survey responses</p>
<p>Two interviews</p>
<h3>Demand management: individuals (1)</h3>
<p>Limiting researchers to being a lead investigator only on one project or application at a time.</p>
<h4>Main intended aims</h4>
<p>The main aim is to reduce application numbers and concentration of awards.</p>
<h4>Main hazards</h4>
<p>The main hazards are that:</p>
<ul>
<li>it shifts burden to other funders</li>
<li>savings are minimal</li>
</ul>
<h4>Evidence strength</h4>
<p>One star</p>
<h4>Findings</h4>
<p>Many funders limit applicants to one application per funding opportunity. However, this may be expanded to one application across the fundersâ€™ entire portfolio. This intervention is intended to reduce the number of applications (by limiting or excluding the participation of current awardees). There may also be a motivation to limit the concentration of awards to a small number of continuously successful researchers.</p>
<p>This intervention is rare, not least as it requires a comprehensive research information system (preferably covering multiple funders so that applications cannot be resubmitted to other funders instead). There is ongoing use at the Swedish Research Council, though no assessments or feedback could be identified.</p>
<p>Our research also highlights sceptical views around this intervention. The Royal Society has stated that it does not support disincentives to apply for funding in the first place (though this statement is from 2007). In addition, a Rand report concluded that savings gained from individual targeting restrictions were marginal if proposals became complex as a result, and recommended institutional quotas for more substantive savings. As noted above, resubmission to other funders is a risk, so burden and application-influx is shifted rather than lessened.</p>
<p>Most UK-based evidence we find is from around 2006 to 2007 after the publication of a peer review report by Research Councils UK (RCUK, UKRIâ€™s precursor). It does not appear to be a heavily studied intervention or one for which there is much â€˜appetiteâ€™.</p>
<h4>References</h4>
<p><a href="http://eprints.lse.ac.uk/88207/">The effects of funding policies on academic research</a>. Grove L.</p>
<p><a href="https://www.rand.org/pubs/technical_reports/TR742.html">Evaluating Grant Peer Review in the Health Sciences: A review of the literature</a>. Ismail S, Farrands A, and Wooding S.</p>
<p><a href="https://webarchive.nationalarchives.gov.uk/ukgwa/20130804092441/http://www.rcuk.ac.uk/documents/documents/rcukprreport.pdf">Report of the Research Councils UK Efficiency and</a><br>
<a href="https://webarchive.nationalarchives.gov.uk/ukgwa/20130804092441/http://www.rcuk.ac.uk/documents/documents/rcukprreport.pdf">Effectiveness of Peer Review Project</a>. Research Councils UK.</p>
<p><a href="https://royalsociety.org/topics-policy/publications/2007/peer-review-effectiveness/">Response to the RCUK consultation on the Efficiency and Effectiveness of Peer Review</a>. Royal Society.</p>
<p><a href="https://www.vr.se/english/applying-for-funding/applying-for-a-grant/several-grants-simultaneously.html">Several grants simultaneously</a>. Swedish Research Council.</p>
<p><a href="https://www.vr.se/english/applying-for-funding/applying-for-a-grant/several-grants-simultaneously.html">What requirements apply if I already have a grant from the Swedish Research Council</a>. Swedish Research Council.</p>
<h4>Interviewees and survey responses</h4>
<p>No survey responses or interviews</p>
<h3>Demand management: individuals (2)</h3>
<ul>
<li>Having a â€˜time outâ€™ period of a year, so that after an unsuccessful application, the applicant is not allowed to apply the following year. Based on previous behaviour and includes an element of quality control</li>
</ul>
<h4>Main intended aims</h4>
<p>The main aims are to:</p>
<ul>
<li>limit application volume</li>
<li>increase success rates</li>
<li>save burden</li>
</ul>
<h4>Main hazards</h4>
<p>The main hazards are that:</p>
<ul>
<li>it may simply shift resubmission to other funders</li>
<li>it may not be well received by applicant community</li>
</ul>
<h4>Evidence strength</h4>
<p>Two star</p>
<h4>Findings</h4>
<p>This intervention aims to control application-based demand (for example, application volume and overall success rates) and reduce the workload for funders and reviewers.</p>
<p>The Engineering and Physical Sciences Research Council (EPSRC) already operates a variant of this intervention. For the EPSRC variation any investigator that is repeatedly unsuccessful in the preceding two years will be written to and limited to just one application in the following 12 months.</p>
<p>This approach has received positive feedback from reviewers and senior university personnel. Paired with the approach to ban identical resubmissions, it has been found to reduce application volumes.</p>
<p>Some comments note that researchers suffering from biases may be put in an increasingly disadvantaged position. They also note that this approach may damage individualsâ€™ confidence, experience, career, and wellbeing, though this has not been studied (logically though, it appears plausible that this approach would penalise at least some potential applicants).</p>
<p>In the absence of comprehensive international research information systems, it is also impossible to control for researchers resubmitting applications to other funders. While this approach therefore limits burden for the funder in question, it is unlikely to lead to burden reduction in the wider research system.</p>
<p>Our research indicates that introducing this intervention has occasionally been controversial. Generally, it appears to divide researchers (especially early career researchers) on the one hand, and funders or senior personnel on the other, who typically view the approach fairly positively. However, this assessment is based on various pieces of anecdotal evidence only.</p>
<h4>References</h4>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/22859184/">Science funding: Duel to the death</a>. Bhattacharya A.</p>
<p><a href="https://jpands.org/vol24no4/huntoon.pdf">Sham Peer Review: the Destruction of Medical Careers (PDF, 37KB).</a> Huntoon L R.</p>
<p><a href="https://doi.org/10.1186/s41073-022-00120-2">What works for peer review and decision-making in research funding: a realist synthesis</a>. Recio-Saucedo A, Crane K, Meadmore K, Fackrell K, Church H, Fraser S, and Blatch-Jones A.</p>
<p><a href="https://doi.org/10.1038/464465a">Tough love</a>. Nature</p>
<h4>Interviewees and survey responses</h4>
<p>Two survey responses</p>
<p>Four interviews</p>
<h3>Demand management: institutions</h3>
<p>Limiting the number of applications or resubmissions accepted from a single institution.</p>
<h4>Main intended aims</h4>
<p>The main aims are to:</p>
<ul>
<li>limit application volume</li>
<li>increase success rates</li>
<li>save burden in the funder and reviewer community</li>
</ul>
<h4>Main hazards</h4>
<p>The main hazards are that:</p>
<ul>
<li>it largely shifts burden to institutions</li>
<li>potential additional bias, depending on institutional processes</li>
</ul>
<h4>Evidence strength</h4>
<p>Four star</p>
<h4>Findings</h4>
<p>This intervention aims to reduce workload and administrative burden for the funder and reviewer community. Key indicators would be the number of applications received (lower than without this intervention) and a higher application success rate.</p>
<p>This intervention is known to accomplish what it intends. Variations are in continued use in multiple funding organisations in US and Europe. Examples include:</p>
<ul>
<li>the Natural Environment Research Council (NERC) limits the number of applications per institution where the HEI in question has failed to meet a 20% success rate over the six most recent grant rounds</li>
<li>the European Society for Paediatric Research allows an unlimited number of applications, but only awards one per institution</li>
<li>National Institutes of Health (NIH) allows two applications per institution in the Directorâ€™s Early Independence Awards</li>
<li>the Economic and Social Research Council (ESRC) allows a limited number of applications per institution for its research centres competition (alongside the use of outline proposals)</li>
<li>the US National Science Foundation (NSF) allows three expressions of interest (EoIs) per institution, of which a maximum of one can result in an invite to submit a full proposal</li>
</ul>
<p>The National Natural Science Foundation of China (NSFC) has a different version of demand management. The 2011 evaluation of the NSFC noted that applicants submit their proposals via their host institution and they may not submit them directly to NSFC. An applicant may not apply more than once per year to any single NSFC programme or hold more than three NSFC grants at the same time (this example is also relevant to the previous section).</p>
<p>This approach is known to have reduced the number of applications in cases of schemes that had previous funding rounds without the intervention.</p>
<p>A major problem with this intervention consistently mentioned throughout the evidence is that it largely shifts selection burden from the funder to the institution. The institution may opt for a more limited reviewing procedure, thus still reducing overall burden to some extent. However, there is also some anecdotal evidence that institutions may be less experienced in some aspects of selection processes, leading to suboptimal outcomes.</p>
<p>This intervention is not passionately debated in one way or the other. Most sources agree on the strengths and hazards of this approach, however there are naturally conflicting interests between funders and research performing organisations on this. As a practice, it is in use in multiple contexts, though it appears to be quite commonplace in the US especially, particularly in funding opportunities aimed at early career researchers. We also note this approach has often been found paired with use of â€˜expressions of interestâ€™.</p>
<h4>References</h4>
<p><a href="https://www.researchgate.net/publication/337440748_International_Evaluation_of_the_Funding_and_Management_of_the_National_Natural_Science_Foundation_of_China">International Evaluation of the Funding and Management of the National Natural Science Foundation of China</a>. Arnold E, Lu Y, and Xue L.</p>
<p><a href="https://www.espr.eu/funding/research_grant_programme.php">ESPR Research Grant Programme 2017 to 2022</a>. ESPR.</p>
<p><a href="https://research.blogs.lincoln.ac.uk/2016/08/03/esrc-large-grants-competition-201617-update/">ESRC â€“ Large Grants Competition 2016/17 (Update). University of Lincoln: Research Blog</a>. Mycroft C.</p>
<p><a href="/councils/nerc/guidance-for-applicants/types-of-funding-we-offer/discovery-science/demand-management/">Demand management</a>. NERC.</p>
<p><a href="http://www.sciencepolicyjournal.org/article_1038126_jspg180105.html">Towards inclusive funding practices for early career researchers</a>. de Winde CM, Sarabipour S, Carignano H, Davla S, Eccles D, Hainer SJ, Haidar M, Ilangovan V, Jadavji NM, Kritsiligkou P, Lee T-Y, and Ã“lafsdÃ³ttir H F.</p>
<h4>Interviewees and survey responses</h4>
<p>One survey response</p>
<p>No interviews</p>
<h3>Working with underrepresented groups</h3>
<p>Providing additional support to groups that are unrepresented in the funderâ€™s portfolio to encourage them to apply and support them as they do, with the view to increasing diversity.</p>
<h4>Main intended aims</h4>
<p>The main aim is to increase diversity of applicants and award winners.</p>
<h4>Main hazards</h4>
<p>The main hazards are:</p>
<ul>
<li>may take some time to show effect</li>
<li>may entail administrative burden</li>
</ul>
<h4>Evidence strength</h4>
<p>Four star</p>
<h4>Findings</h4>
<p>This intervention intends to increase the number of applicants (and their success rate when applying for an award) of underrepresented groups, for example, ethnic minority groups or younger or early career researchers.</p>
<p>The Arts and Humanities Research Councilâ€™s (AHRC) 2020 to 2022 Equality, Diversity and Inclusion Engagement Fellowship (EDIEF) pilot specifically targeted arts and humanities researchers whose work has a significant equality, diversity and inclusion (EDI) dimension. The funding opportunity sought to enable researchers to engage a variety of relevant stakeholders with their research, to embed their work into policy and practice, and to work with relevant communities to realise the full potential benefits of their research.</p>
<p>The intervention emerged as a response to previous studies identifying barriers to collaborative research partnerships with the minority ethnic communities (common cause research) and a commitment to improving EDI. An evaluation of the pilot showed that 28% of applicants were Asian, Black or mixed ethnicity, while only 9% of applicants to the standard research grant scheme were from an ethnic minority.</p>
<p>The UK Equality Challenge Unit (ECU) launched the Athena SWAN charter in 2005 to recognise universitiesâ€™ work to improve gender equality and diversity of women in science, technology, engineering, medicine, and mathematics. As a voluntary action, universities are not set with goals, but are instead encouraged to assess their current gender gaps and adopt measures to reduce disparities.</p>
<p>The Athena SWAN Charter offers different levels of accreditation (bronze, silver and gold) to universities depending on the type of interventions and strategies adopted to alleviate gender gaps. Universities need to gain Athena SWAN Charter membership first to apply for accreditation. For the bronze accreditation, universities undertake an assessment of gender disparities and propose a five-year plan to address this. Silver recognition requires the implementation of specific actions, while gold is awarded to those achieving or improving gender parity levels.</p>
<p>In 2011, the National Institute for Health Research (NIHR) linked its research funding for biomedical research centres to actions towards gender equality through the Athena SWAN charter. In 2016, academic institutions had to hold at least silver accreditation to be shortlisted for funding. This intervention led to an increase in women theme leads from 8% in 2006 to 24% in 2016. It may also have contributed to the increase in the number of universities in the field implementing action plans from one in 2011 to 69 in 2016. According to the literature, this intervention has been replicated by funders and science organisations in Ireland, Australia, the US and Canada.</p>
<p>A final example found in the literature is the National Research Mentoring Network delivered by the NIH (US) as part of the â€˜Diversity Program Consortiumâ€™. It is reported that intensive and sustained training of early career researchers of underrepresented minority groups can help participants to achieve the benchmarks of proposal submission and funding. This mentoring can also have an impact on other areas, such as teaching.</p>
<p>Our interviewees also note that using positive language to encourage womenâ€™s participation has led to an increase in the number of applications from women.</p>
<p>Action to improve not just the application but the success rate of underrepresented groups is a rather broader issue with many possible techniques. Most notably we come back to this issue when we address anonymised reviewing, as well as various training interventions covered in the latter parts of this report.</p>
<p>However, on a final point here it is worth mentioning efforts to diversify reviewers. In its 2022 Race and Ethnicity Inequity report, EPSRC noted its action to increase the representation of ethnic minority researchers on its peer review college to 20%. This would be done by actively encouraging self-nominations to the peer review college from all researchers but particularly seeking nominations from minority ethnic researchers. In the first six months of the campaign, EPSRC observed a positive response with a 2.5 times increase in self-nominations compared to the previous year.</p>
<p>There is general agreement on the benefits and effectiveness of the intervention. However, while not noted explicitly in the literature, these actions are likely to take time, which can limit their applicability. There is also an associated administrative burden, which, according to some sources, may be disproportionately carried out by women.</p>
<p>We note as a general comment on the evidence that historically, much of the literature around this intervention has focused mostly on gender. However, among the more recent sources we have considered here, race or ethnicity and age also feature quite strongly.</p>
<h4>References</h4>
<p><a href="http://oro.open.ac.uk/87420/">The Equality, Diversity and Inclusion Engagement Fellowship Pilot AHRC funding scheme report 2020 to 2022</a>. Blackburn, M., Coutinho K, and Suviste H.</p>
<p><a href="/publications/ethnicity-and-race-inequity-in-our-portfolio/">Ethnicity and race inequity in our portfolio: findings of our community engagement and actions for change</a>. EPSRC.</p>
<p><a href="https://doi.org/10.2139/ssrn.3390198">Gender equality and positive action: evidence from UK universities</a>. Gamage DDK, and Sevilla A.</p>
<p><a href="https://www.researchgate.net/publication/318283822_Positive_Action_Towards_Gender_Equality_Evidence_from_the_Athena_SWAN_Charter_in_UK_Medical_Schools">Positive action towards gender equality? Evidence from the Athena SWAN Charter in UK Medical Schools.</a> Gregory-Smith I.</p>
<p><a href="https://www.bmj.com/content/371/bmj.m3975">Effect of Athena SWAN funding incentives on womenâ€™s research leadership</a>. Ovseiko PV, Taylor M, Gilligan RE, Birks J, Elhussein L, Rogers M, Tesanovic S, Hernandez J, Wells G, Greenhalgh T and Buchan AM.</p>
<p><a href="https://doi.org/10.2777/16211">Study on the proposal evaluation system for the EU R&amp;I framework programme</a>. Rodriguez-Rincon D, Feijao C, Stevenson C, Evans H, Sinclair A, Thomson S and Guthrie S.</p>
<p><a href="https://doi.org/10.1007/s10734-020-00626-y">The leaky pipeline in research grant peer review and funding decisions: challenges and future directions</a>. Sato S, Gygax PM and Randall J.</p>
<p><a href="https://doi.org/10.1371/journal.pone.0241851">Grant application outcomes for biomedical researchers who participated in the National Research Mentoring Networkâ€™s Grant Writing Coaching Programs</a>. Weber-Main AM, McGee R, Eide Boman K, Hemming J, Hall M and Unold T.</p>
<h4>Interviewees and survey responses</h4>
<p>No survey responses</p>
<p>Two interviews</p>
<h2 id="section-main-findings:-interventions-in-assessment-process-design">Main findings: interventions in assessment process design</h2><h3>â€˜Sandpitsâ€™ or matching events</h3>
<p>Potential applicants are invited to an event to discuss possibilities and form teams for potential proposals. May involve some application submission on the day.</p>
<h4>Main intended aims</h4>
<p>The main aim is to foster inter- or multidisciplinary research, new collaborations and transformative research</p>
<h4>Main hazards</h4>
<p>The hazards include:</p>
<ul>
<li>problems for access, EDI issues</li>
<li>can be partially resolved through remote events</li>
</ul>
<h4>Evidence strength</h4>
<p>Four star</p>
<h4>Findings</h4>
<p>This intervention intends to foster interdisciplinary research and more innovative proposals and solutions to research challenges, particularly when seeking to promote transformative research.</p>
<p>EPSRC has used the Ideas Factory Sandpit for over 10 years with positive outcomes in terms of the establishment of research communities. There is an observable culture change amongst participants embracing creativity and originality and an increase in the capacity of multidisciplinary researchers and their interaction in the UK.</p>
<p>EPSRC has also run sandpits at distance (remote) with positive results. For respondents, this intervention creates opportunities for building new multidisciplinary partnerships and foster blue-skies ideas.</p>
<p>The EPSRC sandpits also include elements of group review, so this example also pertains to the group review section (5.13) of this report. However, we focus on the collaboration-building aspect of the sandpits.</p>
<p>There are however some negative effects from an EDI perspective reported in the literature and from consultees due to the sandpitsâ€™ setup. Intensive face-to-face interaction, mostly away from home, with durations of one-to-five days reduces the opportunities of participation of those with caring responsibilities and potentially for those with disabilities or sensory needs.</p>
<p>Remote sandpits offer more flexibility but do not overcome all the limitations identified. EPSRC implemented a number of further mitigation measures including:</p>
<ul>
<li>inviting and paying for carers to sandpits to enable the applicant to attend</li>
<li>adapting the facilitation style of the sandpit to make it more accessible</li>
<li>embedding more breaks into the sandpit and changing the model of the sandpit to be accessible virtually over a different timescale to ensure a reduction in screen time</li>
</ul>
<p>There is clear evidence and strong agreement on the positive impact of sandpits or matching events on fostering multidisciplinary research and innovative solutions to research challenges. Sources also converge on limitations and negative effects for EDI, though the mitigation efforts noted above may provide important ways forward.</p>
<h4>References</h4>
<p><a href="https://rori.figshare.com/articles/report/The_experimental_research_funder_s_handbook_final_version_/19459328">The experimental research funderâ€™s handbook, Research on Research Institute</a>. Bendiscioli S.</p>
<p><a href="https://www.rand.org/pubs/research_reports/RR139.html">Alternatives to peer review in research project funding</a>. Guthrie S, Guerin B, Wu H, Ismail S and Wooding S.</p>
<p><a href="https://petranetwork.org/resources/sandpit-methodology-a-rapid-literature-search-to-inform-a-sandpit-exercise-for-petra/">Sandpit methodology: results of a rapid literature search to inform a sandpit exercise for PETRA</a>. Lodge H.</p>
<p><a href="https://doi.org/10.1057/s41599-018-0105-9">Sandpits can develop cross-disciplinary projects, but funders need to be as open-minded as researchers</a>. Maxwell K, Benneworth P and Siefkes M.</p>
<p><a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0239757">Decision-making approaches used by UK and international health funding organisations for allocating research funds: a survey of current practice</a>. Meadmore K, Fackrell K, Recio-Saucedo A, Bull A, Fraser SDS and Blatch-Jones A.</p>
<p><a href="https://doi.org/10.1186/s41073-022-00120-2">What works for peer review and decision-making in research funding: a realist synthesis. Research integrity and peer review</a>. Recio-Saucedo A, Crane K, Meadmore K, Fackrell K, Church H, Fraser, S and Blatch-Jones A.</p>
<p><a href="https://doi.org/10.1016/j.ijhcs.2015.10.006">Creativity greenhouse: at-a-distance collaboration and competition over research funding</a>. SchnÃ¤delbach H, Sun X, Kefalidou G, Coughlan T, Meese R, Norris J and McAuley D.</p>
<p><a href="https://doi.org/10.1017/cts.2018.311">Exploring the potential role of community engagement in evaluating clinical and translational science grant proposals</a>. Treem JW, Schneider M, Zender RL and Sorkin DH.</p>
<h4>Interviewees and survey responses</h4>
<p>Three survey responses</p>
<p>Two interviews</p>
<h3>Two-stage application process</h3>
<p>Two â€˜roundsâ€™ of peer or panel review are used, sifting out some after the first stage. May involve different parts of the application being reviewed at different stages, or a pre-proposal or expression of interest (see above).</p>
<h4>Main intended aims</h4>
<p>Reduce burden for reviewers, applicants and programme officers, increase relevance of stage-two proposals</p>
<h4>Main hazards</h4>
<p>Slight danger of reduced levels of feedback.</p>
<h4>Evidence strength</h4>
<p>Four star</p>
<h4>Findings</h4>
<p>This intervention is strongly linked to the â€˜pre-proposal or expression of interestâ€™ intervention. Often, they may be interchangeable. Stage one may involve a pre-proposal, though it is also possible that the same proposal document will be reviewed at stage one and stage two. In such cases, this intervention is distinct. Review at the first stage is typically conducted by a review panel (often specifically put together for the funding opportunity to reflect the thematic nature of the applications), though in some cases remote reviewers are also used.</p>
<p>The purpose of this intervention is to reduce overall burden of the evaluation process (on applicants, administrators and reviewers). It is also used to sift out applications that do not meet particular requirements (for example, out of scope).</p>
<p>There are verified positive outcomes from this intervention for both funders and applicants. Wellcome has adopted it and become a regular practice in their evaluation process, reducing burden on written review by 50%. NIHR adopted it with successful results including:</p>
<ul>
<li>increased number of applications</li>
<li>reduced number of applications per reviewer</li>
<li>lower cost per evaluation round (40% reduction)</li>
<li>shorter notification periods to applicants</li>
</ul>
<p>There is wide agreement among our sources and consultees on the positive effects of this intervention, sifting out applications that do not meet programme requirements. The only noted concerns are about limited feedback to first stage applications, meaning overall less feedback in the research system and consequent less scope for learning.</p>
<p>Some scepticism was voiced during the study of the Horizon 2020 proposal assessment process, where the study team found that the length of the stage two applications did not significantly differ from single-stage applications. Therefore they claimed that at least 65% of stage one applications must be rejected in order for the overall process to reduce the burden rather than increase it.</p>
<h4>References</h4>
<p><a href="https://doi.org/10.1186/s12913-015-0721-7">Streamlined research funding using short proposals and accelerated peer review: an observational study</a>. Barnett AG, Herbert DL, Campbell M, Daly N, Roberts JA., Mudge A and Graves N.</p>
<p><a href="https://doi.org/10.1126/science.353.6299.528">NSF tries two-step review, drawing praise â€“ and darts</a>. Mervis J.</p>
<p><a href="https://doi.org/10.1371/journal.pone.0230118">Assessing health research grant applications: a retrospective comparative review of a one-stage versus a two-stage application assessment process</a>. Morgan B, Yu LM, Solomon T and Ziebland S.</p>
<p><a href="https://doi.org/10.1017/cts.2018.311">Exploring the potential role of community engagement in evaluating clinical and translational science grant proposals. Journal of Clinical and Translational Science</a>. Treem JW, Schneider M, Zender RL and Sorkin DH.</p>
<p><a href="https://doi.org/10.2777/16211">Study on the proposal evaluation system for the EU R&amp;I framework programme</a>. Rodriguez-Rincon D, Feijao C, Stevenson C, Evans H, Sinclair A, Thomson S and Guthrie S.</p>
<h4>Interviewees and survey responses</h4>
<p>Three survey responses</p>
<p>Three interviews</p>
<h3>Applicant anonymisation</h3>
<p>Reviewers or panels members or both do not see the identity of the applicant or applicants.</p>
<h4>Main intended aims</h4>
<p>Reduce bias, foster innovative or transformative ideas.</p>
<h4>Main hazards</h4>
<p>The main hazard is a limited ability to judge feasibility of projects.</p>
<h4>Evidence strength</h4>
<p>Four star</p>
<h4>Findings</h4>
<p>This intervention aims to reduce bias (for example, in relation to institution, gender, career stage, etc.), and to focus reviewersâ€™ attention on project idea rather than person to identify and fund more unconventional research.</p>
<p>This intervention is widely used. Among the examples we find are:</p>
<ul>
<li>the NIH Directorâ€™s Transformative Research Award</li>
<li>EPSRCâ€™s New Horizons scheme</li>
<li>ESRCâ€™s Transformative Research Scheme (currently paused)</li>
<li>the New Zealand HRC Explorer Grant</li>
</ul>
<p>It is also in use at the Austrian Science Fund (FWF), VW Foundation (where it is variously paired with other interventions), and it has been piloted at the Swiss SNSF.</p>
<p>SNSFâ€™s Spark Fund evaluation found that anonymising applications attracts more unconventional research ideas. Evidence from VW foundation also shows increased success rates for women applicants and early career researchers. Similarly, using anonymisation in the FWFâ€™s 1000 Ideas programme attracted a more diverse pool of applicants than other programmes. Anonymisation is generally considered a â€˜gold standardâ€™ for reducing bias.</p>
<p>There is however some evidence to suggest that in the absence of personal information to judge the suitability of the applicants, reviewers or panellists sometimes report that they struggle to assess feasibility of projects from this point of view (though â€˜feasibilityâ€™ as an assessment criterion usually covers aspects besides applicantsâ€™ abilities). FWF also reported instances of some jury members saying they knew who the applicant was and why they should be funded. FWF then reminds the jury that this information is irrelevant to this assessment process.</p>
<p>There is also evidence to suggest that not all bias is eliminated through applicant anonymisation. One reviewed study finds that men and women tend to use language differently and reviewers reward some language uses more associated with men. FWF reported that some applications included information about affiliation by accident, for example, referring to the ethics policy of a particular university.</p>
<p>Our research also finds that anonymisation is often coupled with other interventions, and that funders suspect it may be the combination rather than necessarily the intervention by itself that leads to positive outcomes (includes review without panel and partial randomisation). A separate application stage that is not anonymised can help mitigate the issue around judging feasibility (as practiced in ESRCâ€™s Transformative Research scheme).</p>
<h4>References</h4>
<p><a href="https://rori.figshare.com/articles/report/The_experimental_research_funder_s_handbook_final_version_/19459328">The experimental research funderâ€™s handbook, Research on Research Institute</a>. Bendiscioli S, Firpo T, Bravo-Biosca A, Czibor E, Garfinkel M, Stafford T, Wilsdon J, Buckley Woods H and Balling GV.</p>
<p><a href="https://pubsonline.informs.org/doi/10.1287/mnsc.2015.2285">Looking across and looking beyond the knowledge frontier: intellectual distance, novelty, and resource allocation in science</a>. Boudreau K, Guinan E, Lakhani K and Riedl C.</p>
<p><a href="https://doi.org/10.12688/f1000research.11917.2">What do we know about grant peer review in the health sciences?</a> Guthrie S, Ghiga I and Wooding S.</p>
<p><a href="http://www.nber.org/papers/w25759">Is blinded review enough? How gendered outcomes arise even under anonymous evaluation</a>. Kolev J, Murray Y and Fuentes-Medel F.</p>
<p><a href="https://doi.org/10.1287/mnsc.2021.4107">Conservatism gets funded? A field experiment on the role of negative information in novel project evaluation</a>. Lanei JN, Teplitskiy M, Gray G, Ranu H, Menietti M, Guinan EC and Lakhani KR.</p>
<p><a href="https://nifu.brage.unit.no/nifu-xmlui/handle/11250/2995910">Evaluation of the Spark pilot.</a> Langfeldt L, Ingeborgrud L, Reymert I, Svartefoss SM and Borlaug SB.</p>
<p><a href="https://nexus.od.nih.gov/all/2020/05/27/anonymizing-peer-review-for-the-nih-directors-transformative-research-award-applications/">Anonymizing peer review for the NIH Directorâ€™s Transformative Research Award Applications</a>. Lauer M.</p>
<p><a href="https://www.timeshighereducation.com/news/german-funder-sees-early-success-grant-lottery-trial">German funder sees early success in grant-by-lottery trial</a> Matthews D.</p>
<p><a href="https://doi.org/10.7554/eLife.71368">An experimental test of the effects of redacting grant applicant identifiers on peer review outcomes</a>. Nakamura R, Mann LS, Lindner MD, Braithwaite J, Chen MC, Vancea A, Byrnes N, Durrant V and Reed B.</p>
<p><a href="https://doi.org/10.2777/16211">Study on the proposal evaluation system for the EU R&amp;I framework programme</a>. Rodriguez-Rincon D, Feijao C, Stevenson C, Evans H, Sinclair A, Thomson S and Guthrie S.</p>
<p><a href="https://academic.oup.com/rev/article/26/3/181/3858258">Blinding applicants in a first-stage peer-review process of biomedical grants: an observational study</a>, Solans-Domenech M, GuillamÃ³n I, Ribera A, Ferreira-GonzÃ¡lez I, Carrion C, Permanyer-Miralda G and Pons JMV.</p>
<p>One additional confidential UKRI document shared for information with the study.</p>
<h4>Interviewees and survey responses</h4>
<p>One survey response</p>
<p>Four interviews</p>
<h3>Automation-assisted reviewer allocation</h3>
<p>Using algorithms, AI or text recognition to aid allocation of reviewers to applications.</p>
<h4>Main intended aims</h4>
<p>The main aims are:</p>
<ul>
<li>to increase efficiency or reduce burden in reviewer allocation</li>
<li>better matching of applications to reviewers</li>
</ul>
<h4>Main hazards</h4>
<p>The main hazards are that:</p>
<ul>
<li>the technology is not widely tested</li>
<li>some algorithms may have problems</li>
</ul>
<h4>Evidence strength</h4>
<p>Three star</p>
<h4>Findings</h4>
<p>This is an intervention that has become possible with some modern application management systems. It typically involves matching applicationsâ€™ keywords or other machine-readable details to reviewers who are associated with those keywords (for example, via applications they have reviewed in the past).</p>
<p>We use the term â€˜automation-assistedâ€™ rather than just â€˜automatedâ€™ to denote that a human element still remains in the process at all times. Meaning that whatever the automated system recommends still needs to be checked by funder staff.</p>
<p>The objective of this approach is to increase efficiency in expert allocation, to reduce administrative burden, and enable a higher degree of quality in application reviews due to identifying the most knowledgeable experts on the topics. It may also lead to a decrease in declined review invitations (reviewers declining due to subject matter being outside their expertise). This technology can also be used to identify potential conflicts of interest.</p>
<p>Automation-assisted reviewer allocationÂ is in ongoing use at the Australian Research Council (ARC) with reported satisfaction. We find mentions of previous use at the Canadian Institutes of Health Research but with poorer reception, although a review study suggests this is due to avoidable challenges with implementation.</p>
<p>The Research Council of Norway (RCN) uses an online tool to find experts to assess applications. RCN reports significant time savings and access to a broader pool of reviewers. In addition, we find anecdotes of numerous instances of use in journal peer review with a high level of reviewer satisfaction.</p>
<p>In short, this is a very promising intervention. We find no difficulties at a general level. However, it may be subject to pitfalls simply because it is a relatively new technological approach. For example, if reviewers are identified based on past reviews, then there is a potential challenge around how to integrate new first-time reviewers into the system. It is not an insurmountable challenge, but one that requires consideration.</p>
<p>The approach has been studied (and algorithms have been developed), but implementation so far is somewhat limited. However, we note that we found no high-profile announcements of implementation even where it had occurred, so it is possible that it is used more than it appears. Potential hazards can likely be avoided through sharing of successful algorithms and technical procedures by funders who have had positive results.</p>
<h4>References</h4>
<p><a href="https://www.researchgate.net/publication/259635940_Assigning_evaluators_to_research_grant_applications_The_case_of_Slovak_Research_and_Development_Agency">Assigning evaluators to research grant applications: the case of Slovak Research and Development Agency</a>. CechlÃ¡rovÃ¡ K, Fleiner T and PotpinkovÃ¡ E.</p>
<p><a href="https://academyhealth.org/publications/2019-11/innovating-research-funding-process-peer-review-alternatives-and-adaptations">Innovating in the research funding process: peer review alternatives and adaptations</a>. Guthrie S.</p>
<p><a href="https://dl.acm.org/doi/abs/10.1007/s11192-020-03519-0">An algorithm for automatic assignment of reviewers to papers.</a> Kalmukov Y.</p>
<p><a href="https://www.researchgate.net/publication/333853175_How_Research_Funders_Ensure_the_Scientific_Legitimacy_of_their_Decisions_Investigation_in_support_of_the_design_of_Formas_scientific_management">How research funders ensure the scientific legitimacy of their decisions: investigation in support of the design of formas</a>. Kolarz P, Arnold E, DavÃ© A, Andreasson H and Bryan B.</p>
<p><a href="https://www.technopolis-group.com/wp-content/uploads/2020/02/Support-to-the-generation-of-a-Research-and-Innovation-Funding-Service.pdf">UKRI Research and Innovation Funding Service (RIFS) visioning work</a>. Kolarz P.</p>
<p><a href="https://doi.org/10.3233/978-1-61499-432-9-950">A semi-automatic web based tool for the selection of research projects reviewers</a>. Pupella V, Monteverde ME, Lombardo C, Belardelli F and Giacomini M.</p>
<p><a href="https://doi.org/10.1186/s41073-022-00120-2">What works for peer review and decision-making in research funding: a realist synthesis, Research Integrity and Peer Review</a>, Recio-Saucedo A.</p>
<p>One additional confidential UKRI document shared for information with the study.</p>
<h4>Interviewees and survey responses</h4>
<p>No survey responses</p>
<p>One interview</p>
<h3>Dragonâ€™s den-style pitch</h3>
<p>Applicants are invited to pitch their proposal in front of a panel, and panels have an opportunity to ask questions. This differs from an interview in that no other form of evidence (for example, written proposals or external expert review) is used in the assessment.</p>
<h4>Main intended aims</h4>
<p>The main aims are to:</p>
<ul>
<li>increase stakeholder involvement</li>
<li>fund novel, transformative ideas</li>
</ul>
<h4>Main hazards</h4>
<p>The main hazards are that it:</p>
<ul>
<li>favours applicants with sharp presenting skills</li>
<li>may present access problems</li>
</ul>
<h4>Evidence strength</h4>
<p>One star</p>
<h4>Findings</h4>
<p>This intervention seeks to provide an innovate way of funding allocation by facilitating stakeholder engagement with the research ideas. Fostering more diverse and transformative research projects has also been noted as an aim here, though â€˜transformativeâ€™ may here suggest societal transformation rather than transformation of scientific practice itself.</p>
<p>EPSRC has used Dragonâ€™s Den-style events in the Bright IDEAS Award programme. There is no evaluation of the programme but it claims to have funded highly diverse set of applicants and potentially transformative research.</p>
<p>It has also been used by the Hounslow and Richmond Community Healthcare NHS Trust to ensure that some of the most innovative practices are captured and supported. Two pitching panels were carried out with positive effects in terms of mentoring, fostering collaborative work and innovation in the trust. In another case at the National Cancer Research Institute, a Dragonâ€™s Den event was used to facilitate patientsâ€™ involvement in epidemiological research. This resulted in positive feedback from participants in terms of their interest in continuing to engage with the research.</p>
<p>Authors emphasise the role of independent facilitators to run the process. In other words, there needs to be sufficient briefing and oversight of the â€˜dragonsâ€™. More generally, there is a perceived difficulty in that these events will only suit specific types of individuals (good presentation skills, able to access the events, native speakers) and disadvantage others. This is therefore unlikely to be a widely suitable intervention.</p>
<h4>References</h4>
<p><a href="https://www.researchgate.net/publication/279730227_Dragons'_Den_promoting_healthcare_research_and_innovation">Dragonsâ€™ Den: promoting healthcare research and innovation</a>. Mazhindu D and Gregory S.</p>
<p><a href="https://doi.org/10.1136/bmjopen-2019-036311">Fleshing out the data: when epidemiological researchers engage with patients and carers. Learning lessons from a patient involvement activity</a>. Morris M, Alencar Y, Rachet B, Stephens R and Coleman MP.</p>
<h4>Interviewees and survey responses</h4>
<p>No survey responses</p>
<p>One interview</p>
<h3>External review only (no panel)</h3>
<p>Proposals are only assessed by external reviewers and review scores are simply combined to give the final score.</p>
<h4>Main intended aims</h4>
<p>The main aims are to:</p>
<ul>
<li>reduce risk-averseness of panels</li>
<li>reduce burden and costs</li>
<li>better match applications to expertise</li>
</ul>
<h4>Main hazards</h4>
<p>Reduced layers of risk control, potential lack of transparency</p>
<h4>Evidence strength</h4>
<p>Two star</p>
<h4>Findings</h4>
<p>This approach is intended to reduce risk-averseness in panel discussions and also to reduce burden (in this case for panellists rather than reviewers in general). Further, it gives more flexibility in matching reviewers with applications as the choice is not limited to a relatively small number of panellists. The aim being better matching between reviewersâ€™ expertise and applications. This intervention may also potentially cut costs of in-person panels. We find examples of its use at Australiaâ€™s NHMRC, Switzerlandâ€™s SNSF and at NERC in the UK.</p>
<p>For the NERC example we find no evaluation evidence, which is why this example is not discussed further. We do note that while there is no panel, reviews are moderated by an external moderator who is an expert in the field and who makes a funding recommendation to NERC.</p>
<p>For SNSFâ€™s Sinergia, the evaluation found that original and unconventional research was given better chances by including originality and unconventionality as key review criteria and funding proposals based on aggregated reviewer grades (rather than panel discussions). Omitting panel meetings was also a way of reducing review costs for small grants.</p>
<p>NHMRCâ€™s data (based on reviewersâ€™ declared suitability before peer review) and responses to NHMRCâ€™s panel member survey suggested better matching of reviewers to applications in 2020 than in 2019.</p>
<p>For the NHMRC case, there was a perceived lack of transparency in the initial round (2020), however, this was mitigated by the addition of reviewer comments in 2021, when previously only scores had been released. This intervention appears also to be largely limited to use for small grants. For larger ones, there is a perceived danger due to fewer â€˜layersâ€™ of risk control.</p>
<h4>References</h4>
<p><a href="https://www.nhmrc.gov.au/about-us/news-centre/peer-review-ideas-grants-2021">Peer review for Ideas Grants in 2021</a>. Kelso A.</p>
<h4>Interviewees and survey responses</h4>
<p>No survey responses</p>
<p>One interview</p>
<h3>Group review</h3>
<p>The same reviewer comments on multiple proposals.</p>
<h4>Main intended aims</h4>
<p>The main aims are to:</p>
<ul>
<li>facilitate consensus building</li>
<li>increase diversity of reviews</li>
</ul>
<h4>Main hazards</h4>
<p>The main hazard is group bias.</p>
<h4>Evidence strength</h4>
<p>One star</p>
<h4>Findings</h4>
<p>This intervention aims to facilitate consensus and deliver more comprehensive reviews particularly when reviewing manuscripts for academic journals. We find very limited evidence on this intervention.</p>
<p>The Association of American Medical Colleges experimented with this intervention and found that more thorough feedback was provided to researchers. Reviewers changed their initial individual assessments throughout the group review process and reduced time was required to evaluate the papers compared to what reviewers would spend individually.</p>
<p>The sources we find note a risk of group bias and that shared views may consolidate over time.</p>
<h4>References</h4>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/27680319/">Expanding group peer review: a proposal for medical education scholarship</a>. Dumenco L, Engle D, Goodell K, Nagler A, Ovitsh R and Whicker S.</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/31135399/">Communities of practice in peer review: outlining a group review process</a>. Nagler A, Ovitsh R, Dumenco L, Whicker S, Engle D and Goodell K.</p>
<h4>Interviewees and survey responses</h4>
<p>No survey responses and interviews</p>
<h3>Changing the number of reviewers</h3>
<p>Two to three external reviews of applications is typical for responsive-mode grant funding, but this number may be lowered to one or significantly increased.</p>
<h4>Main intended aims</h4>
<p>The main aims are to:</p>
<ul>
<li>increase numbers, to improve robustness or reliability</li>
<li>decrease numbers, to save time, burden or cost</li>
</ul>
<h4>Main hazards</h4>
<p>The main hazards are:</p>
<ul>
<li>increasing numbers:
<ul>
<li>a single bad review can sink an application</li>
<li>labour intensive</li>
</ul>
</li>
<li>decrease numbers:
<ul>
<li>reduced robustness</li>
<li>potential for greater bias</li>
</ul>
</li>
</ul>
<h4>Evidence strength</h4>
<p>Three star</p>
<h4>Findings</h4>
<p>Increasing the number of reviewers is done to improve quality and reliability and mitigate against random variations in individual reviews and to improve the ability to address additional assessment criteria. On the other hand, reducing the number of reviewers can be done with the aim to reduce cost and burden of reviews.</p>
<p>There is a broad consensus that reliability of decisions increases with the number of reviewers. This has been demonstrated in quantitative studies and confirmed by funder experience. Several studies have found that five reviewers is an optimal upper limit for robustness, but this is based on data from specific types of programmes. For very small grants, a single reviewer is sometimes used (for example, at the German Research Foundation).</p>
<p>In short, setting the number of reviewers balances two objectives:</p>
<ul>
<li>adding more reviewers to optimise reliability</li>
<li>reducing the number of reviewers to improve resource efficiency</li>
</ul>
<p>The optimal number will inevitably depend on situation-specific trade-offs between cost and benefit of adding more reviewers and the tolerance for mistakes in specific situations.</p>
<p>There is some disagreement about the appropriateness of using a single reviewer. This is sometimes done for very small grants, but some argue that the minimum should be two reviewers.</p>
<p>Further, inter-rater-reliability (IRR) is the subject of a large volume of technical literature across this and related topics, and beyond the scope of this discussion.</p>
<h4>References</h4>
<p><a href="https://rori.figshare.com/articles/report/The_experimental_research_funder_s_handbook_final_version_/19459328">The experimental research funderâ€™s handbook</a>. Bendiscioli S, Firpo T, Bravo-biosca A, Czibor E, Garfinkel M, Stafford T and Wilsdon J.</p>
<p><a href="https://link.springer.com/chapter/10.1007/978-3-030-75263-7_13">The decision-making constraints and processes of grant peer review, and their effects on the review outcome</a>. Langfeldt L.</p>
<p><a href="https://www.nhmrc.gov.au/sites/default/files/documents/peer-review-final-consultation.pdf">Consultation on the development of peer review for NHMRCâ€™s new grant program</a>. Nous Group.</p>
<h4>Interviewees and survey responses</h4>
<p>No survey responses</p>
<p>One interview</p>
<h3>Interviews</h3>
<p>Lead applicant (or several application team members) may do a presentation (optional) and are then asked questions on their application by panel members, reviewers or funder representatives.</p>
<h4>Main intended aims</h4>
<p>The main aim are to:</p>
<ul>
<li>improve quality of reviews and increase scrutiny</li>
<li>give an opportunity to respond to criticism</li>
</ul>
<h4>Main hazards</h4>
<p>The main hazards are that:</p>
<ul>
<li>that it is resource intensive</li>
<li>bias, disadvantage or both for certain groups</li>
</ul>
<h4>Evidence strength</h4>
<p>Two star</p>
<h4>Findings</h4>
<p>Interviews serve different purposes depending on the scheme. They can serve to demonstrate the applicantâ€™s presentation skills (which may be especially relevant to commercialisation projects), improve engagement with panellists (assuming panellists are the interviewers), allow applicants to respond to comments and defend their proposal, or improve the overall quality of reviews as the interview will provide reviewers with additional context.</p>
<p>When used, interviews often occur at the end of the process: due to their resource-intensive nature, efficiencies can be gained by having interviews as the final stage of a multi-stage assessment process (by which point most applicants will have already been rejected, meaning there are fewer interviews to do). In addition to standard interviews, they can also take the form of a scientific symposium or workshop. The practice is often used for early career fellowships (including strongly person-centred awards) and schemes aiming to fund particularly transformative research.</p>
<p>Funders have found interviews to be a helpful way of assessing proposals or candidates against specific objectives, whereas others use it more widely to improve the quality of the review. It can be difficult to evidence the exact effect of using interviews but one study found that that the interview stage had a significant impact on the final grant selection.</p>
<p>Interviews are typically used in addition to other types of assessment.</p>
<p>They are particularly resource intensive, requiring time and space set aside for each individual applicant. For this reason, Wellcome has for instance decreased its use of interviews in recent years. Assessment through interviews can also be biased against certain personality types (for example, introverted, nervous, non-native speakers). In-person interviews may also pose difficulties for applicants with caring responsibilities or disabilities. However, we note on a final point that there is limited research on the effectiveness of interviews in terms of achieving certain types of funding outcomes, despite their relatively frequent use.</p>
<h4>References</h4>
<p><a href="https://research.vu.nl/en/publications/academic-talent-selection-in-grant-review-panels">Academic talent selection in grant review panels</a>. van Arensbergen P, van der Weijden I and van der Besselaar P.</p>
<p><a href="https://www.ida.org/~/media/Corporate/Files/Publications/STPIPubs/ida-p-4899.ashx">An outcome evaluation of the National Institutes of Health (NIH) Directorâ€™s pioneer award (NDPA) program</a>. Lal B, Wilson A, Jonas S, Lee E, Richards A and PeÃ±a V.</p>
<p><a href="https://www.etla.fi/en/publications/evaluation-practices-in-the-selection-of-ground-breaking-research-proposals/">Evaluation practices in the selection of ground-breaking research proposals</a>. Luukkonen T, Stampfer M and Strassnig M.</p>
<h3>Interviewees and survey responses</h3>
<p>No survey responses</p>
<p>Three interviews</p>
<h3>Moderation of reviews</h3>
<p>Reviews are processed internally by funding organisation staff and are only passed to the external panel if they are of sufficient quality.</p>
<h4>Main intended aims</h4>
<p>The main aim is to ensure consistency or quality of reviews.</p>
<h4>Main hazards</h4>
<p>The main hazards are that:</p>
<ul>
<li>it can be time consuming for administrators</li>
<li>administrators may not have sufficient thematic expertise</li>
</ul>
<h4>Evidence strength</h4>
<p>One star</p>
<h4>Findings</h4>
<p>Moderation of reviews is intended to ensure quality of the reviews received in order not to waste time or have an inconsistent evidence base at later stages of the evaluation process. This particularly applies during panel reviews and for feedback from assessor or reviewers. Moderation might only involve a basic â€˜usability checkâ€™ (ensuring that reviews are not just one line of text or similar) or more involved engagement to check if the reviews meet a broader set of criteria.</p>
<p>All UKRI councils use some degree of review moderation. For example, Innovate UK introduced a moderation phase to review outlier scores from assessors to ensure consistency, since they were receiving complaints from applicants about conflicting feedback from assessors.</p>
<p>Our research received some anecdotal comments noting on one hand that moderation of reviews does bring benefits in terms of consistent review quality, but that it places a burden on administratorsâ€™ time. Additionally, administrators may not always have all the necessary thematic expertise if moderation extends to thematic aspects.</p>
<p>Beyond such anecdotal points, our research found no further evidence on the efficacy or hazards of this intervention. Literature appears to be insufficient and does not distinguish from moderation panel intervention.</p>
<h4>References</h4>
<p><a href="https://doi.org/10.2777/16211">Study on the proposal evaluation system for the EU R&amp;I framework programme</a>. Rodriguez-Rincon D, Feijao C, Stevenson C, Evans H, Sinclair A, Thomson S and Guthrie S.</p>
<p><a href="https://doi.org/10.3390/su13052842">Ensuring sustainable evaluation: how to improve quality of evaluating grant proposals?</a> Wieczorkowska G and Kowalczyk K.</p>
<h4>Interviewees and survey responses</h4>
<p>No survey responses or interviews.</p>
<h3>Moderation panel</h3>
<p>Assessment panels use external reviews alongside their own expertise to assess the proposal. Moderation panels do not use their own expertise but can only use the reviews to inform their scores.</p>
<h4>Main intended aims</h4>
<p>The main aims are to ensure consistency, increase expertise and robustness of reviews.</p>
<h4>Main hazards</h4>
<p>Not known</p>
<h4>Evidence strength</h4>
<p>One star</p>
<h4>Findings</h4>
<p>Assessment panels where members can bring in their own expertise are the baseline approach funders use. Our research found no evidence of the effectiveness of using moderation panels. UKRI uses moderation panels in some programmes where assessment panels cannot cover the breadth of expertise required to assess applications from diverse disciplines. However, the effectiveness of the moderation panels is not systematically studied, therefore, evidence strength for this intervention is weak.</p>
<p>Compared to moderation panels, assessment panel members can bring in their own expertise and this approach is mostly part of the baseline process and therefore not considered as an intervention in this study.</p>
<h4>References</h4>
<p>None</p>
<h4>Interviewees and survey responses</h4>
<p>No survey responses or interviews</p>
<h3>Panel only (no postal or external review)</h3>
<p>Proposals are only assessed by a panel of experts.</p>
<h4>Main intended aims</h4>
<p>The main aims are to:</p>
<ul>
<li>increase speed of decisions, efficiency, ensure consistency of reviews</li>
<li>include strategic perspectives in reviewing</li>
</ul>
<h4>Main hazards</h4>
<p>The main hazards are:</p>
<ul>
<li>the difficulty to cover the required expertise in a panel</li>
<li>that it may still need additional reviews</li>
<li>potential bias</li>
</ul>
<h4>Evidence strength</h4>
<p>Three star</p>
<h4>Findings</h4>
<p>This intervention is similar to the â€˜group reviewâ€™ intervention, though it involves reviewers actually meeting as a group (review panel), which the â€˜group reviewâ€™ intervention does not. It is used for a variety of reasons:</p>
<ul>
<li>to speed up funding decisions</li>
<li>to reduce written feedback (and its associated costs and burden)</li>
<li>to improve quality and consistency of feedback to applicants</li>
<li>to assess riskier research proposals and where strategic considerations play a central role in the judgement process (for example, ensuring EDI is properly assessed)</li>
</ul>
<p>AHRC adopted panel-only assessment for the Equality, Diversity and Inclusion Engagement Fellowship (EDIEF) pilot programme, forming a bespoke panel that embedded EDI in the evaluation process and sped up funding decision making.</p>
<p>The Royal Society has also used it with positive results, funding more high-risk high-reward research proposals, and an increase in the number of individuals willing to participate as panellists. The Royal Society has also found that rigour has remained high, which is also reflected in our survey responses.</p>
<p>Cancer Research UK has implemented panel-only assessment, resulting in a significant reduction of written peer review requests. It highlighted the benefits of having in-person discussions as a more valuable way of evaluating research applications.</p>
<p>Panel-only review was also a technique used by a range of funders in their R&amp;I funding responses to COVID-19, as a mechanism for ensuring that awards were made quickly and could thus respond to the societal emergency at hand. Several examples are detailed in the process review of UKRIâ€™s response to COVID-19 (which contains a review of six international comparators), though long-term evaluations of effectiveness are not yet available.</p>
<p>It is a challenge to represent enough expertise on a panel to cover the potentially broad thematic, subject range or both of a large number of incoming applications. There is therefore typically a need to have large panels and funders may still have to rely on external reviewers when applications fall outside the panel expertise, or in the absence of agreement.</p>
<p>Configuration of panels may be difficult as panellists may need to be recruited from distant subject domains, potentially creating some administrative burden in panel set-up.</p>
<p>There is broad agreement on the effectiveness of this intervention (reducing burden and speeding up decision making) but controversy around its effects regarding bias. Some evidence showed panels purposefully used to embed and ensure EDI throughout the process, while in other programmes it was found that it failed to sufficiently factor this in. Cross-disciplinary panel composition may also result in â€˜communication problemsâ€™.</p>
<p>We note that this is the most frequently discussed intervention in our UKRI staff survey.</p>
<h4>References</h4>
<p><a href="https://openaccess.city.ac.uk/id/eprint/30872/">Similar-to-me effects in the grant application process: Applicants, panelists, and the likelihood of obtaining funds</a>. Banal-EstaÃ±ol A, Liu Q, Macho-Stadler I and PÃ©rez-Castrillo D.</p>
<p><a href="https://oro.open.ac.uk/87420/">Equality, Diversity and Inclusion Engagement Fellowship Pilot AHRC Funding Scheme Report</a>. Blackburn M, Coutinho K and Suviste H.</p>
<p><a href="https://doi.org/10.1016/j.respol.2021.104467">Designing grant-review panels for better funding decisions: lessons from an empirically calibrated simulation model</a>. Feliciani T, Morreau M, Luo J, Lucas P and Shankar K.</p>
<p><a href="/publications/process-review-of-ukris-research-and-innovation-response-to-covid-19/">Process review of UKRIâ€™s research and innovation response to COVID-19</a>. Kolarz P, Arnold E, Bryan B, Dâ€™hont J, Horvath A, Simmonds P, Varnai P and Vingre A.</p>
<p><a href="https://academic.oup.com/spp/article/45/5/673/4819248">Exploring the degree of delegated authority for the peer review of societal impact</a>. Samuel GN and Derrick G.</p>
<h4>Interviewees and survey responses</h4>
<p>Six survey responses</p>
<p>Two interviews</p>
<h3>Peer allocation</h3>
<p>The applicants are also the assessors and review the proposals they are competing against to decide who gets funding.</p>
<h4>Main intended aims</h4>
<p>The main aims are to:</p>
<ul>
<li>lesson administrative burden</li>
<li>reduce pressure to identify reviewers</li>
</ul>
<h4>Main hazards</h4>
<p>The main hazards are that:</p>
<ul>
<li>it is possibly open to abuse or gaming</li>
<li>it adds to applicant burden</li>
</ul>
<h4>Evidence strength</h4>
<p>Three star</p>
<h4>Findings</h4>
<p>This intervention evens out the number of applicants to reviewers and is intended to lessen the administrative burden on reviewers and shorten the overall time taken to recruit reviewers.</p>
<p>There are a small number of known instances where the intervention is in use, but the results are cautiously positive across the board. In one scheme, seven rounds of review were organised within a year, with a total of 614 reviews carried out by 201 reviewers (some being applicants and some not). When compared, the two groups of scorings correlated. Where successfully in use, it relieves the pressure to identify expert reviewers. It appears to be a successful way to expedite the review process without impacting the integrity of the selection.</p>
<p>The NSF ran an experiment on peer allocation in 2013. As a condition of application, applicants had to commit to assessing seven other proposals submitted to the scheme and then rank the proposals from best to worst. The NSF also employed a mechanism to dissuade reviewers from downgrading a competitorâ€™s proposal in order to boost their own. Reviewers earned bonus points on their own applications if their assessments of other proposals closely matched what their colleagues thought. An article in Science reports that the system saved time and money, but that the need for â€˜group consensusâ€™ may disadvantage novel, unconventional ideas.</p>
<p>Peer allocation may risk being abused if:</p>
<ul>
<li>the consistency of scoring with non-applicant reviewers is not monitored</li>
<li>the approach is mainstreamed</li>
</ul>
<p>It is possible that this is mainly viable in smaller, perhaps early-career settings. Moreover, peer allocation has the reverse effect on the administrative burden on applicants, particularly if additional training is required.</p>
<p>As a side note, the ESRC Transformative Research scheme had an element of this but in the context of a dragonsâ€™ den-style event rather than application review proper (termed â€˜pitch-to-peersâ€™). The evaluation found that, contrary to simple self-interest arguments, reviewers were generally supportive of their fellow applicants, resulting in collegial discussions.</p>
<h4>References</h4>
<p><a href="https://doi.org/10.12688/f1000research.125886.1">Community review: a robust and scalable selection system for resource allocation within open science and innovation communities</a>. Graham C L B, Landrain T E, Vjestica A, Masselot C, Lawton E, Blondel L, Haenal L, Greshake Tzovaras B and Santolini M.</p>
<p><a href="https://academyhealth.org/publications/2019-11/innovating-research-funding-process-peer-review-alternatives-and-adaptations">Innovating in the research funding process: peer review alternatives and adaptations</a>. Guthrie S.</p>
<p><a href="https://www.technopolis-group.com/report/evaluation-of-the-esrc-transformative-research-scheme/">Evaluation of the ESRC Transformative Research Scheme</a>. Kolarz P, Arnold E, Farla K, Gardham S, Nielsen K, Rosemberg C and Wain M.</p>
<p><a href="https://www.science.org/doi/full/10.1126/science.345.6194.248">A radical change in peer review: a pilot project to ease pressure on NSFâ€™s vaunted peer-review system required grant applicants to review seven competing proposals</a>. Mervis J.</p>
<p><a href="https://cca-reports.ca/reports/international-practices-for-funding-natural-science-and-engineering-research/">Powering discovery: the expert panel on international practices for funding natural sciences and engineering research</a>. The Council of Canadian Academies.</p>
<p><a href="https://doi.org/10.1186/s41073-022-00120-2">What works for peer review and decision-making in research funding: a realist synthesis</a>. Recio-Saucedo A, Crane K, Meadmore K, Fackrell K, Church H, Fraser S and Blatch-Jones A.</p>
<h4>Interviewees and survey responses</h4>
<p>No survey responses or interviews</p>
<h3>Programme managerâ€™s discretion</h3>
<p>Applications go directly to the programme or scheme manager, who can recommend funding or even decide to fund unilaterally. Usually involves complete bypass of peer and panel review.</p>
<h4>Main intended aims</h4>
<p>The main aims are to:</p>
<ul>
<li>shorten time-to-grant</li>
<li>reduce overall burden</li>
<li>respond to emergencies</li>
<li>fund high-risk high-reward projects likely to fail in peer review</li>
</ul>
<h4>Main hazards</h4>
<p>The main hazards are that:</p>
<ul>
<li>there is evidence that it may be underused as programme managers themselves can be risk averse</li>
<li>it lacks transparency, potentially a â€˜winnersâ€™ gameâ€™</li>
</ul>
<h4>Evidence strength</h4>
<p>Three star</p>
<h4>Findings</h4>
<p>This approach is used to support exploratory or high-risk or high-reward projects that might not be selected through potentially more conservative peer review.</p>
<p>This approach has also been used to respond quickly to address urgent issues or grasp immediate opportunities for innovative developments. For example, several funders have on occasion partly or fully bypassed peer review, these include:</p>
<ul>
<li>NSF</li>
<li>NWO</li>
<li>NRC</li>
<li>French National Research Agency</li>
</ul>
<p>Several of them relied on programme managers in parts of their COVID-19 response funding and found that this accelerated the funding decisions at a time when research projects had to start as soon as possible.</p>
<p>The approach can also be applied by leaving the final decision to funding staff (including, programme managers) after an initial shortlisting or sifting through a more traditional external review process. Furthermore, even when programme managers are tasked with assessing the applications, there is still usually an option to recruit external expertise if necessary.</p>
<p>This approach has been found to be successful in supporting exploratory research that often led to follow-on funding and significant results further down the line. The approach also encourages dialogue between applicants and staff at the funding organisation.</p>
<p>This approach is particularly common in the US and is associated with the â€˜Defense Advanced Research Projects Agency (DARPA)â€™ approach, considered highly successful, and attracts a lot of attention from businesses. NSF used the approach in the Small Grants for Exploratory Research programme introduced in 1990. Now it is applied in the successor programme, the RAPID instrument, which is used to fund research in response to emergencies.</p>
<p>In one case, actual use of discretionary allocation was found to be much lower than the allowed limit (up to 5% of grant budget).</p>
<p>In opposition to widespread use of this mechanism, it is argued that the selection process lacks transparency, effectively basing decisions on one personâ€™s opinion. It has also been argued that the successful application of the â€˜DARPAâ€™ model is a â€˜winners gameâ€™ potentially benefitting the most well-established and well-connected researchers.</p>
<h4>References</h4>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/32675837/">Administrative discretion in scientific funding: evidence from a prestigious postdoctoral training program</a>. Ginther DK and Heggeness ML.</p>
<p><a href="https://www.rand.org/pubs/research_reports/RR139.html">Alternatives to peer review in research project funding</a>. Guthrie S, Guerin B, Wu H, Ismail S and Wooding S.</p>
<p><a href="https://www.researchgate.net/publication/357910858_Process_review_of_UKRI's_research_and_innovation_response_to_COVID-19_Final_report_Process_review_of_UKRI's_research_and_innovation_response_to_COVID-19_Final_report">Process review of UKRIâ€™s research and innovation response to COVID-19</a>. Kolarz P, Arnold E, Bryan B, Dâ€™hont J, Horvath A, Simmonds P, Varnai P, Vingre A.</p>
<p><a href="https://doi.org/10.1093/reseval/rvt006">Evaluating transformative research programmes: A case study of the NSF Small Grants for Exploratory Research programme</a>. Wagner CS and Alexander J.</p>
<h4>Interviewees and survey responses</h4>
<p>No survey responses</p>
<p>Two interviews</p>
<h3>Standing panels versus portfolio panels</h3>
<p>Standing panels are the same year on year (with some replacement due to retirement from the panel). Portfolio panels are assembled based on the proposals received and therefore will be comprised differently in each round of funding.</p>
<h4>Main intended aims</h4>
<p>Standing panels ensure consistency, and may be the site of long-term learning and interdisciplinary conversation</p>
<h4>Main hazards</h4>
<p>Standing panels may potentially lead to institutionalised bias</p>
<h4>Evidence strength</h4>
<p>Three star</p>
<h4>Findings</h4>
<p>Broadly speaking, standing panels ensure greater consistency over time and creation of certain â€˜culturesâ€™ and understandings of specific scheme aims. At the same time portfolio (or â€˜ad-hocâ€™) panels can be assembled to better reflect the thematic and disciplinary spread of a specific pool of applications.</p>
<p>The literature highlights that standing panels ensure consistent evaluation. There appears also to be a link with more consistent and comprehensive feedback on applications (particularly important for resubmitted proposals). It also creates opportunities for interdisciplinary conversations between panellists, reviewers and applicants, including over time as a standing panel â€˜maturesâ€™.</p>
<p>In some cases, standing panels present an opportunity to develop capacity of inquiry of reviewers or staff and for professional development of applicants. They also reduce recruitment burden on programme officers as members of standing panels are normally appointed for several-year periods. For example, the review of the National Institutes of Health National Institute on Disability and Rehabilitation Research funding processes concluded that programme staff managing programmes with standing panels face less burden in peer recruitment.</p>
<p>While various forms of training (for example, EDI training) have a longer â€˜effectâ€™ on standing panels, there may in the absence of such training also be more institutionalised bias and narrow perspectives. This therefore needs to be considered when configuring them to offset these potential drawbacks.</p>
<p>The main advantage of the portfolio panels is a fresh view and better ability of peers to assess the specifics of the funding programme concerned, as the peers are selected specifically for the funding opportunity or programme. However, we find no empirical evidence assessing the functioning of portfolio panels and, in the literature, the associated benefits are reported as assumptions about how the portfolio panels would work.</p>
<p>It is worth noting that hybrid-versions are possible, and practised to some degree by many funders. For example, the Human Frontier Science Program (HFSP) uses standing panels where each panellist has a finite tenure. Once a panellistâ€™s tenure expires, secretariat staff may consider any changes over time to the portfolio of applications (evolving themes and new emerging methods or interdisciplinary perspectives) when identifying new panellists.</p>
<h4>References</h4>
<p><a href="https://doi.org/10.1016/j.cell.2008.09.051">Enhancing NIH grant peer review: a broader perspective</a>. Bonetta L.</p>
<p><a href="https://iaes.cgiar.org/spia">Standing Panel on Impact Assessment (SPIA)</a>. CGIAR IAES.</p>
<p><a href="https://www.biorxiv.org/content/10.1101/479816v2">Participation and motivations of grant peer reviewers: a comprehensive survey of the biomedical research community</a>. Gallo SA, Thompson LA, Schmaling KB and Glisson SR.</p>
<p><a href="https://ies.ed.gov/director/sro/pdf/IESGuideforPeerReviewersFY2019.pdf">IES guide for grant peer review panel members: information, tips and instructions for members of IES scientific grant peer review panels (PDF, 780KB)</a>. Institute for Education Sciences.</p>
<p><a href="https://www.technopolis-group.com/report/organisational-and-process-review-of-the-human-frontier-science-program/">Organisational and process review of the Human Frontier Science Program.</a> Kolarz P.</p>
<p><a href="/publications/process-review-of-ukris-research-and-innovation-response-to-covid-19/">Process review of UKRIâ€™s research and innovation response to COVID-19</a>. Kolarz P.</p>
<p><a href="https://nij.ojp.gov/funding/becoming-peer-reviewer-nij">Becoming a peer reviewer for NIJ (2023)</a>. National Institute of Justice.</p>
<p><a href="https://nij.ojp.gov/topics/articles/improving-nijs-peer-review-process-scientific-review-panel-pilot-project">Improving NIJâ€™s peer review process: the scientific review panel pilot project</a>. Newton P and Feucht T.</p>
<p><a href="https://public.csr.nih.gov/AboutCSR/Evaluations">CSR data and evaluations</a>. National Institutes of Health.</p>
<p><a href="https://www.researchgate.net/publication/318779712_Review_of_disability_and_rehabilitation_research_NIDRR_grantmaking_processes_and_products">Review of disability and rehabilitation research: NIDRR grantmaking processes and products</a>. Rivard J, Oâ€™Connell M and Wegman D.</p>
<p><a href="/about-us/esrc/grant-assessment-panels/">Responsive mode grant assessment process</a>. UKRI</p>
<p><a href="https://education.ufl.edu/educational-research/5499">An overview: IES procedures for peer review of grant applications</a>. University of Florida College of Education.</p>
<p><a href="https://deepblue.lib.umich.edu/handle/2027.42/168211?show=full">Managing internal nomination and peer review processes to reduce bias</a>. Wigginton N, Johnston J and Chavous T.</p>
<h4>Interviewees and survey responses</h4>
<p>One survey response</p>
<h3>Use of international assessors</h3>
<p>Having quotas for assessors based in countries other than the funderâ€™s â€˜homeâ€™ country. May extend to mandating all-international panels, reviewers or both.</p>
<h4>Main intended aims</h4>
<p>The main aims are to:</p>
<ul>
<li>avoid conflicts of interest, ensure required expertise and fill gaps</li>
<li>bring in specific country expertise</li>
</ul>
<h4>Main hazards</h4>
<p>The main hazard is that it may require more guidance or training for panellists.</p>
<h4>Evidence strength</h4>
<p>Two star</p>
<h4>Findings</h4>
<p>International assessors (reviewers or panellists) are used to ensure required expertise (in-country knowledge, international development knowledge) to fill competence gaps in the funder country. Particularly in smaller countries, there may be minimum quotas for international reviewers, or even mandates to use only international reviewers to avoid conflicts of interest among reviewers. For example, the Austrian Science Fund FWF uses only international reviewers for this reason.</p>
<p>UKRI, Wellcome, the Royal Society and CRUK are among many funders who have used international reviewers extensively. They found it to be effective in diversifying and expanding the pool of reviewers and ensuring review quality, particularly from developing countries.</p>
<p>Funders have also used international assessors to fill gaps and in cases of knowledge or context-specific needs. Several funders are also keen to use this intervention more often because of its effectiveness and benefits. However, some also expressed concerns regarding country differences in the assessment process that may require extra guidance for some panellists. Disparities across different countriesâ€™ typical assessment processes may require additional training or guidance for international reviewers.</p>
<p>While the likelihood for conflicts of interest among national reviewers is far more significant in small countries, this issue does also apply to larger countries to some extent. Some consultees for our study also expressed significant support for international reviewers to mitigate for the conflict of interest in areas where there are small numbers of potential reviewers in the UK.</p>
<h4>References</h4>
<p><a href="https://doi.org/10.1503/cmaj.170901">Assessment of potential bias in research grant peer review in Canada</a>. Tamblyn R, Girard N, Qian CJ and Hanley J.</p>
<h4>Interviewees and survey responses</h4>
<p>Three survey responses</p>
<p>Four interviews</p>
<h3>Use of metrics</h3>
<p>Use of metrics and bibliometrics as part of the evidence base to inform decision making.</p>
<h4>Main intended aims</h4>
<p>The main aims are to:</p>
<ul>
<li>provide additional information about applicants</li>
<li>increase robustness of review</li>
</ul>
<h4>Main hazards</h4>
<p>The use of metrics is highly controversial and the main hazards are that they are:</p>
<ul>
<li>a poor measure of excellence</li>
<li>open to bias and abuse, may contravene the <a href="https://sfdora.org/read/">San Francisco Declaration on Research Assessment (DORA)</a></li>
</ul>
<h4>Evidence strength</h4>
<p>Three star</p>
<h4>Findings</h4>
<p>Metrics can be used to support the assessment of funding applications, providing additional information about the applicantsâ€™ track record. If used, it is typically early in the assessment process. The most commonly used metrics are reportedly field-normalised citation measures and proportion of publications among the most cited in the field. Some UKRI schemes have also used grant income or Research Excellence Framework (REF) outcome metrics in the past, prior to UKRI becoming signatory to the DORA. While the use of metrics overall is rare, when it does appear it tends to be in programmes funding research in bio-medical fields.</p>
<p>Recent survey evidence shows that bibliometric indicators are viewed as important by some reviewers, particularly in the early stages of the review to assess the candidate, and less important at the panel stage.</p>
<p>The use of metrics is controversial, and many limitations have been identified. First, various objections hold that metrics are a poor way of assessing research excellence and potential. Second, their use may lead to biases (for example, around gender, career stage or research field) and that bibliometric indicators are often used unethically. It cannot be ruled out either that the focus on track record (as demonstrated by bibliometric analysis) can contribute to a vicious circle where those with a shorter track will be rendered with fewer research activities overall, while funding concentrates on established individuals. Survey evidence suggests that reviewers who themselves have good personal bibliometric impact scores are more likely to regard metrics as important.</p>
<p>In short, evidence suggests that some reviewers find bibliometric indicators useful as supporting information, but there are widespread concerns about their use in the research communities.</p>
<p>We note that despite the apparently widespread use and despite general controversy, none of our survey respondents and interviewees commented on this intervention.</p>
<h4>References:</h4>
<p><a href="https://rori.figshare.com/articles/report/Harnessing_the_Metric_Tide/21701624">Harnessing the Metric Tide: indicators, infrastructures and priorities for UK responsible research assessment</a>. Curry S, Gadd E and Wilsdon J.</p>
<p><a href="https://doi.org/10.1007/s11192-017-2417-8">How do NIHR peer review panels use bibliometric information to support their decisions?</a> Gunashekar S, Wooding S and Guthrie S.</p>
<p><a href="https://doi.org/10.1093/reseval/rvaa032">The role of metrics in peer assessments</a>. Langfeldt L, Reymert I and Aksnes DW.</p>
<p><a href="https://doi.org/10.3152/147154306781779037">Segmenting academics: resource targeting of research grants</a>. Viner N, Green R and Powel P.</p>
<p><a href="https://www.embo.org/documents/science_policy/peer_review_report.pdf">Dealing with the limits of peer review with innovative approaches to allocating research funding (PDF, 314KB)</a>. Bendiscioli S and Garfinkel M.</p>
<p><a href="https://doi.org/10.1007/s10734-020-00626-y">The leaky pipeline in research grant peer review and funding decision: challenges and future directions.</a> Sato S, Gygax P, Randall J and Schmid Mast M.</p>
<h4>Interviewees and survey responses</h4>
<p>No survey responses and interviews.</p>
<h3>Use of non-academic assessors (including industry, policy and practice, patients, etc.)</h3>
<p>Having quotas for non-academic assessors. May extend to all-user panels, reviewers or both. May take the shape of consultation rather than directly making formal funding recommendations.</p>
<h4>Main intended aims</h4>
<p>The main aim is to increase societal relevance and impact.</p>
<h4>Main hazards</h4>
<p>The main hazard is that it may dilute notions of basic research, and its not recommended for such contexts.</p>
<h4>Evidence strength</h4>
<p>Four star</p>
<h4>Findings</h4>
<p>The inclusion of non-academics is closely related to the increasing priority given to societal use and impact of research. Depending on the context, including non-academic reviewers may aim to:</p>
<ul>
<li>represent stakeholder concerns (for example, patients)</li>
<li>improve the assessment of relevance and potential impact (for example, using industry reviewers)</li>
<li>improve the assessment of potential interest among users, as well as feasibility of real-world applications (for example, using technicians to support the assessment of applications for research infrastructure)</li>
</ul>
<p>Our consultation reveals that most health research funders (for example Wellcome, NIH, NIHR, UKRI, MRC) involve patient representatives in at least some of their funding. Funders observe that this helps panel members assess whether the applications consider patient needs. The Science and Technology Facilities Council (STFC) sometimes involves technical professionals and project management experts in the assessment process of applications for new major projects and project technology development funding. STFC finds that this adds valuable information to assess the feasibility of proposed operational costs and other technical details. Relatedly, the involvement of non-academic assessors is seen as a way to overcome a perceived bias against applied research in traditional peer review.</p>
<p>Non-academic users are now widely used in programmes where societal or economic impact are important objectives and recommended in grey literature texts. Practically, this intervention can be implemented in a staggered review process, for example with a traditional academic peer review followed by a more diverse panel with a greater focus on relevance and impact.</p>
<p>Funders report that this helps improve panel discussions, understanding of the context of use (for example, industry), and the quality of the assessment. For example, EPSRC and Norwayâ€™s RCN use industry reviewers in programmes that support collaborative research and aim to deliver academic outcomes and also benefit industry partners. Using industry reviewers helps assess applications that cover industry motivation and potential commercial outcomes of the proposed projects.</p>
<p>Feedback from applicants shows that they feel better understood when industry reviewers are involved. Although it is hard to attribute programme success to this process element, impact and process evaluations show that the programmes have succeeded in selecting the right applications that align with programme objectives.</p>
<p>Despite the overall positive verdict, non-academic considerations are not appropriate in all contexts, for example, in the context of pure basic research funding schemes.</p>
<p>Our research also highlights a common view that there is a risk of bias in the selection of industry representatives from large enterprises in specialised roles, rather than from small and medium-sized enterprises. As such, pools of non-academic assessors may not be representative of the wider business population (this may not necessarily be a problem depending on scheme aims, for example, if it only targets certain types of businesses).</p>
<p>The value of non-academic reviewers may also be limited if the objects and types of impact sought by the funding schemes are unspecific and too open ended.</p>
<p>There is evidence that some academic reviewers believe they are sufficiently aware of the wider context in which research is used to assess proposals. Some also perceive the role of industry assessors negatively, potentially blocking worthy applications due to a lack of understanding of the academic context.</p>
<p>Interviewed funders report some difficulties in finding/recruiting non-academic reviewers. There are limited incentives to complete reviews in academia, and there are almost none in the industry or other sectors, which can be challenging. The funders use systems to find academic reviewers that are not always appropriate for finding non-academic reviewers. Therefore recruiting non-academic reviewers may require substantial additional effort for research funders.</p>
<p>There is, in short, some difficulty around this intervention, meaning it is important to consider carefully when to use it. However, as a means of increasing relevance and strengthening the science or society interface it has significant importance.</p>
<h4>References</h4>
<p><a href="https://academic.oup.com/spp/article/48/6/763/6332840">Does the inclusion of non-academic reviewers make any difference for grant impact panels?</a> Luo J, Ma L and Shankar K.</p>
<p><a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0165147">The influence of peer reviewer expertise on the evaluation of research funding applications</a>. Gallo SA, Sullivan JH and Glisson SR.</p>
<p><a href="https://www.rand.org/pubs/research_reports/RR139.html">Alternatives to peer review in research project funding</a>. Guthrie S.</p>
<p><a href="https://academyhealth.org/publications/2019-11/innovating-research-funding-process-peer-review-alternatives-and-adaptations">Innovating in the research funding process: peer review alternatives and adaptations</a>. Guthrie S.</p>
<p><a href="https://rori.figshare.com/articles/report/The_experimental_research_funder_s_handbook_final_version_/19459328">The experimental Research funderâ€™s handbook</a>. Bendiscioli S, Firpo T, Bravo-biosca A, Czibor E, Garfinkel M, Stafford T and Wilsdon J.</p>
<p><a href="https://www.technopolis-group.com/wp-content/uploads/2020/02/Support-to-the-generation-of-a-Research-and-Innovation-Funding-Service.pdf">UKRI Research and Innovation Funding Service (RIFS) visioning work (PDF, 1.5MB)</a>. Kolarz P, Bryan B, Farla K, KrÄÃ¡l A, Potau X and Simmonds P.</p>
<p><a href="http://www.diva-portal.org/smash/record.jsf?pid=diva2%3A1307597&amp;dswid=-4867">How research funders ensure the scientific legitimacy of their decisions: investigation in support of the design of Formas scientific management</a>. Kolarz P, Arnold E, DavÃ© A and AndrÃ©asson H.</p>
<p><a href="https://academic.oup.com/spp/article/50/4/619/7115831">Evaluation of research proposals by peer review panels: broader panels for broader assessments?</a> Abma-Schouten R, Gijbels J, Reijmerink W and Meijer I.</p>
<p><a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0196914">Peer review of health research funding proposals: A systematic map and systematic review of innovations for effectiveness and efficiency</a>. Shepherd J, Frampton GK, Pickett K and Wyatt JC.</p>
<h4>Interviewees and survey responses</h4>
<p>Three survey responses</p>
<p>Five interviews</p>
<h3>Virtual panels</h3>
<p>Convening panels online rather than in person.</p>
<h4>Main intended aims</h4>
<p>The main aims are to:</p>
<ul>
<li>save costs and carbon footprint</li>
<li>ensure more international panellists</li>
<li>generally remove barriers to participation</li>
</ul>
<h4>Main hazards</h4>
<p>The main hazards is that there is potentially less robust or detailed discussion, though this is unclear.</p>
<h4>Evidence strength</h4>
<p>Three star</p>
<h4>Findings</h4>
<p>Online panels saw drastically increased use during the COVID-19 pandemic to overcome travel restrictions and lockdowns. More broadly, online panels can help secure participation of international panel members. At a general level, online panels aim to reduce the costs and environmental impact of international (and even national) panellists travelling. Panellists with caring responsibilities or any other travel limitations are also usually more able to participate in virtual panels.</p>
<p>Online panels have been widely adopted by CRUK since the pandemic, and this has resulted in increased participation of international assessors. Other examples report cost reductions and greater diversity of panels. The NSF for example experimented with virtual panels in 2010, and an article in Science reports cost savings of $10,000 per panel.</p>
<p>There is a perceived need with virtual panel meetings to provide especially clear briefing beforehand. Some consultees see a risk of lower engagement and therefore shorter discussions compared to face-to-face panels, which can also be seen as positive in some cases with a very focused discussion.</p>
<p>Although the use of this intervention has increased very recently, there is a lot of positive feedback and agreement around its effectiveness. However, virtual panels saw a substantial increase in use during the COVID-19 pandemic, bringing them to the attention of many more stakeholders.</p>
<p>Much of our literature does not cover these recent experiences and it is possible that this intervention has more detractors than the pre-pandemic literature suggests. We note as one example the Irish Research Councilâ€™s Laureate Award scheme, which shifted its panel meetings online during the pandemic and was reviewed shortly thereafter. The report surveyed panellists on the experience and whether online panels should be mainstreamed in future. While the mean opinion is reported to be in the range of â€˜neutralâ€™ to â€˜somewhat in favourâ€™, the review notes a broad range of different sentiments, indicating the need for more research and consultation on the matter.</p>
<h3>References</h3>
<p><a href="https://doi.org/10.1136/bmjopen-2020-047386">Face-to-face panel meetings versus remote evaluation of fellowship applications: simulation study at the Swiss National Science Foundation</a>. Bieri M, Roser K, Heyard R and Egger M.</p>
<p><a href="https://www.science.org/doi/10.1126/science.331.6013.27">Meeting for peer review at a resort thatâ€™s virtually free</a>. Bohannon J.</p>
<p><a href="https://doi.org/10.1371/journal.pone.0071693">Teleconference versus face-to-face scientific peer review of grant application: effects on review outcomes</a>. Gallo SA, Carpenter AS and Glisson SR.</p>
<p><a href="https://www.rand.org/pubs/research_reports/RR139.html">Alternatives to Peer Review in Research Project Funding</a>. Guthrie S, Guerin B, Wu H, Ismail S and Wooding S.</p>
<p><a href="https://doi.org/10.12688/f1000research.11917.2">What do we know about grant peer review in the health sciences?</a> Guthrie S, Ghiga I and Wooding S.</p>
<p><a href="https://academyhealth.org/publications/2019-11/innovating-research-funding-process-peer-review-alternatives-and-adaptations">Innovating in the research funding process: peer review alternatives and adaptations</a>. Guthrie S.</p>
<p><a href="https://research.ie/assets/uploads/2021/02/IRC-Laureate-review-FINAL.pdf">Pre-award process review of the IRC Laureate Award (PDF, 2.4MB)</a>. Kolarz P, Arnold E, Cimatti R, Dobson C and Seth V.</p>
<p><a href="https://doi.org/10.1186/s41073-022-00120-2">What works for peer review and decision: making in research funding: a realist synthesis, Research Integrity and Peer Review</a>. Recio-Saucedo A, Crane K, Meadmore K, Fackrell K, Church H, Fraser S and Blatch-Jones A.</p>
<p><a href="https://doi.org/10.1371/journal.pone.0196914">Peer review of health research funding proposals: A systematic map and systematic review of innovations for effectiveness and efficiency</a>. Shepherd J, Frampton GK, Pickett K and Wyatt JC.</p>
<h4>Interviewees and survey responses</h4>
<p>One survey response</p>
<p>Three interviews</p>
<h2 id="section-main-findings:-interventions-to-the-shape-of-decision-making">Main findings: interventions to the shape of decision-making</h2><h3>Wildcard</h3>
<p>Sometimes also known as â€˜Golden ticketâ€™ or â€˜Jokerâ€™. Each panel member (or other decision maker) is able to select one proposal (for example, per opportunity, per year, or similar) to guarantee funding (provided there is no conflict of interest), regardless of panel rankings or other decision-making processes.</p>
<h4>Main intended aims</h4>
<p>The main aims are to:</p>
<ul>
<li>fund riskier, transformative ideas</li>
<li>save debating time in panels</li>
</ul>
<h4>Main hazards</h4>
<p>The main hazard is that it is open to abuse if conflicts of interest are not monitored very well. This intervention requires anonymised reviewing.</p>
<h4>Evidence strength</h4>
<p>Three star</p>
<h4>Findings</h4>
<p>This is an intervention aimed mostly at increased funding for new and riskier ideas. The underlying assumption is that panels tend towards conservatism supported by the finding that often a single poor review may mean an application is rejected. This intervention provides a way of circumventing this type of â€˜group thinkâ€™.</p>
<p>A secondary aim of this intervention is to reach funding decisions more rapidly. Especially controversial applications (applications with some very positive and some very negative reviews) tend to take up a considerable time in panel meetings. A â€˜wildcardâ€™ option means occasionally ending long discussions where agreements seemingly cannot be reached.</p>
<p>There are three known instances of implementation (at Volkswagen (VW) Foundation, FWF and Villum Foundation). At Volkswagen Foundation and Villum Foundation outcomes were generally as hoped. Awarded applicants included greater numbers of young and early career researchers, and selected proposals included ones which would not have been awarded based on ranked scores. At FWF, no reviewers chose to apply their â€˜wildcardâ€™ in any of the three funding opportunities where it was used.</p>
<p>At the VW foundation, only 11 out of 183 possible grants (6%) have been awarded on the basis of a wildcard. One important effect of the wildcard option was to save time in the meetings, when two opposing opinions could not be resolved by further deliberation.</p>
<p>There is, however, a strong risk of cronyism, which means that conflicts of interest need to be monitored extremely carefully, and anonymised reviewing needs to accompany schemes where a â€˜wildcardâ€™ system is used. Both are likely necessary as even in anonymised reviewing, peer reviewers or panellists may still be able to infer the identity of the applicant based on the topic or approach. In addition, giving a panellist the power to outright select an application conflicts with interventions targeting subjectivity in the selection process via training.</p>
<p>The literature also tends to pair â€˜wildcardâ€™ systems with anonymised reviewing, so positive findings (for example, increased confidence to submit â€˜braverâ€™ ideas than usual) is likely contributed to by this double approach. The intervention has also been used only in experimental schemes thus far, setting a contextual predisposition to riskier research.</p>
<p>This appears to be a somewhat controversial approach. Among the sources available to us, strengths and risks are variously emphasised, with some positive and some negative verdicts.</p>
<h4>References</h4>
<p><a href="https://doi.org/10.1016/j.shpsa.2018.11.006">Mavericks and lotteries</a>. Avin S.</p>
<p><a href="https://www.embo.org/documents/science_policy/peer_review_report.pdf">Dealing with the limits of peer review with innovative approaches to allocating research funding (PDF, 314KB)</a>. Bendiscioli S and Garfinkel M.</p>
<p><a href="https://doi.org/10.13128/Substantia-182">I won a project!</a> GarcÃ­a-Ruiz JM.</p>
<p><a href="https://www.rand.org/pubs/research_reports/RR139.html">Alternatives to peer review in research project funding</a>. Guthrie S, Guerin B, Wu H, Ismail S and Wooding S</p>
<p><a href="https://doi.org/10.1186/s41073-022-00120-2">What works for peer review and decision-making in research funding: a realist synthesis</a>. Recio-Saucedo A, Crane K, Meadmore K, Fackrell K, Church H, Fraser S and Blatch-Jones A.</p>
<p><a href="https://www.nature.com/articles/d41586-018-02743-2">Fund ideas, not pedigree, to find fresh insight</a>. SinkjÃ¦r T.</p>
<h4>Interviewees and survey responses</h4>
<p>No survey responses</p>
<p>Three interviews</p>
<h3>Partial randomisation</h3>
<p>Successful proposals are chosen at random. In most methodologies, randomisation is only partial. For example, proposals may be scored and sorted into bands, and only those on the border of being funded will be randomised.</p>
<h4>Main intended aims</h4>
<p>The main aims are to:</p>
<ul>
<li>remove bias</li>
<li>reduce panel burden</li>
</ul>
<h4>Main hazards</h4>
<p>The main hazard is reputational impact on applicants.</p>
<h4>Evidence strength</h4>
<p>Three star</p>
<h4>Findings</h4>
<p>Literature, survey and interviews all suggest that partial randomisation aims to remove bias (both against demographic factors and riskier ideas), and to reduce administrative burden in the selection process. Mostly the burden is mentioned in connection to ranking, but the literature suggests that it has also been used (in connection with other interventions) to enable shorter applications. The use of partial randomisation is justified by increasingly overwhelming evidence that while peer or panel review reliably identifies the very highest quality applications, as well as the â€™tailâ€™ of unsuitable low-quality ones, it tends towards arbitrary decision making in the â€˜upper-midfieldâ€™ of the quality spectrum.</p>
<p>Evidence on this intervention is mainly from observations from real-life applications, some of which have been assessed for diversity and applicant satisfaction. However, in most cases it is too early to say anything about effect on the actual nature of the funded research. The approach is further supported with statistical analysis suggesting arbitrariness in the traditional peer review process.</p>
<p>The data collection identified at least six research funding bodies where partial randomisation has been used. Some assessments have been carried out on the impacts of the intervention, and at least two funders (Volkswagen Foundation (VWF) and SNSF) were found to have diversified their awardee pool. In addition, applications at BA, FWF and VWF were found to increase in response to the partial randomisation introduction. In the case of VWF, this was reportedly due to a perceived higher chance of success among applicants.</p>
<p>We identify two main concerns. First, (from the fundersâ€™ point of view) there is the risk of awarding lower-quality or less relevant awards. Second (from the applicantsâ€™ point of view), there is a concern of reputational impact from both rejections or successes.</p>
<p>The first concern is inevitable but can be mitigated by narrowing down the pool of applications to those where finding consensus among reviewers and panellists is challenging (genuinely poor-quality applications will at this stage already have been sifted out). This is typically the approach taken, and use of the term â€˜partial randomisationâ€™ rather than simply â€˜lotteryâ€™ is generally preferred in order to emphasise this point.</p>
<p>The second concern has been approached differently. At VWF, applicants were concerned about crediting their awards (if successful) to randomisation, which was mitigated by the added use of wildcards and not disclosing which applications were awarded via what method. FWF also used wildcards in combination with partial randomisation. However, in the three opportunities of its 1,000 Ideas programme, no reviewers used the wildcard option. FWF thinks this is because panel members were concerned about their reputation in case other jury members disagreed about the value of the application supported by the wildcard. Conversely, at SNSF, all applicants were informed if partial randomisation was used in both rejection letters and award letters to ensure transparency.</p>
<p>While there is controversy around this intervention in general terms, all evidence on implementation is fairly positive. From the UK, we also have anecdotal evidence that the academic communityâ€™s response to NERCâ€™s partial randomisation trial has been overwhelmingly positive.</p>
<p>We note also that there is considerable versatility in application, for instance in terms of how conservatively the process is used. RCN has thus far only randomised the selection of applications identical either in idea or scoring. It can (and often is) paired with applicant anonymisation to fully avoid bias (as some degree of filtering applications takes place in all instances of implementation). VWF relies on a quadruple process of anonymisation then outlines to full applications then wildcards followed by partial randomisation of those not outright selected but of good quality.</p>
<h4>References</h4>
<p><a href="https://doi.org/10.1016/j.shpsa.2018.11.006">Mavericks and lotteries</a>. Avin S.</p>
<p><a href="https://doi.org/10.15252/embr.201949472">The troubles with peer review for allocating research funding</a>. Bendiscioli S.</p>
<p><a href="https://rori.figshare.com/articles/report/The_experimental_research_funder_s_handbook_final_version_/19459328">The experimental research funderâ€™s handbook</a>. Bendiscioli S.</p>
<p><a href="https://doi.org/10.7554/eLife.13323">NIH peer review percentile scores are poorly predictive of grant productivity</a>. Fang FC, Bowen A and Casadevall A.</p>
<p><a href="https://doi.org/10.1128/mBio.00422-16">Research funding: the case for a modified lottery</a>. Fang FC and Casadevall A.</p>
<p><a href="https://www.rand.org/content/dam/rand/pubs/research_reports/RR100/RR139/RAND_RR139.pdf">Alternatives to peer review in research project funding</a>. Guthrie S, Guerin B, Wu H, Ismail S and Wooding S.</p>
<p><a href="https://academyhealth.org/publications/2019-11/innovating-research-funding-process-peer-review-alternatives-and-adaptations">Innovating in the research funding process: peer review alternatives and adaptations</a>. Guthrie S.</p>
<p><a href="https://www.researchgate.net/publication/301597208_The_consequences_of_competition_simulating_the_effects_of_research_grant_allocation_strategies">The consequences of competition: simulating the effects of research grant allocation strategies</a>. HÃ¶ylÃ¤ T, Bartneck C and Tiihonen T.</p>
<p><a href="https://doi.org/10.1080/03623319.2020.1728506">Are peer-reviews of grant proposals reliable? An analysis of Economic and Social Research Council (ESRC) funding applications</a>. Jerrim J and de Vries R.</p>
<p><a href="https://doi.org/10.2777/16211">Study on the proposal evaluation system for the EU R&amp;I framework programme</a>. Rodriguez-Rincon D, Feijao C, Stevenson C, Evans H, Sinclair A, Thomson S and Guthrie S.</p>
<p><a href="https://blogs.lse.ac.uk/impactofsocialsciences/2019/12/11/blind-luck-could-lotteries-be-a-more-efficient-mechanism-for-allocating-research-funds-than-peer-review/">Blind Luck â€“ Could lotteries be a more efficient mechanism for allocating research funds than peer review?</a> Roumbanis L.</p>
<p><a href="https://doi.org/10.1177/0162243918822744">Peer review or lottery? A critical analysis of two different forms of decision-making mechanisms for allocation of research grants</a>. Roumbanis L.</p>
<p><a href="https://www.volkswagenstiftung.de/en/funding/peer-review/partially-randomized-procedure-lottery-and-peer-review">Partially Randomized Procedure â€“ Lottery and Peer Review</a>. VolkswagenStiftung.</p>
<p><a href="https://www.volkswagenstiftung.de/en/news/story/give-chance-chance">Give Chance a Chance</a>. Walsweer T.</p>
<h4>Interviewees and survey responses</h4>
<p>One survey response</p>
<p>Six interviews</p>
<h3>Scoring mechanisms</h3>
<p>Includes calibration of scores, consensus vs voting, weighting.</p>
<h4>Main intended aims</h4>
<p>The main aims are to:</p>
<ul>
<li>increase the relevance of funded projects to the aims</li>
<li>improve review quality or reliability</li>
</ul>
<h4>Main hazards</h4>
<p>There are no confirmed hazards but it may disadvantage high-risk or high-reward applications.</p>
<h4>Evidence strength</h4>
<p>Four star</p>
<h4>Findings</h4>
<p>Consulted funders and literature point to two main variants of this intervention. The first involves applying equal weighting of some criteria to meet the specific needs of the funding scheme (for example, wider or non-academic impact, novelty). Reviewed literature and survey respondents provided examples of the use of equal weighting of scientific merit and impact, making the scoring matrix and calibration of scores more quantitative or absolute. Consulted funders claim that the intervention was successful in making sure the right applications were funded considering the importance of impact. The intervention also appears to have been successful in that panels followed the criteria and funder instructions instead of any other considerations (for example, applying or balancing criteria as they would in â€˜ordinaryâ€™ schemes).</p>
<p>In the second variant of this intervention, reviewers may apply their own interpretation of criteria and weightings when scoring proposals. According to the literature, calibration of scores (disclosure of scores and discussion to calibrate scores between reviewers) has been found to have the effect of converging scores within a panel, but not an increase in relatability overall (as tested in experiments with multiple panels scoring the same proposals).</p>
<p>Our research has not identified any known hazards of this intervention.</p>
<p>The literature points out that, depending on the situation, the two objectives for the use of this intervention (increase reliability and meet specific funding needs) might lead to opposite recommendations. For instance, to increase reliability, one might recommend calibration and elimination of outliers, whereas to identify and fund novel research, one might want to prioritise proposals with highly variable scores.</p>
<h4>References</h4>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/23029386/">Peer review of grant applications: criteria used and qualitative study of reviewer practices</a>. Abdoul H, Perrey C, Amiel P, Tubach F, Gottot S, Durand-Zaleski I, Alberti C.</p>
<p><a href="https://www.rand.org/pubs/research_reports/RR139.html">Alternatives to peer review in research project funding â€“ 2013 update</a>. Guthrie S, Guerin B, Wu H, Ismail S, Wooding S.</p>
<p><a href="https://www.tandfonline.com/doi/abs/10.1080/03623319.2020.1728506?journalCode=ussj20">Are peer-reviews of grant proposals reliable? An analysis of Economic and Social Research Council (ESRC) funding applications</a>. Jerrim J and de Vries R.</p>
<p><a href="https://www.cambridge.org/core/journals/philosophy-of-science/article/abs/commensuration-bias-in-peer-review/167B46F1B092E28E163D8F7E52EE9FD5">Commensuration bias in peer review</a>. Lee CJ.</p>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5407376/">Your comments are meaner than your scoreâ€™: score calibration talk influences intra- and inter-panel variability during scientific grant peer review</a>. Pier EL, Raclaw J, Kaatz A, Brauer M, Carnes M, Nathan MJ and Ford CE.</p>
<h4>Interviewees and survey responses</h4>
<p>Two survey respondents</p>
<p>No interviews</p>
<h3>Sequential application of criteria (rather than simultaneous application)</h3>
<p>A proposal is scored for one set of criteria, ranked and a cut-off point determined. Then those above the cut-off point are assessed again for another set of criteria to determine the final funded list.</p>
<h4>Main intended aims</h4>
<p>The main aims are to:</p>
<ul>
<li>ensure application of all criteria</li>
<li>increase relevance to programme aims</li>
</ul>
<h4>Main hazards</h4>
<p>None known</p>
<h4>Evidence strength</h4>
<p>Two star</p>
<h4>Findings</h4>
<p>This intervention is typically related to two-stage approaches, pre-proposals or both. The literature shows that funders can use this for programmes with a complex set of aims (typically research excellence as well as non-academic relevance), where assessing based on one set of criteria first can help reduce the burden of subsequent rounds.</p>
<p>The Dutch NWOâ€™s â€˜Veniâ€™ programme required the submission of a CV and track record along with an initial short proposal. This first round thus included an assessment of the set of criteria related to the researchersâ€™ qualities. This allowed a reduction in the number of applications progressing to the subsequent round focused on an assessment of the proposal and potential impact. This is reported to have worked well and reduced the assessment time of reviewers by 25%.</p>
<p>We note at this point the evidence on this form of criteria application is too limited to arrive at a strong verdict. However, it needs to be considered alongside the aforementioned two-stage approaches, pre-proposals or both, which often implicitly take this approach (however, they do not always do so, hence we mention this intervention here separately).</p>
<h4>References</h4>
<p><a href="https://scienceeurope.org/our-resources/science-europe-study-on-research-assessment-practices/">Science Europe study on research assessment practices</a>. del Carmen Calatrava Moreno M, Warta K, Arnold E, Tiefenthaler B, Kolarz P and Skok S.</p>
<p><a href="https://www.technopolis-group.com/wp-content/uploads/2020/02/Support-to-the-generation-of-a-Research-and-Innovation-Funding-Service.pdf">UKRI Research and Innovation Funding Service (RIFS) visioning work â€“ Final report (PDF, 1.5MB)</a>. Kolarz P, Bryan B, Farla K, KrÄÃ¡l A, Potau X and Simmonds P.</p>
<p><a href="http://www.diva-portal.org/smash/record.jsf?pid=diva2%3A1307597&amp;dswid=-1200">How research funders ensure the scientific legitimacy of their decisions: investigation in support of the design of Formas scientific management.</a> Kolarz P, Arnold E, DavÃ© A and AndrÃ©asson H.</p>
<h4>Interviewees and survey responses</h4>
<p>No survey responses or interviews</p>
<h3>Use of quotas</h3>
<p>After ranking, proposals are reviewed to ensure sufficient numbers in certain categories including quotas related to protected characteristics, place, first-time applicants, etc.</p>
<h4>Main intended aims</h4>
<p>The main aim is to avoid or counteract bias and â€˜clusteringâ€™.</p>
<h4>Main hazards</h4>
<p>The main hazard is that this is a very drastic approach.</p>
<h4>Evidence strength</h4>
<p>One star</p>
<h4>Findings</h4>
<p>Quotas are a means of avoiding clustering of investments in places or themes and ensuring equitable success rates among disadvantaged and minority researcher populations.</p>
<p>Our research indicates that funders use quotas to ensure diversity among reviewers and panel members (see also intervention on â€˜embedding EDI in assessmentâ€™ below). Some literature items discuss applying quotas as an option at the decision point, but we found no evidence of implementation. Some literature items point to this measure being too drastic and that funders can achieve diversity through other means (for example, working with underrepresented groups, partial randomisation, anonymisation).</p>
<h4>References</h4>
<p><a href="https://doi.org/10.38126/jspg180408">Addressing racial disparities in NIH funding</a>. Comfort N.</p>
<p><a href="http://hdl.handle.net/10261/200024">Grant allocation disparities from a gender perspective: literature review</a>. Cruz-Castro L and Sanz-MenÃ©ndez L.</p>
<p><a href="https://www.tandfonline.com/doi/abs/10.1080/08989621.2021.1927727">The modified lottery: formalizing the intrinsic randomness of research funding, accountability in research</a>. De Peuter S and Conix S.</p>
<h4>Interviewees and survey responses</h4>
<p>One survey response</p>
<p>No interviews</p>
<h2 id="section-main-findings:-interventions-in-training-and-feedback">Main findings: interventions in training and feedback</h2><h3>Bringing in reviewers from earlier careers and providing mentoring</h3>
<p>Panels and reviewers tend to be very experienced researchers or innovators. Those early in their careers could be invited to review or be part of panels with additional training, bringing different perspectives and experiences. Previous funding opportunity award winners may also be brought in as reviewers or panellists.</p>
<h4>Main intended aims</h4>
<p>The main aims are to:</p>
<ul>
<li>improve review quality</li>
<li>diversify reviewers</li>
</ul>
<h4>Main hazards</h4>
<p>None known</p>
<h4>Evidence strength</h4>
<p>Two star</p>
<h4>Findings</h4>
<p>Funders use this intervention to improve review quality, reduce burden, diversify the pool of reviewers and provide career support to early career researchers (ECRs). Most consulted funders involve ECRs in the peer review and one (CRUK) invites ECRs to observe panels and committees. One funder (Wellcome) has specific targets for the number of ECRs on its panels.</p>
<p>All consulted funders report positive feedback from involved ECRs. The experience helped them to learn about the process, improve their grant writing skills and made the assessment process more transparent.</p>
<p>All funders report significant interest and demand from ECRs to be involved in the peer review. This results in improved ability of funders to secure reviewers (because of the larger pool available). Similarly, all sources available to us report that ECRs provide very good quality reviews and are very enthusiastic. Though most evidence is based on funder observation rather than controlled experiments, there is general agreement on the effectiveness of this intervention.</p>
<h4>References</h4>
<p>None</p>
<h4>Interviewees and survey responses</h4>
<p>Three survey responses</p>
<p>Three interviews</p>
<h3>Embedding EDI in assessment</h3>
<p>Training or support provided to make assessors aware of their unconscious biases and to encourage them to call each other out during the assessment process.</p>
<h4>Main intended aims</h4>
<p>The main aims are to:</p>
<ul>
<li>reduce bias</li>
<li>increase diversity among awardees</li>
</ul>
<h4>Main hazards</h4>
<p>The main hazards are that ineffective training may install a false sense of confidence.</p>
<h4>Evidence strength</h4>
<p>Two star</p>
<h4>Findings</h4>
<p>Funders introduce this intervention to reduce bias, enable fair decisions and improve diversity in the funded portfolio.</p>
<p>Consultees pointed out that there is no way to remove bias entirely, but they feel that highlighting potential issues (via training) helps. It is difficult to demonstrate the effectiveness of this intervention because it is hard to attribute positive changes to a single intervention (hence the relatively low star-rating for this intervention despite many sources). But anecdotal feedback from panel members is that it does make them question their biases and decisions. For example, since anti-bias training for the Austrian FWFâ€™s board (â€˜Kuratoriumâ€™), every board meeting now starts with a one-slide reminder about bias and the need to call it out.</p>
<p>Submissions and success rates by demographics are periodically reviewed in organisations including the UK research councils. In different funding institutions in Canada, finding improvements in the diversity of the funded portfolio (though as noted, causality is difficult to confirm).</p>
<p>We find only anecdotal evidence from funders, in some cases based on monitoring data, but it is a challenge to attribute change to a single intervention. There is nevertheless broad consensus about the relevance of this intervention despite difficulty attributing change directly.</p>
<p>Available material discussing the effectiveness of this type of training offers mixed views and cautions against blind reliance on it. Training approaches vary greatly, and ineffective training may harmfully install a false sense of confidence. The reliability of self-reported results has also been questioned. Other points of criticism assess its impact at the institutional level and note that bias training should only form part of a more holistic approach addressing the bigger picture. That said, there is little evidence addressing unconscious bias training in grant peer review specifically (the majority of the material on the effect of unconscious bias training focuses on general professional or healthcare settings).</p>
<p>We note that there are several aspects to EDI, and a wide range of techniques that may be implemented. Some additional forms of embedding EDI at UKRI have included reducing the number of proposals at panel and increasing the number of breaks to help with cognitive overload, silent scoring, and management of any unacceptable behaviours or comments at the panel. Some councils have also had diversity panel targets in place since May 2016 (for example, panels aim to meet at least 30% representation of the underrepresented gender) and there are gender and ethnicity targets to increase diversity of perspective in assessment. (For current guidance, see: <a href="/what-we-do/supporting-healthy-research-and-innovation-culture/equality-diversity-and-inclusion/epsrc/evolving-and-upholding-fairness-in-peer-review/">Evolving and upholding fairness in peer review</a>) These targets have since been met or surpassed.</p>
<p>While not fully related to this intervention, we note that all interviewed funders try to ensure balanced panels, and two funders (Wellcome and CRUK) have introduced diversity targets and quotas. Wellcome achieved the targets in 2022, which has been a big success, as it brings in a much broader breadth of voices. Wellcome did not have any challenges securing diverse membership, but there is a tendency to go to the same reviewers. Regarding the impact this intervention has had on the diversity of the portfolio, it is too early to tell. Wellcome has not seen a significant shift in, for example, the proportion of ethnic minority groups. The measure was introduced because it was deemed the right thing to do and to improve the diversity of voices. This intervention has become a new normal at Wellcome and will not change.</p>
<h4>References</h4>
<p><a href="/publications/inequality-in-early-career-research-in-the-uk-life-sciences/">Inequality in early career research in the UK life sciences</a>. Dias Lopes A and Wakeling P.</p>
<p><a href="/publications/epsrc-understanding-our-portfolio-a-gender-perspective/">Understanding our portfolio: a gender perspective</a>. EPSRC.</p>
<p><a href="https://bmcpsychology.biomedcentral.com/articles/10.1186/s40359-019-0299-7">Interventions designed to reduce implicit prejudices and implicit stereotypes in real world contexts: a systematic review</a>. Fitzgerald C, Martin A, Berner D and Hurst S.</p>
<p><a href="https://doi.org/10.1093/biosci/biab130">Scientists from minority-serving institutions and their participation in grant peer review</a>. Gallo SA, Sullivan JH and Croslan DJR.</p>
<p><a href="https://www.scientificamerican.com/article/the-problem-with-implicit-bias-training/">The problem with implicit bias training</a>. Green T and Hagiwara N.</p>
<p><a href="https://www.mcgill.ca/pharma/files/pharma/final_report.win4science_report_-_nov_30_2018.pdf">The state of women in life sciences at McGill: a summary and report of the Win4Science Forum (PDF, 918KB)</a>. Hillier E, Razack S, Clary V and MÃ¼nter L.</p>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5822732/">Who resembles a scientific leader â€“ Jack or Jill? How implicit bias could influence research grant funding</a>. Kolehmainen C and Carnes M.</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/30739671/">The good, the bad, and the ugly of implicit bias</a>. Pritlove C, Juando-Prats C, Ala-Leppilampi K and Parsons J.</p>
<p><a href="https://doi.org/10.1128/mmbr.00018-19">Does gender bias still affect women in science?</a> Roper RL.</p>
<p><a href="https://doi.org/10.1503/cmaj.170901">Assessment of potential bias in research grant peer review in Canada</a>. Tamblyn R, Girard N, Qian CJ and Hanley J.</p>
<p><a href="https://www.gov.uk/government/publications/unconscious-bias-and-diversity-training-what-the-evidence-says">Unconscious bias and diversity training â€“ what the evidence says</a>. The Behavioural Insights Team</p>
<p><a href="https://doi.org/10.1057/s41599-020-00656-y">Is there gender bias in research grant success in social sciences? Hong Kong as a case study</a>. Yip PSF, Xiao Y, Wong CLH and Au TKF.</p>
<h4>Interviewees and survey responses</h4>
<p>Three survey responses</p>
<p>Four interviews</p>
<h3>Expanding or reducing feedback to unsuccessful applicants</h3>
<p>Different levels of feedback may be provided on unsuccessful applications.</p>
<h4>Main intended aims</h4>
<p>The main aims are to:</p>
<ul>
<li>improve transparency</li>
<li>improve applicantsâ€™ learning from unsuccessful applications</li>
</ul>
<h4>Main hazards</h4>
<p>The main hazards are:</p>
<ul>
<li>an added burden</li>
<li>that feedback may be of inconsistent quality</li>
</ul>
<h4>Evidence strength</h4>
<p>Two star</p>
<h4>Findings</h4>
<p>Consulted funders use feedback mainly to explain decisions and thus increase theÂ  transparency of the assessment process. Some share feedback only if an applicant requests it. A secondary aim is to ensure there can be a better learning process for unsuccessful applicants.</p>
<p>Literature on the subject is limited but one study shows that well-developed, good-quality feedback helps applicants to improve the quality of future applications. Consulted institutions reported that in rare instances when unsuccessful applicants receive feedback, it is very helpful, and encouraged the funders do so more.</p>
<p>One funder changed the presentation of feedback by sending panel membersâ€™ written comments verbatim instead of a summary of the panel discussion. This was not effective because applicants received several sets of comments which can conflict with each other, making it difficult for applicants to understand the rationale for the decision on their application.</p>
<p>A notable hazard is that it is hard to be consistent and equitable with the type of feedback given, as the quality of feedback may differ at least slightly. Additionally, consolidating, checking and distributing feedback creates an additional burden for the funder. There is therefore a trade-off here between transparency and learning on one hand and reduced burden on the other.</p>
<p>Evidence is mostly anecdotal, based on funder observations and one survey of applicants. However, there generally seems to be appetite for more feedback on unsuccessful application. Given the added burden, there is a case to consider carefully whether feedback is more useful in some funding schemes or for some applicant types than for others.</p>
<h4>References</h4>
<p><a href="https://osf.io/preprints/socarxiv/a8psh/">Targeted, actionable and fair: reviewer reports as feedback and its effect on ECR career choices</a>. Derrick GE, Zimmermann A, Greaves H, Best J and Klavans R.</p>
<p><a href="https://doi.org/10.2777/16211">Study on the proposal evaluation system for the EU R&amp;I framework programme</a>. Rodriguez-Rincon D, Feijao C, Stevenson C, Evans H, Sinclair A, Thomson S and Guthrie S.</p>
<h4>Interviewees and survey responses</h4>
<p>One survey response</p>
<p>Five interviews</p>
<h3>Funder representation on review panels</h3>
<p>The funder is represented on the panel to guide discussion or provide briefing on programme aims. Their role is beyond a purely administrative function, they may even be in a chair role or similar.</p>
<h4>Main intended aims</h4>
<p>The main aims are to:</p>
<ul>
<li>ensure guidance is followed</li>
<li>help ensure the relevance of decisions to scheme aims</li>
</ul>
<h4>Main hazards</h4>
<p>None known</p>
<h4>Evidence strength</h4>
<p>Two star</p>
<h4>Findings</h4>
<p>Funders are usually represented on review panels to ensure the panels follow the guidance and to document the process but not in an advisory or chair role. In this intervention, representatives of the funder take a more active role in communicating scheme aims and ensuring that the review and discussion stay focused on the schemeâ€™s main criteria. This may happen at the start of panel meetings, but may also involve prior briefings, as well as reminders and steering while discussion of applications is taking place. However, even within this intervention, funder representatives generally do not have a role in making the funding recommendations as such (they may steer but they do not have a â€˜voteâ€™).</p>
<p>We note that â€˜funder representationâ€™ is a term that is somewhat open to interpretation. For example, in the Austrian FWFâ€™s Emerging Fields scheme, the FWF board is involved in the decision making at several points in the multi-stage decision-making process. Its members are based at various research performing organisations. However, the Executive Board president chairs these board meetings. This individual has a strong academic track and experience but is closely familiar with the funderâ€™s strategy and operations. The Emerging Fields scheme is currently subject to evaluation and so the effects of this form of funder representation are at this point unknown.</p>
<p>A more â€˜clear-cutâ€™ type of funder representation on panels occurs at the Human Frontier Science Program (HFSP), which has undergone a full organisational and process review recently. The review found that, in line with its stated objectives, the HFSP process successfully identifies the most innovative, â€˜frontierâ€™ research ideas and recommends them for funding. However, the review further found that it relies primarily on culture rather than process structure to achieve this, and that this â€˜HFSP-cultureâ€™ is in part perpetuated through the presence and input of secretariat staff at the panel meetings. While secretariat staff are not involved in the decision making itself, they ensure through briefing both the panel in general and new panellists individually about the purpose of the programme and the emphasis on â€˜frontierâ€™ research that panellists are expected to identify and reward.</p>
<p>A further example worth noting (though it does not constitute â€˜funder representationâ€™ in the strict sense) is ESRCâ€™s Transformative Research scheme. In its third round, an awardee from the first round two years prior was selected as panel chair, with the aim of ensuring a cultural understanding of the scheme aims (and therefore of the criteria and how to select applications) would be ingrained in the panel as much as possible. While this chair did not represent the funder (ESRC) as such, their previous involvement with the scheme meant that they could be an important voice to communicate the scheme aims to the rest of the panel. Evaluation of the scheme found that, alongside other process innovations, this selection of panel chair played an important role in maintaining the panelâ€™s focus on the â€˜transformativeâ€™ element of submitted applications.</p>
<p>While evidence on this intervention is relatively limited, there is agreement among consultees that funder presence on panels helps to ensure panels follow the funder guidance and thus improves the quality of the assessment, and some evaluative evidence points in the same direction.</p>
<h4>References</h4>
<p><a href="https://webarchive.nationalarchives.gov.uk/ukgwa/20210323114051/https://esrc.ukri.org/files/research/research-and-impact-evaluation/esrc-transformative-research-scheme-evaluation/">Evaluation of the ESRC Transformative Research Scheme (PDF, 1.5MB)</a>. Kolarz P, Arnold E, Farla K, Gardham S, Nielsen K, Rosemberg C and Wain M.</p>
<p><a href="https://www.hfsp.org/node/74873#book/">Organisational and process review of the Human Frontier Science Program</a>.Â Kolarz P, DavÃ© A, Bryan B, Urquhart I, Rigby J and Suninen L.</p>
<h4>Interviewees and survey responses</h4>
<p>No survey responses</p>
<p>Two interviews</p>
<h3>Improving quality of reviews</h3>
<p>Through training, retaining good reviewers or recognition. Peer Review colleges fit here too.</p>
<h4>Main intended aims</h4>
<p>The main aims are to:</p>
<ul>
<li>improve quality of reviews</li>
<li>simplify training</li>
<li>increase response rate for review requests</li>
</ul>
<h4>Main hazards</h4>
<p>None known</p>
<h4>Evidence strength</h4>
<p>Four star</p>
<h4>Findings</h4>
<p>Funders use training and peer review colleges to improve the quality of reviews. The literature on this intervention mostly uses reviewer agreement as a proxy for improved quality of the review. Peer review colleges are also seen as a tool to address peer-review fatigue and to increase reviewer response rates.</p>
<p>However, some sources speculate about high disagreement being an indication of the high-risk/high-reward nature of an application. We note this to indicate that, while the overall evidence base on this intervention is strong, there is some disagreement about whether this common form of measuring its success might have some limitations.</p>
<p>One controlled trial at the US National Institutes of Health showed that a training programme to increase inter-rater reliability improved scoring accuracy and reviewer agreement. Consulted funders also report that use of a peer review college provides a large number of reviewers to approach initially who are familiar with the scheme and have a proven track record of providing good reviews. Additional training has been useful and that has been developed based on common review errors.</p>
<p>An ongoing example of the above can be found at EPSRC, whose peer review college consists of more than 6000 members, all of whom have undergone online training upon joining the college. The training, among other factors in the membership, is stated to help members to increase their knowledge of proposal writing and reviewing.</p>
<p>Funders note that they receive more reviews per request from college members compared to â€˜coldâ€™ peer review invites as well as a higher percentage of reviews of suitable quality.</p>
<p>Evidence on this intervention is fundamentally strong, there are controlled trials reported in literature (about training) and funder observations and monitoring data on positive responses to peer review requests and improved review quality.</p>
<h4>References</h4>
<p><a href="https://www.esf.org/fileadmin/user_upload/esf/PeerReview-Practices_Survey2011.pdf">ESF survey analysis report on peer review practices (PDF, 6.4MB)</a>. ESF</p>
<p><a href="https://doi.org/10.12688/f1000research.11917.2">What do we know about grant peer review in the health sciences?</a> Guthrie S, Ghiga I and Wooding S.</p>
<p><a href="https://doi.org/10.1186/s41073-021-00115-5">Individual versus general structured feedback to improve agreement in grant peer review: a randomized controlled trial</a>. Hesselberg J-O, Fostervold K I, Ulleberg P and Svege I.</p>
<p><a href="https://clarivate.com/lp/global-state-of-peer-review-report/">Global state of peer review 2018</a>. Publons and Clarivate Analytics.</p>
<p><a href="https://doi.org/10.1186/s41073-022-00120-2">What works for peer review and decision-making in research funding: a realist synthesis</a>. Recio-Saucedo A, Crane K, Meadmore K, Fackrell K, Church H, Fraser S and Blatch-Jones A.</p>
<p><a href="https://doi.org/10.1371/journal.pone.0130450">Grant peer review: improving inter-rater reliability with training</a>. Sattler D N, McKnight P E, Naney L and Mathis R.</p>
<p><a href="https://doi.org/10.1371/journal.pone.0196914">Peer review of health research funding proposals: a systematic map and systematic review of innovations for effectiveness and efficiency</a>. Shepherd J, Frampton G K, Pickett K, Wyatt J C.</p>
<h4>Interviewees and survey responses</h4>
<p>Two survey responses</p>
<p>Three interviews</p>
<h3>Open review or rebuttal</h3>
<p>Reviews are published or made available to the applicant, or both, before funding decisions are taken, so they can be viewed and responded to.</p>
<h4>Main intended aims</h4>
<p>The main aim is to increase accountability and review quality.</p>
<h4>Main hazards</h4>
<p>The main hazard is that it possibly increases the burden for the funder (and longer timelines depending how rebuttal works).</p>
<h4>Evidence strength</h4>
<p>Three star</p>
<h4>Findings</h4>
<p>Open reviews and rebuttals have been particularly well-known elements in journal peer review but are also becoming recognised as potential tools for grant peer review. Open peer review is considered an umbrella term inclusive of open identities, open reviews and open interaction. They are expected to lead to increased accountability, challenging unjust reviews, giving applicants more voice in the process and increasing overall review quality. The latter is particularly enabled by applicants being able to clarify in case reviewers have genuinely misunderstood some of the applicationâ€™s content, which may be especially important where English is not the applicantâ€™s first language. Open identities are also hoped to contribute to the credit of the reviewer.</p>
<p>Consulted funders were positive about the intervention as it is well received by the applicants and reviewers and helps to increase the transparency of the process.</p>
<p>There are, however, some opposing voices. Concerns have been raised about the potential for reduced rigour and valid criticism where the identities of the reviewers are made known. Literature also points to a potential (but not evidenced) increase in burden, though consulted funders did not raise this concern.</p>
<p>A prominent example of the ongoing use of rebuttals is at NWO (Dutch Research Council), where reviews are shared with applicants, who then have one week to produce a short rebuttal to reflect on issues raised by reviewers. These rebuttals will be reviewed along with the review by the panel. In other words, the rebuttals may influence the funding recommendation. One reviewed study suggests that this rebuttal stage may have a corrective effect on some degree of gender bias in the review process.</p>
<p>A similar process is also used at UKRI. There is a 10 working day turnaround time for lead applicants to provide a rebuttal (recently extended from five working days to take into account EDI concerns). These may then influence the final funding decision. They are provided to the panel alongside the written reviews to aid their decision making.</p>
<h4>References</h4>
<p><a href="https://doi.org/10.1371/journal.pone.0244529">Attitudes and practices of open data, preprinting, and peer-review-A cross sectional study on Croatian scientists.</a> BaÅ¾dariÄ‡ K, VrkiÄ‡ I, Arh E, Mavrinac M, MarkoviÄ‡ M G, BiliÄ‡-Zulle L, Stojanovski J and MaliÄki M.</p>
<p><a href="https://doi.org/10.1016/j.respol.2021.104399">Gender-equal funding rates conceal unequal evaluations</a>. Bol T, de Vaan M and van de Rijt A.</p>
<p><a href="https://www.hepi.ac.uk/2022/09/29/plan-b-research-funding-turning-adversity-into-opportunity/">Horizon Europe and Plan B research funding: turning adversity into opportunity</a>. Cavallaro M.</p>
<p><a href="https://www.genderportal.eu/resources/report-strategic-advice-enhancing-gender-dimension-open-science-and-innovation-policy">Strategic advice for enhancing the gender dimension of Open Science and Innovation Policy</a>. Gender Action.</p>
<p><a href="https://academyhealth.org/publications/2019-11/innovating-research-funding-process-peer-review-alternatives-and-adaptations">Innovating in the research funding process: peer review alternatives and adaptations</a>.Â Guthrie S.</p>
<p><a href="https://www.embopress.org/doi/full/10.15252/embr.201948587">Response by the Author</a>. Hill M.</p>
<p><a href="https://doi.org/10.1371/journal.pone.0239757">Decision-making approaches used by UK and international health funding organisations for allocating research funds: a survey of current practice</a>. Meadmore K, Fackrell K, Recio-Saucedo A, Bull A, Fraser S D S and Blatch-Jones A.</p>
<p><a href="http://www.diva-portal.org/smash/record.jsf?pid=diva2%3A1307597&amp;dswid=-3985">How research funders ensure the scientific legitimacy of their decisions: investigation in support of the design of Formas scientific management</a>. Kolarz P, Arnold E, DavÃ© A and AndrÃ©asson H.</p>
<p><a href="https://doi.org/10.1186/s41073-022-00120-2">What works for peer review and decision-making in research funding: a realist synthesis</a>. Recio-Saucedo, A. Crane K, Meadmore K, Fackrell K, Church H, Fraser S and Blatch-Jones A.</p>
<h4>Interviewees and survey responses</h4>
<p>One survey response</p>
<p>Two interviews</p>
<h2 id="section-additional-interventions-identified-by-our-review">Additional interventions identified by our review</h2><p>Our data collection focused on the 38 interventions that served as a baseline for this review. However, while going through the literature on the set of 38 and running several consultations, we identified some other interventions not included in the initial list. Two of these are recently introduced interventions facilitated by technological advances and increased use of information technology to support the peer review process. A third summarises various actions to improve behaviours and culture or supporting EDI in interviews and panel meetings. We briefly describe these interventions here.</p>
<h3>Roving panel members</h3>
<p>The UKRI Future Leaders Fellowships scheme uses panels of experts from across the research and innovation system to consider all assessment criteria, and the panel members are roving. Panel members change panels through the assessment process to ensure consistency and quality between panels. The intervention is easy to introduce, and according to programme staff, it makes a significant difference in ensuring consistency across the panels.</p>
<h3>Discussion boards</h3>
<p>BBSRC uses discussion boards (shared virtual platforms for information exchange) to reduce â€˜on the dayâ€™ peer review pressure because the discussion has already happened three weeks period before the panel meeting online. In the actual panel meeting, reviewers only have to discuss outstanding issues and agree a ranked list. Discussion boards allow panel members to be flexible with the time they commit to the review. Discussion boards support increased transparency of pre-panel meeting work and discussion and improve benchmarking of scoring before the panel meeting. Our consultees pointed out that discussion boards help to remove the â€˜corner of the roomâ€™ discussions that happen at in-person meetings and might not be transparent and cannot be challenged. Furthermore, discussion boards enable clear and detailed feedback to applicants because all discussions are recorded.</p>
<h3>Use of videos</h3>
<p>Several consulted funders reported using videos as part of the application process. For example, UKRI uses video clips along with short application forms at the EOI stage of the Healthy Ageing Catalysts programme. FWF uses videos for pre-selection before soliciting full applications in its Momentum programme. The programme funds researchers one to two years after tenure to provide a boost for their career. The programme received many applications, and FWF decided to introduce pre-applications and used a three-minute video application for the first assessment stage. The accompanying evaluation found no bias in the assessment based on the video format (for example, showing diagrams, not showing the speaker, etc.), and reviewers were happy with the format. The video format helped to keep the burden for reviewers low.</p>
<h3>Improving culture or supporting EDI in interviews and panel meetings</h3>
<p>Our consultation also reveals several small interventions or tweaks to the assessment process, all aimed at improving assessment culture and supporting EDI. None of these modifications has the potential to improve the process alone, but in combination with other measures, these small interventions can potentially have a positive impact. For example, UKRIâ€™s Future Leaders Fellowships programme introduced silent reflection periods in interviews (adapted from prior use by EPSRC in 2016 to 2017). After the interview, a two-minute silent period is mandated when no one can speak. A silent period helps to stop initial verbal reactions about how good or bad the interview was, which may otherwise affect the rest of the discussion. The silent period is intended for panel members to reflect on what they have heard and develop reasoning for their grading.</p>
<p>In the same programme, UKRI introduced the numbers-first approach. This means that panel members first give their grades without commentary to avoid the risk of them changing their views and grades because other panel members have different or more loudly expressed opinions. UKRI observed improved panel discussion quality after introducing the above measures.</p>
<h2 id="section-summary-and-recommendations">Summary and recommendations</h2><p>Our headline findings are noted at the outset of this report. We have summarised our list of recommendations resulting from our research in a <a href="/publications/review-of-peer-review/">summary table of aims, hazards and evidence strength</a>. It shows how each of the 38 interventions relates to the seven main aims posited at the start, as well as the main hazards of each intervention, and our evidence strength rating.</p>
<h3>Recommendations</h3>
<p>There are several recommendations stemming from our research. An initial draft of these was discussed and slightly refined at a validation meeting with UKRI in April 2023.</p>
<p>We note that the recommendations below are not specific to UKRI. They are intended as recommendations of good practice for any organisation involved in R&amp;I funding.</p>
<h4>Recommendations on how to use the interventions</h4>
<p>Our headline recommendation is that process design should always be a constituent part of scheme design. The standard review process posited at the start of this report (submission, eligibility check, two to three external reviews, panel review, decision) should never be a â€˜defaultâ€™. Every funding scheme has specific aims and characteristics, and so the design of the application, review and decision-making process should be considered for each individual funding opportunity.</p>
<p>We encourage funders to make extensive use of the interventions studied here and to vary their assessment processes widely. Our review shows that some highly effective interventions (for example, two-stage processes, encouraging positive behaviours, interactive assessment processes) in achieving desired outcomes still require additional staff effort, which can be challenging in resource constraints. However, plenty of interventions also present opportunities for resource savings (for example, using automation-assisted peer allocation, virtual panels, and partial randomisation). Therefore, funders can strategically review the mix of their funding portfolio and use interventions appropriate for the objectives of specific funding schemes and seek balanced use of interventions in terms of the resources required. For example, resources saved by introducing partial randomisation or panel-only approaches for smaller grants can be used to run two-stage processes and recruit non-academic reviewers in programmes that fund projects with extra-scientific objectives.</p>
<p>It is worth noting that such diversification may create a high cognitive load for both funder staff and researchers. In order to facilitate such diversification, it is therefore important that funders have the necessary resources and modernised systems needed to implement interventions as easily as possible. This likely constitutes an important confluence point between this study and other recent work in the UK and beyond on research bureaucracy and research culture.</p>
<p>There are many reasons to reduce bureaucracy and change research culture, and doing so will likely also create conditions where interventions to peer review processes can be implemented more easily.</p>
<p>Most critically, to ensure our recommended level of variation is possible, IT systems need to have the necessary flexibility and function. Fundersâ€™ application and review management systems (the IT underpinning the process) need to be designed in such a way that the interventions can easily be integrated into every bespoke scheme setup. While this is not a prerequisite for all 38 interventions studied here, it plays a part in many of them. Outdated, overly rigid IT systems may risk stifling fundersâ€™ ability to vary and optimise their processes.</p>
<p>Critically, we note that the judgement of experienced R&amp;I funder staff is critical. Almost every intervention we have considered has advantages as well as potential hazards and drawbacks. Our research can give extensive guidance on which interventions might suit a particular funding scheme, but scheme design is not a mechanical process with â€˜only one right answerâ€™.</p>
<p>Most interventions studied here are suitable for specific contexts and should not be rolled out across all R&amp;I funding opportunities. Indeed, a small number have extremely limited applicability (use of quotas, metrics, dragonâ€™s den pitches). However, some interventions have the potential to become a â€˜new normalâ€™ in order to save burden and reduce bias across the board.</p>
<p>Providing additional support to groups unrepresented in the funderâ€™s portfolio to encourage them to apply and support them may be used by funders to improve diversity. Of the interventions aiming to support greater inclusion, working with underrepresented groups is the one with the highest demonstrated evidence strength. The actual implementation may vary from more sophisticated actions, including hands-on support, to less involved actions, like simply stating in the funding opportunity document that the unrepresented groups are encouraged to apply. Both approaches are shown to be effective</p>
<p>Use of peer review colleges (and the training/briefing opportunities they entail) may be a good default practice to improve review quality. Where the expertise represented on such colleges does not cover certain applications, there must however remain the possibility to recruit reviewers beyond the college. Funders should ensure the college membership is diverse (for example, open to ECRs) and open to new participants.</p>
<p>On a related note, automated reviewer allocation may become a genuine opportunity for saving administrative burden, avoiding conflicts of interest and increasing reviewer response rates. Experience-sharing among funders will be important here, especially in relation to which systems have been proven to work. Peer review colleges combined with automation-assisted reviewer allocation would bring additional benefits</p>
<p>There is a good case to substantially expand the use of anonymised reviewing. Most funding schemes likely need at some stage to scrutinise the track record of applicants, but in multi-stage assessment processes and for smaller awards (where risk levels are lower), having at least parts of the process anonymised would help reduce bias and inequitable outcomes</p>
<p>While often seen as a â€˜radicalâ€™ innovation in R&amp;I funding, there is a good case to mainstream an element of partial randomisation across most R&amp;I funding endeavours. This should not be extensive and should not cover all or even the majority of funding decisions: expert judgement through peer and panel review does well at identifying the very best applications, as well as the â€˜tailâ€™ of unsuitable ones. However, having partial randomisation as a consistently available option would enable some time savings and counteract bias, both against underrepresented groups and high-risk or high-reward ideas.</p>
<p>As a minimum, randomisation should be used in cases where applications are of indistinguishable quality so as to avoid excessive and laboured discussion. Funders may however go further and randomise among a larger subset of high-quality applications where panels struggle to reach agreement</p>
<h4>Recommendations on testing and further research</h4>
<p>For some of the interventions covered in this report, there is limited evidence of their effectiveness simply because they have not been empirically studied to a sufficient degree. Virtual panels are potentially the most telling example.</p>
<p>Many research funders have widely adopted virtual panels since the COVID-19 pandemic and report that this has become a â€˜new normalâ€™ because of the time savings and associated improved ability to secure panel membership and diversity. While these gains are obvious and valuable, evidence of the impact on the discussion quality is scarce and requires further research. However, this should not necessarily discourage R&amp;I funders from considering the interventions.</p>
<p>For both well-tested and more embryonic interventions, we recommend that funders monitor any interventions they undertake, and where possible compare them to a pre-intervention baseline or to other funding schemes running in parallel. Importantly, funders should share good practice with their peers so that successes can be mainstreamed.</p>
<p>To counter the perceived risk that might accompany the innovative use of the interventions, we recommend that funders first test the intervention on a smaller scale via a pilot opportunity or by commissioning accompanying process evaluations. If funders introduce the intervention to an existing programme, then evaluation or simply review of monitoring data comparing the processes and outcomes pre- and post-intervention can be organised.</p>
<p>The comparison allows for detecting the benefits (or lack of), improving the process and making a case for the decision makers. Most evaluations of the interventions rely on programme monitoring data analysis, programme staff and stakeholder (applicants and reviewers) consultation and complete the evaluations during or right after the funding opportunities that introduce new interventions.</p>
<p>Our review shows that some interventions (demand management, shortening applications) can reduce the burden for the funder but not the system because the burden is simply shifted elsewhere, for example, to the research community, to institutions, or to other funders. Therefore, R&amp;I funders should follow up and assess the effects of the interventions on these wider constituencies.</p>
<h4>Recommendations beyond the interventions</h4>
<p>Our review reveals that the assessment process can be improved with various interventions. However, procedural changes alone cannot fix wider systemic problems that may exist in research culture. Often interventions can go some way to enable improved outcomes, but wider problems of research culture may persist and even dampen the capacity for the interventions to achieve their greatest possible effect. We note this in particular because there have been great efforts by many funders and experts in recent years to assess and improve many elements of research culture, and our findings here should not be read as alternative â€˜quick fixesâ€™ to those important endeavours. Investigations into wider research culture categorically need to continue alongside the process interventions discussed in this report.</p>
<p class="ukri-print-timestamp">Page viewed: 2:23 pm on 23 May 2024</p>			
			</div>
		</div>
				<div class="sticky-element">
			<a class="govuk-link back-to-top govuk-!-margin-bottom-6" href="#contents">
				<svg class="back-to-top__icon" xmlns="http://www.w3.org/2000/svg" width="13" height="17" viewbox="0 0 13 17" aria-hidden="true" focusable="false">
				  <path fill="currentColor" d="M6.5 0L0 6.5 1.4 8l4-4v12.7h2V4l4.3 4L13 6.4z"></path>
				</svg><span>Contents</span>
			</a>
		</div>
			</div>

</div>
    </main>

Title: ['Skip to main content', '\n                                    ', '\n                                ', 'Apply for funding', 'Manage your award', 'What we do', 'News and events', 'Who we are', 'Our councils', 'Apply for funding', 'Funding finder', 'How to apply for research and innovation funding', 'Studentships and doctoral training', 'How we make decisions', 'Improving your funding experience', 'Horizon Europe', 'Manage your award', 'Accept your offer', 'Getting your funding', 'UKRI terms and conditions', 'Request a change', 'Report your outcomes', 'Report your spending', 'Publish your findings', 'What we do', 'Browse our areas of investment and support', 'What weâ€™ve funded', 'International', 'Investing across the UK', 'Career development', 'Supporting collaboration', 'Infrastructure', 'Research culture', 'Artificial intelligence', 'Research financial sustainability', 'Public engagement', 'News and events', 'News', 'Blog', 'Events', 'Voices blog', '101 jobs that change the world', 'Who we are', 'About UK Research and Innovation', 'Our vision and strategy', 'How weâ€™re governed', 'Who we fund', 'How weâ€™re doing', 'How we engage', 'Policies, standards and data', 'Work for us: jobs and advisory roles', 'Contact us', 'Our councils', 'AHRC', 'BBSRC', 'ESRC', 'EPSRC', 'Innovate UK', 'MRC', 'NERC', 'Research England', 'STFC', 'Innovate UK', 'full opportunity details on the Innovation Funding Service', 'Print this guidance or save as PDF', 'feedback', 'help improve our online products and services']
URL: 

Content: <main class="govuk-main-wrapper ukri-main-content" id="main-content">

        <div class="govuk-width-container">
	<div class="content-badge">Funding opportunity</div>
	<h1 class="govuk-heading-xl main-area__page-title" id="skipnav-target"><span class="govuk-visually-hidden">Funding opportunity: </span>Canada-UK: biomanufacturing of biologics and advanced therapies</h1>
    <div class="govuk-grid-row">
                <div class="govuk-grid-column-two-thirds-from-desktop single-opportunity__content-container main-content-column">
      			<div class="entry-header">
        				<div class="entry-meta single-opportunity__entry-meta">
          					
<dl class="govuk-table opportunity__summary">
  <div class="govuk-table__row">
    <dt class="govuk-table__header opportunity-cells">Opportunity status: </dt>
    <dd class="govuk-table__cell opportunity-cells"><span class="closed opportunity-status__flag">Closed</span></dd>
  </div>
  <div class="govuk-table__row">
    <dt class="govuk-table__header opportunity-cells">Funders: </dt>
    <dd class="govuk-table__cell opportunity-cells">
	<a class="ukri-funder__link" href="https://www.ukri.org/councils/innovate-uk/">Innovate UK</a>	</dd>
  </div>
      <div class="govuk-table__row">
      <dt class="govuk-table__header opportunity-cells">Co-funders: </dt>
	  <dd class="govuk-table__cell opportunity-cells">National Research Council of Canada (NRC)</dd>
	</div>
    <div class="govuk-table__row">
    <dt class="govuk-table__header opportunity-cells">Funding type: </dt>
	<dd class="govuk-table__cell opportunity-cells">Grant</dd>
  </div>
      <div class="govuk-table__row">
      <dt class="govuk-table__header opportunity-cells">Total fund: </dt>
	  <dd class="govuk-table__cell opportunity-cells">Â£3,500,000</dd>
    </div>
      <div class="govuk-table__row">
    <dt class="govuk-table__header opportunity-cells">Publication date: </dt>
	<dd class="govuk-table__cell opportunity-cells">23 June 2023</dd>
  </div>
  <div class="govuk-table__row">
    <dt class="govuk-table__header opportunity-cells">Opening date: </dt>
	<dd class="govuk-table__cell opportunity-cells">
	<time datetime="2023-06-26T09:30:00">26 June 2023 9:30am UK time</time>	</dd>
  </div>
  <div class="govuk-table__row">
    <dt class="govuk-table__header opportunity-cells">Closing date: </dt>
	<dd class="govuk-table__cell opportunity-cells">
	<time datetime="2023-10-17T17:00:00">17 October 2023 5:00pm UK time</time>	</dd>
  </div>
</dl>
														<div class="clearfix"></div>
        				</div>
                            </div><!-- .entry-header -->

            <div class="entry-content single-opportunity__entry-content">
                <div class="description">
                    <div class="ukri-callout-box">
<p>See theÂ <a href="https://apply-for-innovation-funding.service.gov.uk/competition/1630/overview/4ce3b4bd-f3a5-43e2-8d03-e4142fa4ce04">full opportunity details on the Innovation Funding Service</a>.</p>
</div>
<p>UK registered organisations can apply for a share of up to Â£3.5 million. You will collaborate with Canadian micro, small or medium-sized enterprises (SME) on joint research and development projects, for enabling technologies and innovations in biomanufacturing of biologics and advanced therapies.</p>
<h2>Eligibility summary</h2>
<p>This competition is open to Canada and UK collaborations only.</p>
<p>To lead a project your organisation must:</p>
<ul>
<li>be a UK registered business</li>
<li>be or involve at least one grant claiming UK registered SME</li>
<li>collaborate with a Canadian SME, which must be a separate non-linked entity to the UK project partners</li>
</ul>
<p>or:</p>
<ul>
<li>be a Canadian SME</li>
<li>partner with at least one grant claiming UK registered SME</li>
</ul>
                </div>
            </div><!-- .entry-content -->

            			
			      	</div><!-- #content -->

        <aside class="govuk-grid-column-one-third-from-desktop ukri-sidebar">
            
<div class="widget ukri-document__widget ukri-print__widget">
    <h2 class="govuk-visually-hidden">Print and download options</h2>
    <ul class="govuk-list ukri-document-list">
        <li class="ukri-document-list__item">
            <span class="ukri-document__icon">
            <svg id="Capa_1" data-name="Capa 1" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 20 15.65" width="20" height="15.65"><title>icon-printer</title><style type="text/css">.st0{fill:#FFFFFF;}</style><path class="st0" d="M0,11.3a4.34,4.34,0,0,0,3.48,4.26V11.74h13v3.82A4.34,4.34,0,0,0,20,11.3V6.52H0ZM3.91,9.13H16.09a.44.44,0,0,1,0,.87H3.91a.44.44,0,0,1,0-.87Z"></path><rect class="st0" x="4.35" y="12.61" width="11.3" height="3.04"></rect><rect class="st0" x="3.91" width="12.17" height="5.65"></rect></svg>
            </span>
            <a class="govuk-link" href="javascript:window.print()" id="analytics-opportunity-print">Print this guidance or save as PDF</a>
        </li>
    </ul>
</div>

<div class="widget good-research">
	<h2 class="govuk-heading-m ukri-sidebar__title">Guidance on good research</h2>
	<div class="textwidget">
		<ul>
			<li><a class="ukri-sidebar__link ukri-good-research__link" href="/about-us/policies-standards-and-data/good-research-resource-hub/"><span>Good research resource hub</span></a></li>
		</ul>
	</div>
</div>




<div class="ukri-email-signup__widget widget"><div class="ukri-email-signup"><h2 class="govuk-heading-m ukri-sidebar__title">Subscribe to UKRI emails</h2><p>Sign up for news, views, events and funding alerts.</p><form id="GD-snippet-form" action="https://public.govdelivery.com/accounts/UKRI/subscriber/qualify" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="âœ“"><input type="hidden" name="authenticity_token" value="+YhakBaKcGaLHAiEXHIrJZI7M21BsdXY4FCT0O65c3+v1fI18upE/geX9xnPumuqjMuPnpb9mqAFT0gZNB1PPA=="><label class="govuk-visually-hidden" for="email">Email address</label><input class="govuk-input ukri-email-signup__input" id="email" name="email" type="email" placeholder="Email address"><br><button class="govuk-button ukri-button--blue ukri-email-signup__button" data-module="govuk-button" id="analytics-newsletter-signup">Subscribe</button></form></div></div>        </aside>
            </div><!-- #primary -->
</div>
    </main>

